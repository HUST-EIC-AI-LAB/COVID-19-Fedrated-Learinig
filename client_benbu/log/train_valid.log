./model/merge_model_Param_v1.pth
some of decrypted state:
tensor([[[[ 0.1958, -0.1750,  0.1467],
          [ 0.3149,  0.3626,  0.2161],
          [-0.2958, -0.2636, -0.0157]],

         [[-0.0586,  0.3643,  0.4186],
          [-0.0624,  0.2001, -0.3992],
          [-0.3946, -0.1502,  0.2413]],

         [[ 0.3884, -0.2353,  0.0850],
          [-0.0387, -0.2813,  0.2216],
          [ 0.3432,  0.3605, -0.3246]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1958, -0.1750,  0.1467],
          [ 0.3149,  0.3626,  0.2161],
          [-0.2958, -0.2636, -0.0157]],

         [[-0.0586,  0.3643,  0.4186],
          [-0.0624,  0.2001, -0.3992],
          [-0.3946, -0.1502,  0.2413]],

         [[ 0.3884, -0.2353,  0.0850],
          [-0.0387, -0.2813,  0.2216],
          [ 0.3432,  0.3605, -0.3246]]]], device='cuda:0')
start training
0 epoch, 1 iter, loss 1.5039613246917725
0 epoch, 2 iter, loss 1.4966825246810913
0 epoch, 3 iter, loss 1.4179152250289917
0 epoch, 4 iter, loss 1.4454185962677002
0 epoch, 5 iter, loss 1.4386348724365234
0 epoch, 6 iter, loss 1.438459873199463
0 epoch, 7 iter, loss 1.4000532627105713
0 epoch, 8 iter, loss 1.4585012197494507
0 epoch, 9 iter, loss 1.3951890468597412
0 epoch, 10 iter, loss 1.4408349990844727
0 epoch, 11 iter, loss 1.4902464151382446
0 epoch, 12 iter, loss 1.482511043548584
0 epoch, 13 iter, loss 1.3629566431045532
0 epoch, 14 iter, loss 1.4174121618270874
0 epoch, 15 iter, loss 1.3696879148483276
0 epoch, 16 iter, loss 1.3503482341766357
0 epoch, 17 iter, loss 1.4312504529953003
0 epoch, 18 iter, loss 1.4555397033691406
0 epoch, 19 iter, loss 1.379127025604248
0 epoch, 20 iter, loss 1.371146559715271
0 epoch, 21 iter, loss 1.3297374248504639
0 epoch, 22 iter, loss 1.3664731979370117
0 epoch, 23 iter, loss 1.3278248310089111
0 epoch, 24 iter, loss 1.2831426858901978
0 epoch, 25 iter, loss 1.281415581703186
0 epoch, 26 iter, loss 1.2962068319320679
0 epoch, 27 iter, loss 1.2768181562423706
0 epoch, 28 iter, loss 1.2250887155532837
0 epoch, 29 iter, loss 1.3039958477020264
0 epoch, 30 iter, loss 1.269683599472046
0 epoch, 31 iter, loss 1.2164961099624634
0 epoch, 32 iter, loss 1.309022068977356
0 epoch, 33 iter, loss 1.268863320350647
0 epoch, 34 iter, loss 1.242484450340271
0 epoch, 35 iter, loss 1.3086378574371338
0 epoch, 36 iter, loss 1.2562403678894043
0 epoch, 37 iter, loss 1.2238099575042725
0 epoch, 38 iter, loss 1.267148733139038
0 epoch, 39 iter, loss 1.2931970357894897
0 epoch, 40 iter, loss 1.1971137523651123
0 epoch, 41 iter, loss 1.2624552249908447
0 epoch, 42 iter, loss 1.3348454236984253
0 epoch, 43 iter, loss 1.2369656562805176
0 epoch, 44 iter, loss 1.2519111633300781
0 epoch, 45 iter, loss 1.2063395977020264
0 epoch, 46 iter, loss 1.232240915298462
0 epoch, 47 iter, loss 1.1215611696243286
0 epoch, 48 iter, loss 1.21549654006958
0 epoch, 49 iter, loss 1.2370390892028809
0 epoch, 50 iter, loss 1.1771528720855713
0 epoch, 51 iter, loss 1.1136282682418823
0 epoch, 52 iter, loss 1.2452917098999023
0 epoch, 53 iter, loss 1.220245122909546
0 epoch, 54 iter, loss 1.1979906558990479
0 epoch, 55 iter, loss 1.1553690433502197
0 epoch, 56 iter, loss 1.2174128293991089
0 epoch, 57 iter, loss 1.2659430503845215
0 epoch, Average loss 1.3119502799552785
./model/merge_model_Param_v2.pth
some of decrypted state:
tensor([[[[ 0.0652, -0.0584,  0.0488],
          [ 0.1049,  0.1208,  0.0719],
          [-0.0988, -0.0880, -0.0054]],

         [[-0.0196,  0.1214,  0.1395],
          [-0.0209,  0.0666, -0.1331],
          [-0.1317, -0.0502,  0.0803]],

         [[ 0.1294, -0.0785,  0.0283],
          [-0.0129, -0.0938,  0.0738],
          [ 0.1143,  0.1201, -0.1083]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1955, -0.1752,  0.1465],
          [ 0.3146,  0.3623,  0.2158],
          [-0.2964, -0.2641, -0.0161]],

         [[-0.0589,  0.3641,  0.4184],
          [-0.0626,  0.1999, -0.3994],
          [-0.3950, -0.1506,  0.2410]],

         [[ 0.3882, -0.2354,  0.0849],
          [-0.0388, -0.2814,  0.2215],
          [ 0.3430,  0.3603, -0.3248]]]], device='cuda:0')
start training
1 epoch, 1 iter, loss 1.2571449279785156
1 epoch, 2 iter, loss 1.277693271636963
1 epoch, 3 iter, loss 1.2297013998031616
1 epoch, 4 iter, loss 1.194645643234253
1 epoch, 5 iter, loss 1.3748021125793457
1 epoch, 6 iter, loss 1.2421631813049316
1 epoch, 7 iter, loss 1.2730900049209595
1 epoch, 8 iter, loss 1.2979415655136108
1 epoch, 9 iter, loss 1.1722371578216553
1 epoch, 10 iter, loss 1.2142223119735718
1 epoch, 11 iter, loss 1.2255303859710693
1 epoch, 12 iter, loss 1.2963312864303589
1 epoch, 13 iter, loss 1.1107796430587769
1 epoch, 14 iter, loss 1.3365517854690552
1 epoch, 15 iter, loss 1.14998459815979
1 epoch, 16 iter, loss 1.2334883213043213
1 epoch, 17 iter, loss 1.243873953819275
1 epoch, 18 iter, loss 1.2796107530593872
1 epoch, 19 iter, loss 1.2581517696380615
1 epoch, 20 iter, loss 1.1135610342025757
1 epoch, 21 iter, loss 1.2871209383010864
1 epoch, 22 iter, loss 1.2707668542861938
1 epoch, 23 iter, loss 1.2335643768310547
1 epoch, 24 iter, loss 1.2806190252304077
1 epoch, 25 iter, loss 1.3073455095291138
1 epoch, 26 iter, loss 1.1698541641235352
1 epoch, 27 iter, loss 1.1758508682250977
1 epoch, 28 iter, loss 1.1157258749008179
1 epoch, 29 iter, loss 1.2629430294036865
1 epoch, 30 iter, loss 1.1571844816207886
1 epoch, 31 iter, loss 1.239547848701477
1 epoch, 32 iter, loss 1.212309718132019
1 epoch, 33 iter, loss 1.227107048034668
1 epoch, 34 iter, loss 1.1000462770462036
1 epoch, 35 iter, loss 1.2436455488204956
1 epoch, 36 iter, loss 1.1403478384017944
1 epoch, 37 iter, loss 1.0974928140640259
1 epoch, 38 iter, loss 1.1837310791015625
1 epoch, 39 iter, loss 1.283501386642456
1 epoch, 40 iter, loss 1.2181411981582642
1 epoch, 41 iter, loss 1.1132956743240356
1 epoch, 42 iter, loss 1.1840453147888184
1 epoch, 43 iter, loss 1.1525431871414185
1 epoch, 44 iter, loss 1.102230429649353
1 epoch, 45 iter, loss 1.089256763458252
1 epoch, 46 iter, loss 1.1563692092895508
1 epoch, 47 iter, loss 1.0818737745285034
1 epoch, 48 iter, loss 1.1216245889663696
1 epoch, 49 iter, loss 1.1420111656188965
1 epoch, 50 iter, loss 1.0797940492630005
1 epoch, 51 iter, loss 1.1498661041259766
1 epoch, 52 iter, loss 1.063990592956543
1 epoch, 53 iter, loss 1.0776082277297974
1 epoch, 54 iter, loss 1.237241506576538
1 epoch, 55 iter, loss 1.0543310642242432
1 epoch, 56 iter, loss 1.1278585195541382
1 epoch, 57 iter, loss 1.1390044689178467
1 epoch, Average loss 1.194057818044696
./model/merge_model_Param_v3.pth
some of decrypted state:
tensor([[[[ 0.0649, -0.0586,  0.0487],
          [ 0.1048,  0.1207,  0.0718],
          [-0.0992, -0.0884, -0.0057]],

         [[-0.0198,  0.1213,  0.1394],
          [-0.0209,  0.0666, -0.1332],
          [-0.1320, -0.0505,  0.0800]],

         [[ 0.1292, -0.0786,  0.0282],
          [-0.0130, -0.0938,  0.0738],
          [ 0.1141,  0.1198, -0.1085]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1947, -0.1757,  0.1460],
          [ 0.3143,  0.3620,  0.2155],
          [-0.2975, -0.2652, -0.0171]],

         [[-0.0594,  0.3638,  0.4181],
          [-0.0626,  0.1999, -0.3995],
          [-0.3959, -0.1515,  0.2401]],

         [[ 0.3876, -0.2359,  0.0846],
          [-0.0389, -0.2815,  0.2214],
          [ 0.3422,  0.3595, -0.3256]]]], device='cuda:0')
start training
2 epoch, 1 iter, loss 1.5870773792266846
2 epoch, 2 iter, loss 1.3502455949783325
2 epoch, 3 iter, loss 1.130674958229065
2 epoch, 4 iter, loss 1.130993127822876
2 epoch, 5 iter, loss 1.1020569801330566
2 epoch, 6 iter, loss 1.1458630561828613
2 epoch, 7 iter, loss 1.120330572128296
2 epoch, 8 iter, loss 1.0989266633987427
2 epoch, 9 iter, loss 1.4093809127807617
2 epoch, 10 iter, loss 1.371579647064209
2 epoch, 11 iter, loss 1.1744385957717896
2 epoch, 12 iter, loss 1.104945421218872
2 epoch, 13 iter, loss 1.1596858501434326
2 epoch, 14 iter, loss 1.0727201700210571
2 epoch, 15 iter, loss 1.2707970142364502
2 epoch, 16 iter, loss 1.2842020988464355
2 epoch, 17 iter, loss 1.1520483493804932
2 epoch, 18 iter, loss 1.1844559907913208
2 epoch, 19 iter, loss 1.1798838376998901
2 epoch, 20 iter, loss 1.0786182880401611
2 epoch, 21 iter, loss 1.2979074716567993
2 epoch, 22 iter, loss 1.2970727682113647
2 epoch, 23 iter, loss 1.1752235889434814
2 epoch, 24 iter, loss 1.006492018699646
2 epoch, 25 iter, loss 1.0938438177108765
2 epoch, 26 iter, loss 1.096956491470337
2 epoch, 27 iter, loss 1.0284603834152222
2 epoch, 28 iter, loss 1.0657451152801514
2 epoch, 29 iter, loss 0.9983448386192322
2 epoch, 30 iter, loss 1.093192458152771
2 epoch, 31 iter, loss 1.0355031490325928
2 epoch, 32 iter, loss 1.087650179862976
2 epoch, 33 iter, loss 1.2766895294189453
2 epoch, 34 iter, loss 1.015712857246399
2 epoch, 35 iter, loss 1.012191653251648
2 epoch, 36 iter, loss 1.0712193250656128
2 epoch, 37 iter, loss 1.11564040184021
2 epoch, 38 iter, loss 0.9716898798942566
2 epoch, 39 iter, loss 1.0192981958389282
2 epoch, 40 iter, loss 1.0640652179718018
2 epoch, 41 iter, loss 1.0785189867019653
2 epoch, 42 iter, loss 1.201548457145691
2 epoch, 43 iter, loss 1.1140246391296387
2 epoch, 44 iter, loss 1.1202374696731567
2 epoch, 45 iter, loss 1.0580575466156006
2 epoch, 46 iter, loss 0.9898211359977722
2 epoch, 47 iter, loss 0.9954361915588379
2 epoch, 48 iter, loss 1.2441437244415283
2 epoch, 49 iter, loss 1.0473723411560059
2 epoch, 50 iter, loss 1.151552677154541
2 epoch, 51 iter, loss 1.1193739175796509
2 epoch, 52 iter, loss 1.0787837505340576
2 epoch, 53 iter, loss 1.1786607503890991
2 epoch, 54 iter, loss 1.046037197113037
2 epoch, 55 iter, loss 1.2024478912353516
2 epoch, 56 iter, loss 1.128635048866272
2 epoch, 57 iter, loss 0.9493390917778015
2 epoch, Average loss 1.1339616608201413
./model/merge_model_Param_v4.pth
some of decrypted state:
tensor([[[[ 0.0647, -0.0586,  0.0486],
          [ 0.1046,  0.1204,  0.0714],
          [-0.1002, -0.0894, -0.0066]],

         [[-0.0199,  0.1212,  0.1392],
          [-0.0210,  0.0663, -0.1335],
          [-0.1329, -0.0514,  0.0792]],

         [[ 0.1286, -0.0790,  0.0278],
          [-0.0135, -0.0944,  0.0732],
          [ 0.1128,  0.1186, -0.1096]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1942, -0.1759,  0.1457],
          [ 0.3138,  0.3611,  0.2141],
          [-0.3005, -0.2681, -0.0198]],

         [[-0.0598,  0.3635,  0.4177],
          [-0.0630,  0.1990, -0.4005],
          [-0.3986, -0.1543,  0.2377]],

         [[ 0.3859, -0.2371,  0.0834],
          [-0.0404, -0.2831,  0.2195],
          [ 0.3383,  0.3557, -0.3287]]]], device='cuda:0')
start training
3 epoch, 1 iter, loss 1.4473026990890503
3 epoch, 2 iter, loss 1.3911175727844238
3 epoch, 3 iter, loss 1.1833750009536743
3 epoch, 4 iter, loss 0.9827237129211426
3 epoch, 5 iter, loss 1.2617915868759155
3 epoch, 6 iter, loss 1.1467729806900024
3 epoch, 7 iter, loss 1.2066092491149902
3 epoch, 8 iter, loss 1.0790575742721558
3 epoch, 9 iter, loss 1.0024946928024292
3 epoch, 10 iter, loss 1.2294012308120728
3 epoch, 11 iter, loss 1.141998291015625
3 epoch, 12 iter, loss 0.8341763615608215
3 epoch, 13 iter, loss 1.184151530265808
3 epoch, 14 iter, loss 1.3317184448242188
3 epoch, 15 iter, loss 1.0617344379425049
3 epoch, 16 iter, loss 1.159199595451355
3 epoch, 17 iter, loss 1.023370623588562
3 epoch, 18 iter, loss 1.0533159971237183
3 epoch, 19 iter, loss 1.0670684576034546
3 epoch, 20 iter, loss 1.0783416032791138
3 epoch, 21 iter, loss 0.9896016120910645
3 epoch, 22 iter, loss 1.0219628810882568
3 epoch, 23 iter, loss 1.0651872158050537
3 epoch, 24 iter, loss 1.1177018880844116
3 epoch, 25 iter, loss 1.058526635169983
3 epoch, 26 iter, loss 1.0283808708190918
3 epoch, 27 iter, loss 0.9628238081932068
3 epoch, 28 iter, loss 1.118036150932312
3 epoch, 29 iter, loss 0.9358634948730469
3 epoch, 30 iter, loss 1.0969797372817993
3 epoch, 31 iter, loss 0.9430506825447083
3 epoch, 32 iter, loss 1.053552508354187
3 epoch, 33 iter, loss 0.9259103536605835
3 epoch, 34 iter, loss 0.9628878235816956
3 epoch, 35 iter, loss 1.0363800525665283
3 epoch, 36 iter, loss 1.0674148797988892
3 epoch, 37 iter, loss 1.1473716497421265
3 epoch, 38 iter, loss 1.0512443780899048
3 epoch, 39 iter, loss 1.0448685884475708
3 epoch, 40 iter, loss 0.9586589932441711
3 epoch, 41 iter, loss 1.0207467079162598
3 epoch, 42 iter, loss 0.8492584824562073
3 epoch, 43 iter, loss 1.0490163564682007
3 epoch, 44 iter, loss 1.0987764596939087
3 epoch, 45 iter, loss 1.2186074256896973
3 epoch, 46 iter, loss 1.0735387802124023
3 epoch, 47 iter, loss 1.0627177953720093
3 epoch, 48 iter, loss 0.9021363854408264
3 epoch, 49 iter, loss 0.9510781168937683
3 epoch, 50 iter, loss 0.9439702033996582
3 epoch, 51 iter, loss 1.1312862634658813
3 epoch, 52 iter, loss 1.1018651723861694
3 epoch, 53 iter, loss 0.8484271168708801
3 epoch, 54 iter, loss 0.9297358393669128
3 epoch, 55 iter, loss 0.8801813125610352
3 epoch, 56 iter, loss 0.8083634972572327
3 epoch, 57 iter, loss 0.8326921463012695
3 epoch, Average loss 1.0553425247209114
./model/merge_model_Param_v5.pth
some of decrypted state:
tensor([[[[ 0.0648, -0.0588,  0.0481],
          [ 0.1047,  0.1205,  0.0715],
          [-0.1012, -0.0903, -0.0074]],

         [[-0.0196,  0.1212,  0.1390],
          [-0.0205,  0.0667, -0.1329],
          [-0.1334, -0.0519,  0.0790]],

         [[ 0.1280, -0.0797,  0.0271],
          [-0.0138, -0.0945,  0.0732],
          [ 0.1115,  0.1175, -0.1102]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1943, -0.1764,  0.1444],
          [ 0.3140,  0.3614,  0.2144],
          [-0.3035, -0.2708, -0.0222]],

         [[-0.0589,  0.3635,  0.4171],
          [-0.0616,  0.2001, -0.3987],
          [-0.4001, -0.1556,  0.2370]],

         [[ 0.3841, -0.2392,  0.0813],
          [-0.0413, -0.2834,  0.2196],
          [ 0.3346,  0.3525, -0.3305]]]], device='cuda:0')
start training
4 epoch, 1 iter, loss 1.22129225730896
4 epoch, 2 iter, loss 1.2187875509262085
4 epoch, 3 iter, loss 0.9776238203048706
4 epoch, 4 iter, loss 0.9890896081924438
4 epoch, 5 iter, loss 1.0512467622756958
4 epoch, 6 iter, loss 0.916076123714447
4 epoch, 7 iter, loss 1.0097503662109375
4 epoch, 8 iter, loss 0.9992533922195435
4 epoch, 9 iter, loss 1.0133720636367798
4 epoch, 10 iter, loss 1.0455125570297241
4 epoch, 11 iter, loss 1.0469317436218262
4 epoch, 12 iter, loss 0.9668005108833313
4 epoch, 13 iter, loss 1.0731686353683472
4 epoch, 14 iter, loss 0.9833448529243469
4 epoch, 15 iter, loss 0.9764108657836914
4 epoch, 16 iter, loss 1.0611958503723145
4 epoch, 17 iter, loss 1.0494825839996338
4 epoch, 18 iter, loss 0.8963866829872131
4 epoch, 19 iter, loss 0.9242353439331055
4 epoch, 20 iter, loss 0.9875279664993286
4 epoch, 21 iter, loss 0.9480955600738525
4 epoch, 22 iter, loss 0.8505541086196899
4 epoch, 23 iter, loss 0.9910455346107483
4 epoch, 24 iter, loss 1.177856683731079
4 epoch, 25 iter, loss 0.896998941898346
4 epoch, 26 iter, loss 0.9771903157234192
4 epoch, 27 iter, loss 0.9515847563743591
4 epoch, 28 iter, loss 0.9645522832870483
4 epoch, 29 iter, loss 1.0591270923614502
4 epoch, 30 iter, loss 0.7664473056793213
4 epoch, 31 iter, loss 1.0593397617340088
4 epoch, 32 iter, loss 1.0299980640411377
4 epoch, 33 iter, loss 0.8635960221290588
4 epoch, 34 iter, loss 0.8646365404129028
4 epoch, 35 iter, loss 1.0292023420333862
4 epoch, 36 iter, loss 1.0883899927139282
4 epoch, 37 iter, loss 0.9192091226577759
4 epoch, 38 iter, loss 0.9240898489952087
4 epoch, 39 iter, loss 0.8514048457145691
4 epoch, 40 iter, loss 1.154213547706604
4 epoch, 41 iter, loss 0.921570897102356
4 epoch, 42 iter, loss 0.9338794350624084
4 epoch, 43 iter, loss 0.9316047430038452
4 epoch, 44 iter, loss 1.0097558498382568
4 epoch, 45 iter, loss 0.9616389274597168
4 epoch, 46 iter, loss 0.8970783352851868
4 epoch, 47 iter, loss 0.929625391960144
4 epoch, 48 iter, loss 0.8763335943222046
4 epoch, 49 iter, loss 1.0415903329849243
4 epoch, 50 iter, loss 0.9519968032836914
4 epoch, 51 iter, loss 0.8703121542930603
4 epoch, 52 iter, loss 0.8364118337631226
4 epoch, 53 iter, loss 1.0839430093765259
4 epoch, 54 iter, loss 1.0198495388031006
4 epoch, 55 iter, loss 0.9170562624931335
4 epoch, 56 iter, loss 1.1101171970367432
4 epoch, 57 iter, loss 0.8167967200279236
4 epoch, Average loss 0.9804312848208243
./model/merge_model_Param_v6.pth
some of decrypted state:
tensor([[[[ 0.0645, -0.0593,  0.0474],
          [ 0.1053,  0.1211,  0.0716],
          [-0.1016, -0.0908, -0.0078]],

         [[-0.0204,  0.1205,  0.1383],
          [-0.0205,  0.0670, -0.1329],
          [-0.1342, -0.0526,  0.0784]],

         [[ 0.1268, -0.0810,  0.0261],
          [-0.0140, -0.0943,  0.0734],
          [ 0.1108,  0.1169, -0.1106]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1934, -0.1778,  0.1422],
          [ 0.3159,  0.3633,  0.2148],
          [-0.3049, -0.2724, -0.0234]],

         [[-0.0611,  0.3615,  0.4148],
          [-0.0614,  0.2009, -0.3986],
          [-0.4026, -0.1578,  0.2353]],

         [[ 0.3803, -0.2429,  0.0783],
          [-0.0420, -0.2829,  0.2202],
          [ 0.3324,  0.3507, -0.3319]]]], device='cuda:0')
start training
5 epoch, 1 iter, loss 1.1607162952423096
5 epoch, 2 iter, loss 0.9377824664115906
5 epoch, 3 iter, loss 0.881712019443512
5 epoch, 4 iter, loss 1.0294387340545654
5 epoch, 5 iter, loss 1.0608640909194946
5 epoch, 6 iter, loss 0.9978575706481934
5 epoch, 7 iter, loss 1.0099821090698242
5 epoch, 8 iter, loss 0.9539409875869751
5 epoch, 9 iter, loss 0.8130461573600769
5 epoch, 10 iter, loss 0.9275420904159546
5 epoch, 11 iter, loss 0.9900011420249939
5 epoch, 12 iter, loss 0.9552004933357239
5 epoch, 13 iter, loss 0.9354202151298523
5 epoch, 14 iter, loss 0.9377092719078064
5 epoch, 15 iter, loss 0.794475257396698
5 epoch, 16 iter, loss 0.8145875334739685
5 epoch, 17 iter, loss 0.966161847114563
5 epoch, 18 iter, loss 1.166279911994934
5 epoch, 19 iter, loss 1.0475947856903076
5 epoch, 20 iter, loss 0.9688709378242493
5 epoch, 21 iter, loss 0.9084141254425049
5 epoch, 22 iter, loss 0.9505316019058228
5 epoch, 23 iter, loss 1.0695236921310425
5 epoch, 24 iter, loss 0.9580045342445374
5 epoch, 25 iter, loss 0.9683664441108704
5 epoch, 26 iter, loss 0.9452127814292908
5 epoch, 27 iter, loss 1.0735902786254883
5 epoch, 28 iter, loss 0.9470959305763245
5 epoch, 29 iter, loss 0.9976608157157898
5 epoch, 30 iter, loss 0.8157019019126892
5 epoch, 31 iter, loss 0.7517112493515015
5 epoch, 32 iter, loss 0.9996761083602905
5 epoch, 33 iter, loss 0.94098299741745
5 epoch, 34 iter, loss 0.7584479451179504
5 epoch, 35 iter, loss 0.9684562683105469
5 epoch, 36 iter, loss 0.9140858054161072
5 epoch, 37 iter, loss 0.9113386869430542
5 epoch, 38 iter, loss 0.9478800892829895
5 epoch, 39 iter, loss 0.8172825574874878
5 epoch, 40 iter, loss 1.052291989326477
5 epoch, 41 iter, loss 0.9481014013290405
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
5 epoch, 42 iter, loss 0.8761492371559143
5 epoch, 43 iter, loss 0.8442816734313965
5 epoch, 44 iter, loss 0.9437302350997925
5 epoch, 45 iter, loss 0.9635559916496277
5 epoch, 46 iter, loss 0.9585968255996704
5 epoch, 47 iter, loss 0.9437556862831116
5 epoch, 48 iter, loss 1.0430490970611572
5 epoch, 49 iter, loss 0.938583254814148
5 epoch, 50 iter, loss 1.1767370700836182
5 epoch, 51 iter, loss 1.2042129039764404
5 epoch, 52 iter, loss 0.8394878506660461
5 epoch, 53 iter, loss 0.7929822206497192
5 epoch, 54 iter, loss 0.9740868210792542
5 epoch, 55 iter, loss 0.9354079365730286
5 epoch, 56 iter, loss 0.8406823873519897
5 epoch, 57 iter, loss 1.070228099822998
5 epoch, Average loss 0.9533169896979081
./model/merge_model_Param_v7.pth
some of decrypted state:
tensor([[[[ 0.0638, -0.0597,  0.0475],
          [ 0.1055,  0.1214,  0.0716],
          [-0.1017, -0.0905, -0.0076]],

         [[-0.0213,  0.1202,  0.1385],
          [-0.0204,  0.0671, -0.1329],
          [-0.1346, -0.0528,  0.0784]],

         [[ 0.1253, -0.0820,  0.0260],
          [-0.0142, -0.0943,  0.0732],
          [ 0.1102,  0.1166, -0.1111]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1913, -0.1792,  0.1424],
          [ 0.3164,  0.3642,  0.2148],
          [-0.3050, -0.2716, -0.0228]],

         [[-0.0639,  0.3605,  0.4156],
          [-0.0613,  0.2012, -0.3987],
          [-0.4039, -0.1583,  0.2352]],

         [[ 0.3759, -0.2459,  0.0779],
          [-0.0425, -0.2830,  0.2197],
          [ 0.3306,  0.3498, -0.3333]]]], device='cuda:0')
start training
6 epoch, 1 iter, loss 0.9380666613578796
6 epoch, 2 iter, loss 1.011718511581421
6 epoch, 3 iter, loss 1.1225614547729492
6 epoch, 4 iter, loss 1.172940731048584
6 epoch, 5 iter, loss 0.9913150668144226
6 epoch, 6 iter, loss 0.785894513130188
6 epoch, 7 iter, loss 1.0606034994125366
6 epoch, 8 iter, loss 0.8512024879455566
6 epoch, 9 iter, loss 0.8679659962654114
6 epoch, 10 iter, loss 1.0230140686035156
6 epoch, 11 iter, loss 0.70159912109375
6 epoch, 12 iter, loss 0.9274172186851501
6 epoch, 13 iter, loss 0.9548073410987854
6 epoch, 14 iter, loss 0.9245272874832153
6 epoch, 15 iter, loss 0.924639105796814
6 epoch, 16 iter, loss 0.8443470597267151
6 epoch, 17 iter, loss 0.7586221098899841
6 epoch, 18 iter, loss 0.8841822743415833
6 epoch, 19 iter, loss 0.8247069716453552
6 epoch, 20 iter, loss 0.7164759635925293
6 epoch, 21 iter, loss 0.8904174566268921
6 epoch, 22 iter, loss 0.9592499136924744
6 epoch, 23 iter, loss 1.0997205972671509
6 epoch, 24 iter, loss 0.8463609218597412
6 epoch, 25 iter, loss 0.8887825012207031
6 epoch, 26 iter, loss 0.8498372435569763
6 epoch, 27 iter, loss 0.7926482558250427
6 epoch, 28 iter, loss 0.9262435436248779
6 epoch, 29 iter, loss 0.8076252341270447
6 epoch, 30 iter, loss 0.9277929067611694
6 epoch, 31 iter, loss 0.837891161441803
6 epoch, 32 iter, loss 0.622280478477478
6 epoch, 33 iter, loss 0.8729538321495056
6 epoch, 34 iter, loss 0.8985213041305542
6 epoch, 35 iter, loss 1.1041889190673828
6 epoch, 36 iter, loss 1.0417264699935913
6 epoch, 37 iter, loss 0.9529256820678711
6 epoch, 38 iter, loss 0.868156373500824
6 epoch, 39 iter, loss 1.0892919301986694
6 epoch, 40 iter, loss 0.8760308027267456
6 epoch, 41 iter, loss 1.100637674331665
6 epoch, 42 iter, loss 0.9641804695129395
6 epoch, 43 iter, loss 0.8742444515228271
6 epoch, 44 iter, loss 0.8834860324859619
6 epoch, 45 iter, loss 0.7557191252708435
6 epoch, 46 iter, loss 0.8385602235794067
6 epoch, 47 iter, loss 0.979740560054779
6 epoch, 48 iter, loss 0.9541399478912354
6 epoch, 49 iter, loss 1.1439130306243896
6 epoch, 50 iter, loss 1.0773916244506836
6 epoch, 51 iter, loss 0.8027644753456116
6 epoch, 52 iter, loss 1.0122274160385132
6 epoch, 53 iter, loss 0.8176771402359009
6 epoch, 54 iter, loss 1.040909767150879
6 epoch, 55 iter, loss 0.8875393867492676
6 epoch, 56 iter, loss 0.7203405499458313
6 epoch, 57 iter, loss 0.6898033618927002
6 epoch, Average loss 0.9119741791173032
./model/merge_model_Param_v8.pth
some of decrypted state:
tensor([[[[ 0.0634, -0.0602,  0.0473],
          [ 0.1058,  0.1220,  0.0719],
          [-0.1018, -0.0906, -0.0076]],

         [[-0.0220,  0.1197,  0.1385],
          [-0.0204,  0.0674, -0.1327],
          [-0.1350, -0.0530,  0.0782]],

         [[ 0.1239, -0.0834,  0.0252],
          [-0.0147, -0.0944,  0.0731],
          [ 0.1096,  0.1162, -0.1116]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1901, -0.1805,  0.1420],
          [ 0.3174,  0.3661,  0.2158],
          [-0.3054, -0.2718, -0.0228]],

         [[-0.0660,  0.3592,  0.4155],
          [-0.0613,  0.2022, -0.3980],
          [-0.4049, -0.1589,  0.2347]],

         [[ 0.3716, -0.2501,  0.0755],
          [-0.0441, -0.2831,  0.2192],
          [ 0.3288,  0.3485, -0.3348]]]], device='cuda:0')
start training
7 epoch, 1 iter, loss 1.2714487314224243
7 epoch, 2 iter, loss 0.8092374801635742
7 epoch, 3 iter, loss 1.0845462083816528
7 epoch, 4 iter, loss 1.1971700191497803
7 epoch, 5 iter, loss 0.9195601344108582
7 epoch, 6 iter, loss 1.0899056196212769
7 epoch, 7 iter, loss 1.0452462434768677
7 epoch, 8 iter, loss 0.8364582061767578
7 epoch, 9 iter, loss 0.8761305809020996
7 epoch, 10 iter, loss 0.8913260102272034
7 epoch, 11 iter, loss 0.7545985579490662
7 epoch, 12 iter, loss 0.898688793182373
7 epoch, 13 iter, loss 0.8609438538551331
7 epoch, 14 iter, loss 0.9767836928367615
7 epoch, 15 iter, loss 1.0184717178344727
7 epoch, 16 iter, loss 0.8957954049110413
7 epoch, 17 iter, loss 0.8637823462486267
7 epoch, 18 iter, loss 0.9814608097076416
7 epoch, 19 iter, loss 0.9664371609687805
7 epoch, 20 iter, loss 0.8998878598213196
7 epoch, 21 iter, loss 0.8218749165534973
7 epoch, 22 iter, loss 0.8474473357200623
7 epoch, 23 iter, loss 1.032556176185608
7 epoch, 24 iter, loss 0.7683498859405518
7 epoch, 25 iter, loss 0.826256275177002
7 epoch, 26 iter, loss 1.0235369205474854
7 epoch, 27 iter, loss 0.8873850107192993
7 epoch, 28 iter, loss 0.9310906529426575
7 epoch, 29 iter, loss 0.8640895485877991
7 epoch, 30 iter, loss 0.993260383605957
7 epoch, 31 iter, loss 0.9018392562866211
7 epoch, 32 iter, loss 0.9577848315238953
7 epoch, 33 iter, loss 0.9102082252502441
7 epoch, 34 iter, loss 0.8708789348602295
7 epoch, 35 iter, loss 0.8557535409927368
7 epoch, 36 iter, loss 0.8067640662193298
7 epoch, 37 iter, loss 0.9484221339225769
7 epoch, 38 iter, loss 0.5728276371955872
7 epoch, 39 iter, loss 0.6715578436851501
7 epoch, 40 iter, loss 0.77704918384552
7 epoch, 41 iter, loss 0.8248780369758606
7 epoch, 42 iter, loss 0.7756691575050354
7 epoch, 43 iter, loss 0.8602831363677979
7 epoch, 44 iter, loss 0.7105218172073364
7 epoch, 45 iter, loss 0.752547562122345
7 epoch, 46 iter, loss 1.0262926816940308
7 epoch, 47 iter, loss 0.8775029182434082
7 epoch, 48 iter, loss 0.6652461886405945
7 epoch, 49 iter, loss 0.8447583317756653
7 epoch, 50 iter, loss 0.7742058634757996
7 epoch, 51 iter, loss 0.7195079326629639
7 epoch, 52 iter, loss 0.8370222449302673
7 epoch, 53 iter, loss 0.9405373930931091
7 epoch, 54 iter, loss 1.0305280685424805
7 epoch, 55 iter, loss 0.6687036156654358
7 epoch, 56 iter, loss 0.9047915935516357
7 epoch, 57 iter, loss 0.9338827729225159
7 epoch, Average loss 0.8869068685330843
./model/merge_model_Param_v9.pth
some of decrypted state:
tensor([[[[ 0.0630, -0.0605,  0.0470],
          [ 0.1060,  0.1223,  0.0721],
          [-0.1023, -0.0910, -0.0081]],

         [[-0.0224,  0.1194,  0.1383],
          [-0.0206,  0.0674, -0.1325],
          [-0.1358, -0.0536,  0.0776]],

         [[ 0.1230, -0.0845,  0.0242],
          [-0.0154, -0.0947,  0.0727],
          [ 0.1085,  0.1154, -0.1126]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1890, -0.1816,  0.1409],
          [ 0.3179,  0.3669,  0.2164],
          [-0.3069, -0.2731, -0.0243]],

         [[-0.0673,  0.3583,  0.4148],
          [-0.0618,  0.2021, -0.3975],
          [-0.4073, -0.1608,  0.2329]],

         [[ 0.3689, -0.2535,  0.0726],
          [-0.0461, -0.2841,  0.2181],
          [ 0.3256,  0.3461, -0.3377]]]], device='cuda:0')
start training
8 epoch, 1 iter, loss 1.096876859664917
8 epoch, 2 iter, loss 0.9025835990905762
8 epoch, 3 iter, loss 0.8657011389732361
8 epoch, 4 iter, loss 0.8787243962287903
8 epoch, 5 iter, loss 0.9618518948554993
8 epoch, 6 iter, loss 0.7312061190605164
8 epoch, 7 iter, loss 0.839236319065094
8 epoch, 8 iter, loss 0.7765114307403564
8 epoch, 9 iter, loss 0.7598300576210022
8 epoch, 10 iter, loss 0.7411499619483948
8 epoch, 11 iter, loss 0.9541459679603577
8 epoch, 12 iter, loss 0.9995242953300476
8 epoch, 13 iter, loss 0.8312667608261108
8 epoch, 14 iter, loss 0.7451421618461609
8 epoch, 15 iter, loss 0.7462571263313293
8 epoch, 16 iter, loss 1.017676591873169
8 epoch, 17 iter, loss 0.8200045824050903
8 epoch, 18 iter, loss 1.085571527481079
8 epoch, 19 iter, loss 0.7977645397186279
8 epoch, 20 iter, loss 0.9926956295967102
8 epoch, 21 iter, loss 0.8360715508460999
8 epoch, 22 iter, loss 0.6954320669174194
8 epoch, 23 iter, loss 0.9108853936195374
8 epoch, 24 iter, loss 0.8745540976524353
8 epoch, 25 iter, loss 1.0764532089233398
8 epoch, 26 iter, loss 0.7180455923080444
8 epoch, 27 iter, loss 0.8192241787910461
8 epoch, 28 iter, loss 0.8550525307655334
8 epoch, 29 iter, loss 0.8280008435249329
8 epoch, 30 iter, loss 0.8508971333503723
8 epoch, 31 iter, loss 0.8063149452209473
8 epoch, 32 iter, loss 0.8966369032859802
8 epoch, 33 iter, loss 0.8531367778778076
8 epoch, 34 iter, loss 0.936692476272583
8 epoch, 35 iter, loss 0.9210465550422668
8 epoch, 36 iter, loss 1.0735793113708496
8 epoch, 37 iter, loss 0.8470900058746338
8 epoch, 38 iter, loss 0.9610804319381714
8 epoch, 39 iter, loss 0.7880425453186035
8 epoch, 40 iter, loss 0.8963481187820435
8 epoch, 41 iter, loss 0.7248300909996033
8 epoch, 42 iter, loss 0.6742348670959473
8 epoch, 43 iter, loss 0.785973846912384
8 epoch, 44 iter, loss 0.8132033348083496
8 epoch, 45 iter, loss 0.8151465654373169
8 epoch, 46 iter, loss 0.7446052432060242
8 epoch, 47 iter, loss 0.5952216982841492
8 epoch, 48 iter, loss 0.6820169687271118
8 epoch, 49 iter, loss 0.7091246843338013
8 epoch, 50 iter, loss 0.7014098167419434
8 epoch, 51 iter, loss 0.9981212615966797
8 epoch, 52 iter, loss 0.7303426265716553
8 epoch, 53 iter, loss 1.0043985843658447
8 epoch, 54 iter, loss 0.5386823415756226
8 epoch, 55 iter, loss 0.6587843894958496
8 epoch, 56 iter, loss 0.7451720833778381
8 epoch, 57 iter, loss 0.980437159538269
8 epoch, Average loss 0.8401756349362826
./model/merge_model_Param_v10.pth
some of decrypted state:
tensor([[[[ 0.0631, -0.0601,  0.0478],
          [ 0.1064,  0.1226,  0.0721],
          [-0.1013, -0.0901, -0.0074]],

         [[-0.0224,  0.1199,  0.1392],
          [-0.0203,  0.0677, -0.1325],
          [-0.1350, -0.0528,  0.0782]],

         [[ 0.1227, -0.0844,  0.0250],
          [-0.0151, -0.0943,  0.0728],
          [ 0.1095,  0.1163, -0.1117]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1894, -0.1803,  0.1435],
          [ 0.3193,  0.3679,  0.2162],
          [-0.3038, -0.2702, -0.0222]],

         [[-0.0672,  0.3597,  0.4175],
          [-0.0610,  0.2030, -0.3974],
          [-0.4050, -0.1584,  0.2346]],

         [[ 0.3681, -0.2533,  0.0750],
          [-0.0453, -0.2828,  0.2183],
          [ 0.3284,  0.3490, -0.3351]]]], device='cuda:0')
start training
9 epoch, 1 iter, loss 1.0957456827163696
9 epoch, 2 iter, loss 0.9748298525810242
9 epoch, 3 iter, loss 0.9957461953163147
9 epoch, 4 iter, loss 1.102294921875
9 epoch, 5 iter, loss 0.8887373805046082
9 epoch, 6 iter, loss 0.905491292476654
9 epoch, 7 iter, loss 0.7969462275505066
9 epoch, 8 iter, loss 0.9287474155426025
9 epoch, 9 iter, loss 0.919916033744812
9 epoch, 10 iter, loss 0.7608699798583984
9 epoch, 11 iter, loss 0.7876471281051636
9 epoch, 12 iter, loss 0.7683685421943665
9 epoch, 13 iter, loss 1.0344957113265991
9 epoch, 14 iter, loss 0.8077772855758667
9 epoch, 15 iter, loss 0.9871457815170288
9 epoch, 16 iter, loss 0.713671088218689
9 epoch, 17 iter, loss 0.7946338653564453
9 epoch, 18 iter, loss 1.0289148092269897
9 epoch, 19 iter, loss 0.8154435753822327
9 epoch, 20 iter, loss 0.9490004181861877
9 epoch, 21 iter, loss 0.8600108027458191
9 epoch, 22 iter, loss 0.8945534229278564
9 epoch, 23 iter, loss 1.0744785070419312
9 epoch, 24 iter, loss 0.8439430594444275
9 epoch, 25 iter, loss 0.7508206963539124
9 epoch, 26 iter, loss 0.831599235534668
9 epoch, 27 iter, loss 0.7911393642425537
9 epoch, 28 iter, loss 0.9586927890777588
9 epoch, 29 iter, loss 0.9861248731613159
9 epoch, 30 iter, loss 0.8071152567863464
9 epoch, 31 iter, loss 0.8942089676856995
9 epoch, 32 iter, loss 0.7808766961097717
9 epoch, 33 iter, loss 0.7650204300880432
9 epoch, 34 iter, loss 0.8915131688117981
9 epoch, 35 iter, loss 0.857106626033783
9 epoch, 36 iter, loss 0.9072549939155579
9 epoch, 37 iter, loss 0.7872780561447144
9 epoch, 38 iter, loss 0.8522283434867859
9 epoch, 39 iter, loss 0.907481849193573
9 epoch, 40 iter, loss 0.7659333944320679
9 epoch, 41 iter, loss 0.8281477093696594
9 epoch, 42 iter, loss 0.6759877800941467
9 epoch, 43 iter, loss 0.7180517315864563
9 epoch, 44 iter, loss 0.8479543924331665
9 epoch, 45 iter, loss 0.87430739402771
9 epoch, 46 iter, loss 0.6368463635444641
9 epoch, 47 iter, loss 0.7524365782737732
9 epoch, 48 iter, loss 0.8171203136444092
9 epoch, 49 iter, loss 0.8321062326431274
9 epoch, 50 iter, loss 0.7957216501235962
9 epoch, 51 iter, loss 0.9286741018295288
9 epoch, 52 iter, loss 0.7204532623291016
9 epoch, 53 iter, loss 0.7642225027084351
9 epoch, 54 iter, loss 0.6949000954627991
9 epoch, 55 iter, loss 0.9479895234107971
9 epoch, 56 iter, loss 0.8333815932273865
9 epoch, 57 iter, loss 0.7167984247207642
9 epoch, Average loss 0.8534895328053257
./model/merge_model_Param_v11.pth
some of decrypted state:
tensor([[[[ 0.0629, -0.0604,  0.0478],
          [ 0.1071,  0.1230,  0.0721],
          [-0.1017, -0.0908, -0.0083]],

         [[-0.0234,  0.1191,  0.1387],
          [-0.0208,  0.0672, -0.1331],
          [-0.1361, -0.0541,  0.0768]],

         [[ 0.1207, -0.0868,  0.0232],
          [-0.0166, -0.0956,  0.0712],
          [ 0.1080,  0.1149, -0.1133]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1888, -0.1813,  0.1434],
          [ 0.3212,  0.3690,  0.2162],
          [-0.3052, -0.2724, -0.0249]],

         [[-0.0701,  0.3573,  0.4162],
          [-0.0623,  0.2016, -0.3994],
          [-0.4083, -0.1622,  0.2305]],

         [[ 0.3620, -0.2605,  0.0696],
          [-0.0497, -0.2869,  0.2136],
          [ 0.3240,  0.3447, -0.3400]]]], device='cuda:0')
start training
10 epoch, 1 iter, loss 0.9684375524520874
10 epoch, 2 iter, loss 0.9900805354118347
10 epoch, 3 iter, loss 0.947453498840332
10 epoch, 4 iter, loss 0.9984205961227417
10 epoch, 5 iter, loss 0.6902101635932922
10 epoch, 6 iter, loss 0.8193976879119873
10 epoch, 7 iter, loss 0.7900816798210144
10 epoch, 8 iter, loss 0.8768554925918579
10 epoch, 9 iter, loss 0.9182676672935486
10 epoch, 10 iter, loss 1.1624010801315308
10 epoch, 11 iter, loss 0.5614722371101379
10 epoch, 12 iter, loss 0.6783151030540466
10 epoch, 13 iter, loss 0.7182219624519348
10 epoch, 14 iter, loss 0.729242205619812
10 epoch, 15 iter, loss 0.8675878047943115
10 epoch, 16 iter, loss 0.725307285785675
10 epoch, 17 iter, loss 0.9580265879631042
10 epoch, 18 iter, loss 0.9180566072463989
10 epoch, 19 iter, loss 0.8609885573387146
10 epoch, 20 iter, loss 0.5946527123451233
10 epoch, 21 iter, loss 0.7709481716156006
10 epoch, 22 iter, loss 0.7906634211540222
10 epoch, 23 iter, loss 0.881593644618988
10 epoch, 24 iter, loss 0.8664838671684265
10 epoch, 25 iter, loss 0.9118736982345581
10 epoch, 26 iter, loss 0.8135002255439758
10 epoch, 27 iter, loss 0.8031252026557922
10 epoch, 28 iter, loss 0.7968332767486572
10 epoch, 29 iter, loss 0.8077377676963806
10 epoch, 30 iter, loss 0.7403915524482727
10 epoch, 31 iter, loss 0.8742157220840454
10 epoch, 32 iter, loss 0.8183611631393433
10 epoch, 33 iter, loss 0.6651843190193176
10 epoch, 34 iter, loss 0.5950316190719604
10 epoch, 35 iter, loss 1.043990135192871
10 epoch, 36 iter, loss 0.9300726652145386
10 epoch, 37 iter, loss 1.0465342998504639
10 epoch, 38 iter, loss 0.881886899471283
10 epoch, 39 iter, loss 0.8382139205932617
10 epoch, 40 iter, loss 0.9204896688461304
10 epoch, 41 iter, loss 0.6804309487342834
10 epoch, 42 iter, loss 0.6729087829589844
10 epoch, 43 iter, loss 0.7583138346672058
10 epoch, 44 iter, loss 0.6344023942947388
10 epoch, 45 iter, loss 0.6945803761482239
10 epoch, 46 iter, loss 0.8722614645957947
10 epoch, 47 iter, loss 0.7149446606636047
10 epoch, 48 iter, loss 0.9631189107894897
10 epoch, 49 iter, loss 0.9394010901451111
10 epoch, 50 iter, loss 0.8690189123153687
10 epoch, 51 iter, loss 0.7468324303627014
10 epoch, 52 iter, loss 0.8202092051506042
10 epoch, 53 iter, loss 0.651017427444458
10 epoch, 54 iter, loss 0.9832327365875244
10 epoch, 55 iter, loss 0.8537412285804749
10 epoch, 56 iter, loss 0.854969322681427
10 epoch, 57 iter, loss 0.9658998250961304
10 epoch, Average loss 0.8288752949028685
./model/merge_model_Param_v12.pth
some of decrypted state:
tensor([[[[ 0.0622, -0.0609,  0.0478],
          [ 0.1089,  0.1245,  0.0728],
          [-0.1004, -0.0897, -0.0075]],

         [[-0.0243,  0.1187,  0.1390],
          [-0.0194,  0.0684, -0.1326],
          [-0.1350, -0.0532,  0.0772]],

         [[ 0.1191, -0.0884,  0.0228],
          [-0.0155, -0.0944,  0.0719],
          [ 0.1094,  0.1162, -0.1127]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1867, -0.1826,  0.1435],
          [ 0.3267,  0.3736,  0.2183],
          [-0.3013, -0.2692, -0.0225]],

         [[-0.0730,  0.3562,  0.4170],
          [-0.0583,  0.2053, -0.3977],
          [-0.4050, -0.1597,  0.2317]],

         [[ 0.3572, -0.2651,  0.0684],
          [-0.0464, -0.2831,  0.2156],
          [ 0.3281,  0.3487, -0.3380]]]], device='cuda:0')
start training
11 epoch, 1 iter, loss 1.0461452007293701
11 epoch, 2 iter, loss 1.0112800598144531
11 epoch, 3 iter, loss 0.8772977590560913
11 epoch, 4 iter, loss 0.597986102104187
11 epoch, 5 iter, loss 0.9091301560401917
11 epoch, 6 iter, loss 0.786453902721405
11 epoch, 7 iter, loss 0.8827285170555115
11 epoch, 8 iter, loss 0.7976061701774597
11 epoch, 9 iter, loss 0.7923541069030762
11 epoch, 10 iter, loss 0.8465358018875122
11 epoch, 11 iter, loss 0.7668365836143494
11 epoch, 12 iter, loss 0.8802454471588135
11 epoch, 13 iter, loss 0.7825754880905151
11 epoch, 14 iter, loss 0.6345731616020203
11 epoch, 15 iter, loss 0.7788205742835999
11 epoch, 16 iter, loss 0.8192370533943176
11 epoch, 17 iter, loss 0.8519062399864197
11 epoch, 18 iter, loss 0.7468268871307373
11 epoch, 19 iter, loss 0.8219274878501892
11 epoch, 20 iter, loss 0.790272057056427
11 epoch, 21 iter, loss 0.6523153185844421
11 epoch, 22 iter, loss 0.8482842445373535
11 epoch, 23 iter, loss 0.6192779541015625
11 epoch, 24 iter, loss 0.6311671733856201
11 epoch, 25 iter, loss 0.9475290775299072
11 epoch, 26 iter, loss 0.9584763646125793
11 epoch, 27 iter, loss 0.6835395097732544
11 epoch, 28 iter, loss 0.8671419620513916
11 epoch, 29 iter, loss 0.8045415282249451
11 epoch, 30 iter, loss 0.8182997107505798
11 epoch, 31 iter, loss 0.8934613466262817
11 epoch, 32 iter, loss 0.7035853862762451
11 epoch, 33 iter, loss 0.9509322643280029
11 epoch, 34 iter, loss 0.6446332335472107
11 epoch, 35 iter, loss 0.7692455649375916
11 epoch, 36 iter, loss 0.6606926321983337
11 epoch, 37 iter, loss 0.7382053136825562
11 epoch, 38 iter, loss 0.7748607397079468
11 epoch, 39 iter, loss 0.6068602204322815
11 epoch, 40 iter, loss 0.7345067262649536
11 epoch, 41 iter, loss 0.8240234851837158
11 epoch, 42 iter, loss 0.8945614099502563
11 epoch, 43 iter, loss 0.8326303958892822
11 epoch, 44 iter, loss 0.6988722681999207
11 epoch, 45 iter, loss 0.7295939922332764
11 epoch, 46 iter, loss 0.7066002488136292
11 epoch, 47 iter, loss 1.036149501800537
11 epoch, 48 iter, loss 0.6638056635856628
11 epoch, 49 iter, loss 0.7791488170623779
11 epoch, 50 iter, loss 0.6732744574546814
11 epoch, 51 iter, loss 0.705984354019165
11 epoch, 52 iter, loss 0.9311887621879578
11 epoch, 53 iter, loss 0.7139461040496826
11 epoch, 54 iter, loss 0.7973895072937012
11 epoch, 55 iter, loss 0.7909497022628784
11 epoch, 56 iter, loss 0.8301222920417786
11 epoch, 57 iter, loss 0.7398589849472046
11 epoch, Average loss 0.790813946933077
./model/merge_model_Param_v13.pth
some of decrypted state:
tensor([[[[ 0.0626, -0.0602,  0.0486],
          [ 0.1099,  0.1254,  0.0734],
          [-0.0995, -0.0889, -0.0070]],

         [[-0.0244,  0.1188,  0.1391],
          [-0.0192,  0.0686, -0.1323],
          [-0.1350, -0.0533,  0.0769]],

         [[ 0.1184, -0.0893,  0.0220],
          [-0.0157, -0.0945,  0.0714],
          [ 0.1090,  0.1158, -0.1134]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1878, -0.1807,  0.1458],
          [ 0.3298,  0.3763,  0.2202],
          [-0.2986, -0.2667, -0.0209]],

         [[-0.0733,  0.3564,  0.4172],
          [-0.0577,  0.2057, -0.3970],
          [-0.4049, -0.1600,  0.2306]],

         [[ 0.3551, -0.2678,  0.0659],
          [-0.0471, -0.2836,  0.2143],
          [ 0.3269,  0.3475, -0.3402]]]], device='cuda:0')
start training
12 epoch, 1 iter, loss 0.8475150465965271
12 epoch, 2 iter, loss 1.0828006267547607
12 epoch, 3 iter, loss 0.8228744864463806
12 epoch, 4 iter, loss 0.7823805809020996
12 epoch, 5 iter, loss 0.8127560019493103
12 epoch, 6 iter, loss 0.8248291015625
12 epoch, 7 iter, loss 0.9425640106201172
12 epoch, 8 iter, loss 0.7877787947654724
12 epoch, 9 iter, loss 1.1135563850402832
12 epoch, 10 iter, loss 0.7102349996566772
12 epoch, 11 iter, loss 0.9239551424980164
12 epoch, 12 iter, loss 0.7060828804969788
12 epoch, 13 iter, loss 0.8461742997169495
12 epoch, 14 iter, loss 0.7998460531234741
12 epoch, 15 iter, loss 0.8166872262954712
12 epoch, 16 iter, loss 1.028540015220642
12 epoch, 17 iter, loss 0.8412706851959229
12 epoch, 18 iter, loss 0.8768079280853271
12 epoch, 19 iter, loss 0.661128580570221
12 epoch, 20 iter, loss 0.8027032613754272
12 epoch, 21 iter, loss 0.8906030058860779
12 epoch, 22 iter, loss 0.6365039348602295
12 epoch, 23 iter, loss 0.8172177672386169
12 epoch, 24 iter, loss 0.6931940317153931
12 epoch, 25 iter, loss 0.7210375070571899
12 epoch, 26 iter, loss 0.7759687304496765
12 epoch, 27 iter, loss 0.7612259984016418
12 epoch, 28 iter, loss 0.8612744212150574
12 epoch, 29 iter, loss 0.8589106202125549
12 epoch, 30 iter, loss 0.8277990818023682
12 epoch, 31 iter, loss 0.7079933881759644
12 epoch, 32 iter, loss 0.728345513343811
12 epoch, 33 iter, loss 0.8070515990257263
12 epoch, 34 iter, loss 0.8269820213317871
12 epoch, 35 iter, loss 0.6455161571502686
12 epoch, 36 iter, loss 0.8329808712005615
12 epoch, 37 iter, loss 0.8822745680809021
12 epoch, 38 iter, loss 0.7912813425064087
12 epoch, 39 iter, loss 0.7115113139152527
12 epoch, 40 iter, loss 0.9869827628135681
12 epoch, 41 iter, loss 0.8166035413742065
12 epoch, 42 iter, loss 0.7746114730834961
12 epoch, 43 iter, loss 0.6879817843437195
12 epoch, 44 iter, loss 0.9422751665115356
12 epoch, 45 iter, loss 0.5818456411361694
12 epoch, 46 iter, loss 0.7430054545402527
12 epoch, 47 iter, loss 0.9607788920402527
12 epoch, 48 iter, loss 0.7861719727516174
12 epoch, 49 iter, loss 0.8820776343345642
12 epoch, 50 iter, loss 0.8408295512199402
12 epoch, 51 iter, loss 0.7962348461151123
12 epoch, 52 iter, loss 0.8564267158508301
12 epoch, 53 iter, loss 0.8924189805984497
12 epoch, 54 iter, loss 0.6043512225151062
12 epoch, 55 iter, loss 0.7107400298118591
12 epoch, 56 iter, loss 0.7658205628395081
12 epoch, 57 iter, loss 0.7612287998199463
12 epoch, Average loss 0.8105007545989856
./model/merge_model_Param_v14.pth
some of decrypted state:
tensor([[[[ 0.0623, -0.0600,  0.0492],
          [ 0.1107,  0.1259,  0.0732],
          [-0.0997, -0.0892, -0.0078]],

         [[-0.0251,  0.1188,  0.1393],
          [-0.0188,  0.0690, -0.1325],
          [-0.1352, -0.0537,  0.0759]],

         [[ 0.1173, -0.0901,  0.0217],
          [-0.0155, -0.0942,  0.0712],
          [ 0.1088,  0.1158, -0.1141]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1868, -0.1799,  0.1476],
          [ 0.3321,  0.3778,  0.2197],
          [-0.2990, -0.2675, -0.0235]],

         [[-0.0754,  0.3564,  0.4180],
          [-0.0563,  0.2071, -0.3975],
          [-0.4056, -0.1612,  0.2278]],

         [[ 0.3520, -0.2704,  0.0652],
          [-0.0464, -0.2826,  0.2137],
          [ 0.3264,  0.3473, -0.3423]]]], device='cuda:0')
start training
13 epoch, 1 iter, loss 1.1065746545791626
13 epoch, 2 iter, loss 1.0318255424499512
13 epoch, 3 iter, loss 0.8696693778038025
13 epoch, 4 iter, loss 0.9370316863059998
13 epoch, 5 iter, loss 0.9795127511024475
13 epoch, 6 iter, loss 0.7436419725418091
13 epoch, 7 iter, loss 0.7881155610084534
13 epoch, 8 iter, loss 0.7301692962646484
13 epoch, 9 iter, loss 0.7210498452186584
13 epoch, 10 iter, loss 0.7309538125991821
13 epoch, 11 iter, loss 1.0011745691299438
13 epoch, 12 iter, loss 0.6298210620880127
13 epoch, 13 iter, loss 0.56733638048172
13 epoch, 14 iter, loss 0.7208408117294312
13 epoch, 15 iter, loss 0.7726481556892395
13 epoch, 16 iter, loss 1.1465309858322144
13 epoch, 17 iter, loss 0.9843688607215881
13 epoch, 18 iter, loss 0.7385852932929993
13 epoch, 19 iter, loss 0.8201311826705933
13 epoch, 20 iter, loss 0.942740797996521
13 epoch, 21 iter, loss 0.6881014704704285
13 epoch, 22 iter, loss 0.849586009979248
13 epoch, 23 iter, loss 0.7471935153007507
13 epoch, 24 iter, loss 1.1449886560440063
13 epoch, 25 iter, loss 0.8954349160194397
13 epoch, 26 iter, loss 0.695376992225647
13 epoch, 27 iter, loss 0.7014430165290833
13 epoch, 28 iter, loss 0.9772861003875732
13 epoch, 29 iter, loss 0.819494366645813
13 epoch, 30 iter, loss 0.7792231440544128
13 epoch, 31 iter, loss 0.8577882647514343
13 epoch, 32 iter, loss 0.8533249497413635
13 epoch, 33 iter, loss 0.821902334690094
13 epoch, 34 iter, loss 0.683731734752655
13 epoch, 35 iter, loss 0.7732998132705688
13 epoch, 36 iter, loss 0.6872013807296753
13 epoch, 37 iter, loss 0.7001133561134338
13 epoch, 38 iter, loss 0.911271870136261
13 epoch, 39 iter, loss 0.7174636125564575
13 epoch, 40 iter, loss 0.7810649871826172
13 epoch, 41 iter, loss 0.702638566493988
13 epoch, 42 iter, loss 0.7859663367271423
13 epoch, 43 iter, loss 0.7470216751098633
13 epoch, 44 iter, loss 0.8012555837631226
13 epoch, 45 iter, loss 0.9948889017105103
13 epoch, 46 iter, loss 0.6167680621147156
13 epoch, 47 iter, loss 0.7180710434913635
13 epoch, 48 iter, loss 0.7970276474952698
13 epoch, 49 iter, loss 0.5342512130737305
13 epoch, 50 iter, loss 0.6654722690582275
13 epoch, 51 iter, loss 0.6975589990615845
13 epoch, 52 iter, loss 0.6068885326385498
13 epoch, 53 iter, loss 0.948313295841217
13 epoch, 54 iter, loss 0.8754279613494873
13 epoch, 55 iter, loss 0.5074590444564819
13 epoch, 56 iter, loss 0.7763298749923706
13 epoch, 57 iter, loss 0.8478630185127258
13 epoch, Average loss 0.8012493880171525
./model/merge_model_Param_v15.pth
some of decrypted state:
tensor([[[[ 0.0624, -0.0597,  0.0491],
          [ 0.1110,  0.1262,  0.0736],
          [-0.1004, -0.0899, -0.0088]],

         [[-0.0255,  0.1185,  0.1386],
          [-0.0194,  0.0687, -0.1326],
          [-0.1366, -0.0551,  0.0744]],

         [[ 0.1164, -0.0912,  0.0206],
          [-0.0165, -0.0949,  0.0706],
          [ 0.1074,  0.1143, -0.1158]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1873, -0.1790,  0.1474],
          [ 0.3330,  0.3787,  0.2209],
          [-0.3013, -0.2698, -0.0264]],

         [[-0.0765,  0.3555,  0.4159],
          [-0.0581,  0.2062, -0.3979],
          [-0.4097, -0.1653,  0.2231]],

         [[ 0.3492, -0.2737,  0.0619],
          [-0.0494, -0.2847,  0.2117],
          [ 0.3221,  0.3430, -0.3474]]]], device='cuda:0')
start training
14 epoch, 1 iter, loss 0.6304858922958374
14 epoch, 2 iter, loss 0.6450897455215454
14 epoch, 3 iter, loss 0.7773398756980896
14 epoch, 4 iter, loss 0.8186908960342407
14 epoch, 5 iter, loss 0.5789966583251953
14 epoch, 6 iter, loss 0.8627715110778809
14 epoch, 7 iter, loss 0.6370875835418701
14 epoch, 8 iter, loss 0.8282496929168701
14 epoch, 9 iter, loss 0.9190356135368347
14 epoch, 10 iter, loss 0.8547431826591492
14 epoch, 11 iter, loss 0.7606562972068787
14 epoch, 12 iter, loss 0.7467834949493408
14 epoch, 13 iter, loss 0.72012859582901
14 epoch, 14 iter, loss 0.8554230332374573
14 epoch, 15 iter, loss 0.7323408126831055
14 epoch, 16 iter, loss 0.922943115234375
14 epoch, 17 iter, loss 0.691423237323761
14 epoch, 18 iter, loss 0.6811704039573669
14 epoch, 19 iter, loss 0.738661527633667
14 epoch, 20 iter, loss 0.7803629040718079
14 epoch, 21 iter, loss 0.8028743863105774
14 epoch, 22 iter, loss 0.8058724403381348
14 epoch, 23 iter, loss 0.7344467639923096
14 epoch, 24 iter, loss 0.7508215308189392
14 epoch, 25 iter, loss 0.7784534692764282
14 epoch, 26 iter, loss 0.8861110806465149
14 epoch, 27 iter, loss 0.5483984351158142
14 epoch, 28 iter, loss 0.9061744809150696
14 epoch, 29 iter, loss 0.7262788414955139
14 epoch, 30 iter, loss 0.8850123882293701
14 epoch, 31 iter, loss 0.6357612609863281
14 epoch, 32 iter, loss 0.8191574215888977
14 epoch, 33 iter, loss 0.8779942393302917
14 epoch, 34 iter, loss 0.6413105726242065
14 epoch, 35 iter, loss 0.6344552636146545
14 epoch, 36 iter, loss 0.7403175234794617
14 epoch, 37 iter, loss 0.6585514545440674
14 epoch, 38 iter, loss 0.7407673597335815
14 epoch, 39 iter, loss 0.7617579102516174
14 epoch, 40 iter, loss 0.7360135316848755
14 epoch, 41 iter, loss 0.6998156309127808
14 epoch, 42 iter, loss 0.7442618608474731
14 epoch, 43 iter, loss 0.856732189655304
14 epoch, 44 iter, loss 0.8518412113189697
14 epoch, 45 iter, loss 0.7955448031425476
14 epoch, 46 iter, loss 0.7465265989303589
14 epoch, 47 iter, loss 0.64974045753479
14 epoch, 48 iter, loss 0.7931399941444397
14 epoch, 49 iter, loss 0.7628662586212158
14 epoch, 50 iter, loss 0.7871350049972534
14 epoch, 51 iter, loss 0.6533025503158569
14 epoch, 52 iter, loss 0.6645246148109436
14 epoch, 53 iter, loss 1.012169599533081
14 epoch, 54 iter, loss 0.8456143140792847
14 epoch, 55 iter, loss 0.8511480093002319
14 epoch, 56 iter, loss 0.58423912525177
14 epoch, 57 iter, loss 0.728203296661377
14 epoch, Average loss 0.7592933324345371
./model/merge_model_Param_v16.pth
some of decrypted state:
tensor([[[[ 0.0621, -0.0595,  0.0497],
          [ 0.1121,  0.1275,  0.0744],
          [-0.0998, -0.0894, -0.0088]],

         [[-0.0260,  0.1185,  0.1390],
          [-0.0185,  0.0700, -0.1317],
          [-0.1361, -0.0546,  0.0744]],

         [[ 0.1165, -0.0909,  0.0214],
          [-0.0149, -0.0928,  0.0723],
          [ 0.1082,  0.1157, -0.1148]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1862, -0.1785,  0.1490],
          [ 0.3363,  0.3825,  0.2231],
          [-0.2995, -0.2681, -0.0263]],

         [[-0.0780,  0.3554,  0.4169],
          [-0.0554,  0.2101, -0.3950],
          [-0.4084, -0.1637,  0.2231]],

         [[ 0.3495, -0.2728,  0.0642],
          [-0.0447, -0.2785,  0.2168],
          [ 0.3246,  0.3471, -0.3445]]]], device='cuda:0')
start training
15 epoch, 1 iter, loss 1.3784136772155762
15 epoch, 2 iter, loss 1.141717553138733
15 epoch, 3 iter, loss 0.7462341785430908
15 epoch, 4 iter, loss 0.6652789115905762
15 epoch, 5 iter, loss 0.8385931253433228
15 epoch, 6 iter, loss 0.8382464647293091
15 epoch, 7 iter, loss 0.7437052726745605
15 epoch, 8 iter, loss 0.8180354833602905
15 epoch, 9 iter, loss 0.8099013566970825
15 epoch, 10 iter, loss 0.741064190864563
15 epoch, 11 iter, loss 0.7661224007606506
15 epoch, 12 iter, loss 0.7567797303199768
15 epoch, 13 iter, loss 0.9960917830467224
15 epoch, 14 iter, loss 0.801233172416687
15 epoch, 15 iter, loss 0.9071996212005615
15 epoch, 16 iter, loss 0.8314171433448792
15 epoch, 17 iter, loss 0.602202296257019
15 epoch, 18 iter, loss 0.6985980272293091
15 epoch, 19 iter, loss 0.8443669080734253
15 epoch, 20 iter, loss 0.7006537914276123
15 epoch, 21 iter, loss 0.8594144582748413
15 epoch, 22 iter, loss 0.8271204233169556
15 epoch, 23 iter, loss 0.6696363687515259
15 epoch, 24 iter, loss 0.7638676762580872
15 epoch, 25 iter, loss 0.7537009716033936
15 epoch, 26 iter, loss 0.5996717810630798
15 epoch, 27 iter, loss 0.7016822695732117
15 epoch, 28 iter, loss 0.6556224226951599
15 epoch, 29 iter, loss 0.6924160718917847
15 epoch, 30 iter, loss 0.6116461753845215
15 epoch, 31 iter, loss 0.9145879149436951
15 epoch, 32 iter, loss 0.7137582898139954
15 epoch, 33 iter, loss 0.6309530138969421
15 epoch, 34 iter, loss 0.812147319316864
15 epoch, 35 iter, loss 0.6378541588783264
15 epoch, 36 iter, loss 0.9252482652664185
15 epoch, 37 iter, loss 0.6701762676239014
15 epoch, 38 iter, loss 0.6936812400817871
15 epoch, 39 iter, loss 0.6693171262741089
15 epoch, 40 iter, loss 0.7976797223091125
15 epoch, 41 iter, loss 0.7167547345161438
15 epoch, 42 iter, loss 0.7354669570922852
15 epoch, 43 iter, loss 0.6614277362823486
15 epoch, 44 iter, loss 0.5945739150047302
15 epoch, 45 iter, loss 0.6990960836410522
15 epoch, 46 iter, loss 0.7456532120704651
15 epoch, 47 iter, loss 0.8117786049842834
15 epoch, 48 iter, loss 0.8492404222488403
15 epoch, 49 iter, loss 0.7863892912864685
15 epoch, 50 iter, loss 0.7062376737594604
15 epoch, 51 iter, loss 0.8007279634475708
15 epoch, 52 iter, loss 0.7235994338989258
15 epoch, 53 iter, loss 0.8533516526222229
15 epoch, 54 iter, loss 0.7695906758308411
15 epoch, 55 iter, loss 0.5421976447105408
15 epoch, 56 iter, loss 0.7355723977088928
15 epoch, 57 iter, loss 0.9465287923812866
15 epoch, Average loss 0.7702495476655793
./model/merge_model_Param_v17.pth
some of decrypted state:
tensor([[[[ 0.0619, -0.0593,  0.0499],
          [ 0.1138,  0.1294,  0.0762],
          [-0.0992, -0.0883, -0.0077]],

         [[-0.0267,  0.1184,  0.1391],
          [-0.0176,  0.0714, -0.1300],
          [-0.1359, -0.0536,  0.0754]],

         [[ 0.1154, -0.0920,  0.0207],
          [-0.0143, -0.0917,  0.0735],
          [ 0.1083,  0.1165, -0.1140]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1856, -0.1779,  0.1496],
          [ 0.3414,  0.3881,  0.2286],
          [-0.2977, -0.2648, -0.0231]],

         [[-0.0800,  0.3553,  0.4173],
          [-0.0527,  0.2143, -0.3899],
          [-0.4077, -0.1608,  0.2261]],

         [[ 0.3461, -0.2759,  0.0622],
          [-0.0429, -0.2750,  0.2205],
          [ 0.3248,  0.3496, -0.3419]]]], device='cuda:0')
start training
16 epoch, 1 iter, loss 0.8742648959159851
16 epoch, 2 iter, loss 0.6522172689437866
16 epoch, 3 iter, loss 0.6718907356262207
16 epoch, 4 iter, loss 0.8145655393600464
16 epoch, 5 iter, loss 0.9715529680252075
16 epoch, 6 iter, loss 0.7309231162071228
16 epoch, 7 iter, loss 0.6141682267189026
16 epoch, 8 iter, loss 0.6925349235534668
16 epoch, 9 iter, loss 0.6668257713317871
16 epoch, 10 iter, loss 0.7506863474845886
16 epoch, 11 iter, loss 0.6205345392227173
16 epoch, 12 iter, loss 0.7088179588317871
16 epoch, 13 iter, loss 0.7778559327125549
16 epoch, 14 iter, loss 0.7083019018173218
16 epoch, 15 iter, loss 0.6945607662200928
16 epoch, 16 iter, loss 0.6734693050384521
16 epoch, 17 iter, loss 0.732537031173706
16 epoch, 18 iter, loss 0.8113972544670105
16 epoch, 19 iter, loss 0.8626633882522583
16 epoch, 20 iter, loss 0.5745950937271118
16 epoch, 21 iter, loss 0.5730494260787964
16 epoch, 22 iter, loss 0.5417194962501526
16 epoch, 23 iter, loss 0.7025741338729858
16 epoch, 24 iter, loss 0.8480789661407471
16 epoch, 25 iter, loss 0.8023699522018433
16 epoch, 26 iter, loss 0.8444154858589172
16 epoch, 27 iter, loss 0.6297374367713928
16 epoch, 28 iter, loss 0.9078869223594666
16 epoch, 29 iter, loss 0.5729185342788696
16 epoch, 30 iter, loss 0.7663814425468445
16 epoch, 31 iter, loss 0.7615230679512024
16 epoch, 32 iter, loss 0.7771902680397034
16 epoch, 33 iter, loss 0.5178208351135254
16 epoch, 34 iter, loss 0.719613790512085
16 epoch, 35 iter, loss 0.7459661960601807
16 epoch, 36 iter, loss 0.6135969161987305
16 epoch, 37 iter, loss 0.7383251786231995
16 epoch, 38 iter, loss 0.7092956900596619
16 epoch, 39 iter, loss 0.8037499189376831
16 epoch, 40 iter, loss 0.5261350870132446
16 epoch, 41 iter, loss 0.6210996508598328
16 epoch, 42 iter, loss 0.5944443941116333
16 epoch, 43 iter, loss 0.6738671660423279
16 epoch, 44 iter, loss 0.6911312341690063
16 epoch, 45 iter, loss 0.9398615956306458
16 epoch, 46 iter, loss 0.7147833704948425
16 epoch, 47 iter, loss 0.9092247486114502
16 epoch, 48 iter, loss 0.7686417698860168
16 epoch, 49 iter, loss 0.8852059245109558
16 epoch, 50 iter, loss 0.9398708939552307
16 epoch, 51 iter, loss 0.9991809725761414
16 epoch, 52 iter, loss 0.7298097610473633
16 epoch, 53 iter, loss 0.7455650568008423
16 epoch, 54 iter, loss 0.6614424586296082
16 epoch, 55 iter, loss 0.8826926350593567
16 epoch, 56 iter, loss 0.8961710333824158
16 epoch, 57 iter, loss 0.8423233032226562
16 epoch, Average loss 0.740386450499819
./model/merge_model_Param_v18.pth
some of decrypted state:
tensor([[[[ 0.0626, -0.0585,  0.0510],
          [ 0.1151,  0.1304,  0.0771],
          [-0.0982, -0.0876, -0.0072]],

         [[-0.0261,  0.1192,  0.1403],
          [-0.0165,  0.0724, -0.1289],
          [-0.1351, -0.0531,  0.0759]],

         [[ 0.1155, -0.0918,  0.0213],
          [-0.0134, -0.0908,  0.0742],
          [ 0.1087,  0.1170, -0.1135]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1878, -0.1755,  0.1529],
          [ 0.3453,  0.3911,  0.2314],
          [-0.2945, -0.2629, -0.0215]],

         [[-0.0784,  0.3577,  0.4208],
          [-0.0496,  0.2172, -0.3868],
          [-0.4054, -0.1593,  0.2277]],

         [[ 0.3466, -0.2753,  0.0640],
          [-0.0403, -0.2724,  0.2226],
          [ 0.3262,  0.3510, -0.3405]]]], device='cuda:0')
start training
17 epoch, 1 iter, loss 0.7210255861282349
17 epoch, 2 iter, loss 0.8027178049087524
17 epoch, 3 iter, loss 0.6781556606292725
17 epoch, 4 iter, loss 0.6951276659965515
17 epoch, 5 iter, loss 0.5976966619491577
17 epoch, 6 iter, loss 0.7341092228889465
17 epoch, 7 iter, loss 0.7653591632843018
17 epoch, 8 iter, loss 0.5907449722290039
17 epoch, 9 iter, loss 0.6872158050537109
17 epoch, 10 iter, loss 0.5950748920440674
17 epoch, 11 iter, loss 0.7285988926887512
17 epoch, 12 iter, loss 0.7678914070129395
17 epoch, 13 iter, loss 0.6488953232765198
17 epoch, 14 iter, loss 0.6639178991317749
17 epoch, 15 iter, loss 0.7721918225288391
17 epoch, 16 iter, loss 0.7942533493041992
17 epoch, 17 iter, loss 0.7960660457611084
17 epoch, 18 iter, loss 0.7888894081115723
17 epoch, 19 iter, loss 0.7166664600372314
17 epoch, 20 iter, loss 0.7245780825614929
17 epoch, 21 iter, loss 0.5664352774620056
17 epoch, 22 iter, loss 0.821115255355835
17 epoch, 23 iter, loss 0.7390463948249817
17 epoch, 24 iter, loss 0.6731268167495728
17 epoch, 25 iter, loss 0.6512420177459717
17 epoch, 26 iter, loss 0.8547274470329285
17 epoch, 27 iter, loss 0.5080508589744568
17 epoch, 28 iter, loss 0.5713230967521667
17 epoch, 29 iter, loss 0.6577180624008179
17 epoch, 30 iter, loss 0.5707935094833374
17 epoch, 31 iter, loss 0.7339690327644348
17 epoch, 32 iter, loss 0.7318761348724365
17 epoch, 33 iter, loss 0.7790049910545349
17 epoch, 34 iter, loss 0.8033074736595154
17 epoch, 35 iter, loss 0.666778564453125
17 epoch, 36 iter, loss 0.6676994562149048
17 epoch, 37 iter, loss 0.6981556415557861
17 epoch, 38 iter, loss 0.5966742634773254
17 epoch, 39 iter, loss 0.7448133826255798
17 epoch, 40 iter, loss 0.8516621589660645
17 epoch, 41 iter, loss 0.8963865637779236
17 epoch, 42 iter, loss 0.8038851618766785
17 epoch, 43 iter, loss 0.5725581645965576
17 epoch, 44 iter, loss 0.7872545123100281
17 epoch, 45 iter, loss 0.7831197381019592
17 epoch, 46 iter, loss 0.5219216346740723
17 epoch, 47 iter, loss 0.673551082611084
17 epoch, 48 iter, loss 0.8900930285453796
17 epoch, 49 iter, loss 0.5860856175422668
17 epoch, 50 iter, loss 0.930310070514679
17 epoch, 51 iter, loss 0.7147061228752136
17 epoch, 52 iter, loss 0.7703173756599426
17 epoch, 53 iter, loss 0.8209760785102844
17 epoch, 54 iter, loss 0.744667112827301
17 epoch, 55 iter, loss 0.7132781147956848
17 epoch, 56 iter, loss 0.7410809397697449
17 epoch, 57 iter, loss 0.9445905089378357
17 epoch, Average loss 0.7202013647347166
./model/merge_model_Param_v19.pth
some of decrypted state:
tensor([[[[ 0.0628, -0.0583,  0.0509],
          [ 0.1156,  0.1301,  0.0765],
          [-0.0989, -0.0888, -0.0090]],

         [[-0.0264,  0.1192,  0.1398],
          [-0.0169,  0.0716, -0.1299],
          [-0.1359, -0.0542,  0.0741]],

         [[ 0.1149, -0.0926,  0.0204],
          [-0.0136, -0.0914,  0.0733],
          [ 0.1081,  0.1162, -0.1149]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1885, -0.1748,  0.1528],
          [ 0.3468,  0.3904,  0.2295],
          [-0.2967, -0.2663, -0.0271]],

         [[-0.0791,  0.3575,  0.4194],
          [-0.0507,  0.2149, -0.3897],
          [-0.4077, -0.1626,  0.2224]],

         [[ 0.3446, -0.2777,  0.0613],
          [-0.0407, -0.2741,  0.2199],
          [ 0.3242,  0.3485, -0.3447]]]], device='cuda:0')
start training
18 epoch, 1 iter, loss 0.6611166000366211
18 epoch, 2 iter, loss 0.8118024468421936
18 epoch, 3 iter, loss 0.8338438868522644
18 epoch, 4 iter, loss 0.6393699645996094
18 epoch, 5 iter, loss 0.6265458464622498
18 epoch, 6 iter, loss 0.6923242211341858
18 epoch, 7 iter, loss 0.7615349888801575
18 epoch, 8 iter, loss 0.6211348176002502
18 epoch, 9 iter, loss 0.9348679184913635
18 epoch, 10 iter, loss 0.74430251121521
18 epoch, 11 iter, loss 0.6215416789054871
18 epoch, 12 iter, loss 0.7010909914970398
18 epoch, 13 iter, loss 0.44908493757247925
18 epoch, 14 iter, loss 0.7966133952140808
18 epoch, 15 iter, loss 0.6885675191879272
18 epoch, 16 iter, loss 0.7817606925964355
18 epoch, 17 iter, loss 0.6383727788925171
18 epoch, 18 iter, loss 1.010208010673523
18 epoch, 19 iter, loss 0.8602064847946167
18 epoch, 20 iter, loss 0.6733169555664062
18 epoch, 21 iter, loss 0.7315956950187683
18 epoch, 22 iter, loss 0.8125744462013245
18 epoch, 23 iter, loss 0.9234102368354797
18 epoch, 24 iter, loss 0.6597579121589661
18 epoch, 25 iter, loss 0.6896143555641174
18 epoch, 26 iter, loss 0.6379510164260864
18 epoch, 27 iter, loss 0.5033463835716248
18 epoch, 28 iter, loss 0.8302093148231506
18 epoch, 29 iter, loss 0.7037220001220703
18 epoch, 30 iter, loss 0.6999025344848633
18 epoch, 31 iter, loss 0.623289942741394
18 epoch, 32 iter, loss 0.6703880429267883
18 epoch, 33 iter, loss 0.8464571237564087
18 epoch, 34 iter, loss 0.8008686304092407
18 epoch, 35 iter, loss 0.775173544883728
18 epoch, 36 iter, loss 0.61751389503479
18 epoch, 37 iter, loss 0.7063060998916626
18 epoch, 38 iter, loss 0.6527945399284363
18 epoch, 39 iter, loss 0.632442057132721
18 epoch, 40 iter, loss 0.6064383387565613
18 epoch, 41 iter, loss 0.6025466322898865
18 epoch, 42 iter, loss 0.600971519947052
18 epoch, 43 iter, loss 0.6293706893920898
18 epoch, 44 iter, loss 1.030437707901001
18 epoch, 45 iter, loss 0.6674172282218933
18 epoch, 46 iter, loss 0.860806405544281
18 epoch, 47 iter, loss 0.8900999426841736
18 epoch, 48 iter, loss 0.6773167252540588
18 epoch, 49 iter, loss 0.8483486175537109
18 epoch, 50 iter, loss 0.714474081993103
18 epoch, 51 iter, loss 0.5538091659545898
18 epoch, 52 iter, loss 0.62907874584198
18 epoch, 53 iter, loss 0.843418538570404
18 epoch, 54 iter, loss 0.598656177520752
18 epoch, 55 iter, loss 0.6814957857131958
18 epoch, 56 iter, loss 0.7650368809700012
18 epoch, 57 iter, loss 0.9784474968910217
18 epoch, Average loss 0.7235630719285262
./model/merge_model_Param_v20.pth
some of decrypted state:
tensor([[[[ 0.0631, -0.0575,  0.0515],
          [ 0.1172,  0.1319,  0.0776],
          [-0.0980, -0.0877, -0.0079]],

         [[-0.0261,  0.1197,  0.1403],
          [-0.0154,  0.0733, -0.1285],
          [-0.1347, -0.0528,  0.0754]],

         [[ 0.1142, -0.0932,  0.0198],
          [-0.0127, -0.0902,  0.0739],
          [ 0.1082,  0.1165, -0.1144]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1894, -0.1726,  0.1546],
          [ 0.3516,  0.3957,  0.2329],
          [-0.2940, -0.2631, -0.0236]],

         [[-0.0782,  0.3591,  0.4208],
          [-0.0461,  0.2200, -0.3854],
          [-0.4042, -0.1585,  0.2262]],

         [[ 0.3426, -0.2795,  0.0595],
          [-0.0380, -0.2706,  0.2216],
          [ 0.3245,  0.3496, -0.3432]]]], device='cuda:0')
start training
19 epoch, 1 iter, loss 1.1385974884033203
19 epoch, 2 iter, loss 0.5232542157173157
19 epoch, 3 iter, loss 0.7216300368309021
19 epoch, 4 iter, loss 0.904240071773529
19 epoch, 5 iter, loss 0.7473087906837463
19 epoch, 6 iter, loss 0.6425343155860901
19 epoch, 7 iter, loss 0.5749502182006836
19 epoch, 8 iter, loss 0.7695751190185547
19 epoch, 9 iter, loss 0.9325741529464722
19 epoch, 10 iter, loss 0.8664326071739197
19 epoch, 11 iter, loss 0.5128443837165833
19 epoch, 12 iter, loss 0.6872625946998596
19 epoch, 13 iter, loss 0.7854739427566528
19 epoch, 14 iter, loss 0.6562226414680481
19 epoch, 15 iter, loss 0.8551047444343567
19 epoch, 16 iter, loss 0.61326003074646
19 epoch, 17 iter, loss 0.8702549934387207
19 epoch, 18 iter, loss 0.7178440690040588
19 epoch, 19 iter, loss 0.6330536603927612
19 epoch, 20 iter, loss 0.5497452616691589
19 epoch, 21 iter, loss 0.7549924850463867
19 epoch, 22 iter, loss 0.5575895309448242
19 epoch, 23 iter, loss 0.7928362488746643
19 epoch, 24 iter, loss 0.7446152567863464
19 epoch, 25 iter, loss 0.8300865292549133
19 epoch, 26 iter, loss 0.6930004358291626
19 epoch, 27 iter, loss 0.6651501059532166
19 epoch, 28 iter, loss 0.7851622700691223
19 epoch, 29 iter, loss 0.8037669062614441
19 epoch, 30 iter, loss 0.870934009552002
19 epoch, 31 iter, loss 0.7351018786430359
19 epoch, 32 iter, loss 0.9408155679702759
19 epoch, 33 iter, loss 0.7575274705886841
19 epoch, 34 iter, loss 0.6187079548835754
19 epoch, 35 iter, loss 0.6901572942733765
19 epoch, 36 iter, loss 0.7013134360313416
19 epoch, 37 iter, loss 0.9219014644622803
19 epoch, 38 iter, loss 0.6471314430236816
19 epoch, 39 iter, loss 0.8480386734008789
19 epoch, 40 iter, loss 0.7376576662063599
19 epoch, 41 iter, loss 0.7450960874557495
19 epoch, 42 iter, loss 0.7441046833992004
19 epoch, 43 iter, loss 0.7473527193069458
19 epoch, 44 iter, loss 0.8201975226402283
19 epoch, 45 iter, loss 0.9638912081718445
19 epoch, 46 iter, loss 0.7722789645195007
19 epoch, 47 iter, loss 0.6002033352851868
19 epoch, 48 iter, loss 0.6967170238494873
19 epoch, 49 iter, loss 0.5121771097183228
19 epoch, 50 iter, loss 0.8550122380256653
19 epoch, 51 iter, loss 0.7461763620376587
19 epoch, 52 iter, loss 0.5830108523368835
19 epoch, 53 iter, loss 0.48894134163856506
19 epoch, 54 iter, loss 0.7556719779968262
19 epoch, 55 iter, loss 0.5662577748298645
19 epoch, 56 iter, loss 0.7237467765808105
19 epoch, 57 iter, loss 0.7677744626998901
19 epoch, Average loss 0.7348642176703403
./model/merge_model_Param_v21.pth
some of decrypted state:
tensor([[[[ 0.0630, -0.0577,  0.0517],
          [ 0.1170,  0.1315,  0.0764],
          [-0.0991, -0.0888, -0.0091]],

         [[-0.0270,  0.1191,  0.1400],
          [-0.0162,  0.0724, -0.1300],
          [-0.1364, -0.0544,  0.0736]],

         [[ 0.1134, -0.0937,  0.0197],
          [-0.0130, -0.0908,  0.0725],
          [ 0.1068,  0.1152, -0.1157]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1891, -0.1731,  0.1550],
          [ 0.3511,  0.3946,  0.2293],
          [-0.2972, -0.2665, -0.0273]],

         [[-0.0810,  0.3572,  0.4200],
          [-0.0486,  0.2171, -0.3899],
          [-0.4092, -0.1633,  0.2208]],

         [[ 0.3402, -0.2811,  0.0592],
          [-0.0389, -0.2723,  0.2175],
          [ 0.3204,  0.3456, -0.3472]]]], device='cuda:0')
start training
20 epoch, 1 iter, loss 0.6580369472503662
20 epoch, 2 iter, loss 0.7723883986473083
20 epoch, 3 iter, loss 0.746684193611145
20 epoch, 4 iter, loss 0.6388702988624573
20 epoch, 5 iter, loss 0.7056180834770203
20 epoch, 6 iter, loss 0.7436872124671936
20 epoch, 7 iter, loss 0.7404240369796753
20 epoch, 8 iter, loss 0.7269246578216553
20 epoch, 9 iter, loss 0.7689725160598755
20 epoch, 10 iter, loss 0.6430521011352539
20 epoch, 11 iter, loss 0.5620318651199341
20 epoch, 12 iter, loss 0.696675181388855
20 epoch, 13 iter, loss 0.7226237058639526
20 epoch, 14 iter, loss 0.745274007320404
20 epoch, 15 iter, loss 0.5565142035484314
20 epoch, 16 iter, loss 0.7559239268302917
20 epoch, 17 iter, loss 0.6306411623954773
20 epoch, 18 iter, loss 0.7203846573829651
20 epoch, 19 iter, loss 1.0948171615600586
20 epoch, 20 iter, loss 0.6073815226554871
20 epoch, 21 iter, loss 0.5550654530525208
20 epoch, 22 iter, loss 0.7664861679077148
20 epoch, 23 iter, loss 0.6009305715560913
20 epoch, 24 iter, loss 0.44782477617263794
20 epoch, 25 iter, loss 0.7290250658988953
20 epoch, 26 iter, loss 0.8877752423286438
20 epoch, 27 iter, loss 0.5845013856887817
20 epoch, 28 iter, loss 0.5970157384872437
20 epoch, 29 iter, loss 0.6752188801765442
20 epoch, 30 iter, loss 0.8354634642601013
20 epoch, 31 iter, loss 0.48257559537887573
20 epoch, 32 iter, loss 0.9556233286857605
20 epoch, 33 iter, loss 0.655392587184906
20 epoch, 34 iter, loss 0.6447432637214661
20 epoch, 35 iter, loss 0.5612645745277405
20 epoch, 36 iter, loss 0.6122527122497559
20 epoch, 37 iter, loss 0.7362834215164185
20 epoch, 38 iter, loss 0.8603298664093018
20 epoch, 39 iter, loss 0.7730896472930908
20 epoch, 40 iter, loss 0.8420711755752563
20 epoch, 41 iter, loss 0.8833160996437073
20 epoch, 42 iter, loss 0.6560529470443726
20 epoch, 43 iter, loss 0.6712585091590881
20 epoch, 44 iter, loss 0.684071958065033
20 epoch, 45 iter, loss 0.7064699530601501
20 epoch, 46 iter, loss 0.5439268350601196
20 epoch, 47 iter, loss 0.6009126901626587
20 epoch, 48 iter, loss 0.6405307054519653
20 epoch, 49 iter, loss 0.7395882606506348
20 epoch, 50 iter, loss 0.83180171251297
20 epoch, 51 iter, loss 0.6109070181846619
20 epoch, 52 iter, loss 0.692840576171875
20 epoch, 53 iter, loss 0.7090068459510803
20 epoch, 54 iter, loss 0.8189433813095093
20 epoch, 55 iter, loss 0.7040674090385437
20 epoch, 56 iter, loss 0.597822368144989
20 epoch, 57 iter, loss 0.773777961730957
20 epoch, Average loss 0.7000904208735416
./model/merge_model_Param_v22.pth
some of decrypted state:
tensor([[[[ 0.0633, -0.0576,  0.0519],
          [ 0.1189,  0.1332,  0.0778],
          [-0.0980, -0.0878, -0.0082]],

         [[-0.0272,  0.1187,  0.1400],
          [-0.0148,  0.0737, -0.1289],
          [-0.1359, -0.0539,  0.0740]],

         [[ 0.1122, -0.0949,  0.0191],
          [-0.0119, -0.0896,  0.0731],
          [ 0.1070,  0.1153, -0.1158]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1899, -0.1729,  0.1557],
          [ 0.3567,  0.3995,  0.2334],
          [-0.2939, -0.2635, -0.0245]],

         [[-0.0817,  0.3562,  0.4200],
          [-0.0443,  0.2210, -0.3867],
          [-0.4077, -0.1617,  0.2220]],

         [[ 0.3365, -0.2847,  0.0573],
          [-0.0357, -0.2688,  0.2194],
          [ 0.3209,  0.3459, -0.3473]]]], device='cuda:0')
start training
21 epoch, 1 iter, loss 0.850134015083313
21 epoch, 2 iter, loss 0.8998453617095947
21 epoch, 3 iter, loss 0.6843166947364807
21 epoch, 4 iter, loss 0.7273953557014465
21 epoch, 5 iter, loss 0.7614021301269531
21 epoch, 6 iter, loss 0.6466192007064819
21 epoch, 7 iter, loss 0.5711547136306763
21 epoch, 8 iter, loss 0.7378562688827515
21 epoch, 9 iter, loss 0.7534246444702148
21 epoch, 10 iter, loss 0.7873627543449402
21 epoch, 11 iter, loss 0.695483922958374
21 epoch, 12 iter, loss 0.7181423902511597
21 epoch, 13 iter, loss 0.7496899366378784
21 epoch, 14 iter, loss 0.5882382988929749
21 epoch, 15 iter, loss 0.9038142561912537
21 epoch, 16 iter, loss 0.5569106340408325
21 epoch, 17 iter, loss 0.7614566087722778
21 epoch, 18 iter, loss 0.8009084463119507
21 epoch, 19 iter, loss 0.6672598719596863
21 epoch, 20 iter, loss 0.7996821999549866
21 epoch, 21 iter, loss 0.7485224604606628
21 epoch, 22 iter, loss 0.6033666729927063
21 epoch, 23 iter, loss 0.5292901992797852
21 epoch, 24 iter, loss 0.6847369074821472
21 epoch, 25 iter, loss 0.5442838668823242
21 epoch, 26 iter, loss 0.6777103543281555
21 epoch, 27 iter, loss 0.775507926940918
21 epoch, 28 iter, loss 0.8204895257949829
21 epoch, 29 iter, loss 0.979661762714386
21 epoch, 30 iter, loss 0.5338940024375916
21 epoch, 31 iter, loss 0.6712441444396973
21 epoch, 32 iter, loss 0.8743641376495361
21 epoch, 33 iter, loss 0.7798802852630615
21 epoch, 34 iter, loss 0.7639090418815613
21 epoch, 35 iter, loss 0.8210098147392273
21 epoch, 36 iter, loss 0.7103622555732727
21 epoch, 37 iter, loss 0.7020440697669983
21 epoch, 38 iter, loss 0.8696586489677429
21 epoch, 39 iter, loss 0.8383200764656067
21 epoch, 40 iter, loss 0.5982306003570557
21 epoch, 41 iter, loss 0.6215420365333557
21 epoch, 42 iter, loss 0.8178410530090332
21 epoch, 43 iter, loss 0.9453798532485962
21 epoch, 44 iter, loss 0.683452308177948
21 epoch, 45 iter, loss 0.9822361469268799
21 epoch, 46 iter, loss 0.7490250468254089
21 epoch, 47 iter, loss 0.6471970677375793
21 epoch, 48 iter, loss 0.9083980917930603
21 epoch, 49 iter, loss 0.6043113470077515
21 epoch, 50 iter, loss 0.7638399600982666
21 epoch, 51 iter, loss 1.2201271057128906
21 epoch, 52 iter, loss 0.8057562112808228
21 epoch, 53 iter, loss 0.582276463508606
21 epoch, 54 iter, loss 0.7264068722724915
21 epoch, 55 iter, loss 0.8602901101112366
21 epoch, 56 iter, loss 0.6570886969566345
21 epoch, 57 iter, loss 0.7839118838310242
21 epoch, Average loss 0.7464327142949689
./model/merge_model_Param_v23.pth
some of decrypted state:
tensor([[[[ 0.0635, -0.0567,  0.0534],
          [ 0.1198,  0.1341,  0.0782],
          [-0.0969, -0.0866, -0.0071]],

         [[-0.0277,  0.1193,  0.1410],
          [-0.0143,  0.0744, -0.1286],
          [-0.1352, -0.0528,  0.0749]],

         [[ 0.1114, -0.0949,  0.0197],
          [-0.0115, -0.0890,  0.0733],
          [ 0.1074,  0.1160, -0.1151]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1906, -0.1700,  0.1601],
          [ 0.3593,  0.4023,  0.2346],
          [-0.2907, -0.2598, -0.0213]],

         [[-0.0831,  0.3578,  0.4229],
          [-0.0429,  0.2233, -0.3858],
          [-0.4057, -0.1585,  0.2247]],

         [[ 0.3341, -0.2847,  0.0591],
          [-0.0346, -0.2669,  0.2200],
          [ 0.3223,  0.3481, -0.3454]]]], device='cuda:0')
start training
22 epoch, 1 iter, loss 0.673632025718689
22 epoch, 2 iter, loss 0.45300301909446716
22 epoch, 3 iter, loss 0.9431685209274292
22 epoch, 4 iter, loss 0.6594185829162598
22 epoch, 5 iter, loss 1.0313243865966797
22 epoch, 6 iter, loss 0.8349021077156067
22 epoch, 7 iter, loss 0.9788838624954224
22 epoch, 8 iter, loss 0.5754210948944092
22 epoch, 9 iter, loss 0.5109057426452637
22 epoch, 10 iter, loss 0.6221945285797119
22 epoch, 11 iter, loss 0.5864497423171997
22 epoch, 12 iter, loss 0.7565957307815552
22 epoch, 13 iter, loss 0.7123632431030273
22 epoch, 14 iter, loss 0.7985780239105225
22 epoch, 15 iter, loss 0.7557328343391418
22 epoch, 16 iter, loss 0.6540499925613403
22 epoch, 17 iter, loss 0.585557222366333
22 epoch, 18 iter, loss 0.4406273365020752
22 epoch, 19 iter, loss 0.6617149710655212
22 epoch, 20 iter, loss 0.8718792796134949
22 epoch, 21 iter, loss 0.6074090600013733
22 epoch, 22 iter, loss 0.7388338446617126
22 epoch, 23 iter, loss 0.519224226474762
22 epoch, 24 iter, loss 0.6724244952201843
22 epoch, 25 iter, loss 0.7226244211196899
22 epoch, 26 iter, loss 0.6933116316795349
22 epoch, 27 iter, loss 0.7876654267311096
22 epoch, 28 iter, loss 0.7232615351676941
22 epoch, 29 iter, loss 0.7558466792106628
22 epoch, 30 iter, loss 0.7673954963684082
22 epoch, 31 iter, loss 0.7521370053291321
22 epoch, 32 iter, loss 0.7524643540382385
22 epoch, 33 iter, loss 0.6950820088386536
22 epoch, 34 iter, loss 0.8764016628265381
22 epoch, 35 iter, loss 0.6891055703163147
22 epoch, 36 iter, loss 0.750774621963501
22 epoch, 37 iter, loss 0.620724081993103
22 epoch, 38 iter, loss 0.6239641308784485
22 epoch, 39 iter, loss 0.698517918586731
22 epoch, 40 iter, loss 0.7197319269180298
22 epoch, 41 iter, loss 0.6090894341468811
22 epoch, 42 iter, loss 0.5274239778518677
22 epoch, 43 iter, loss 0.7477539777755737
22 epoch, 44 iter, loss 0.7071837782859802
22 epoch, 45 iter, loss 0.8071502447128296
22 epoch, 46 iter, loss 0.4776841998100281
22 epoch, 47 iter, loss 0.8137524724006653
22 epoch, 48 iter, loss 0.3499719798564911
22 epoch, 49 iter, loss 0.7435776591300964
22 epoch, 50 iter, loss 0.6874420642852783
22 epoch, 51 iter, loss 0.7528439164161682
22 epoch, 52 iter, loss 0.5649524331092834
22 epoch, 53 iter, loss 0.6507310271263123
22 epoch, 54 iter, loss 0.5774314403533936
22 epoch, 55 iter, loss 0.718304455280304
22 epoch, 56 iter, loss 0.6255835890769958
22 epoch, 57 iter, loss 0.5432295799255371
22 epoch, Average loss 0.6873229574738887
./model/merge_model_Param_v24.pth
some of decrypted state:
tensor([[[[ 0.0631, -0.0572,  0.0527],
          [ 0.1192,  0.1333,  0.0768],
          [-0.0988, -0.0888, -0.0093]],

         [[-0.0280,  0.1189,  0.1403],
          [-0.0152,  0.0736, -0.1300],
          [-0.1372, -0.0550,  0.0727]],

         [[ 0.1110, -0.0954,  0.0192],
          [-0.0120, -0.0893,  0.0722],
          [ 0.1057,  0.1142, -0.1169]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1894, -0.1717,  0.1581],
          [ 0.3575,  0.3999,  0.2304],
          [-0.2964, -0.2664, -0.0280]],

         [[-0.0840,  0.3568,  0.4210],
          [-0.0455,  0.2208, -0.3900],
          [-0.4116, -0.1649,  0.2180]],

         [[ 0.3329, -0.2863,  0.0576],
          [-0.0361, -0.2680,  0.2167],
          [ 0.3172,  0.3427, -0.3508]]]], device='cuda:0')
start training
23 epoch, 1 iter, loss 0.8317102789878845
23 epoch, 2 iter, loss 0.65815669298172
23 epoch, 3 iter, loss 0.5669466853141785
23 epoch, 4 iter, loss 0.5409626960754395
23 epoch, 5 iter, loss 0.712734580039978
23 epoch, 6 iter, loss 0.6541974544525146
23 epoch, 7 iter, loss 0.6417971849441528
23 epoch, 8 iter, loss 0.53347247838974
23 epoch, 9 iter, loss 0.6627200245857239
23 epoch, 10 iter, loss 0.9464980959892273
23 epoch, 11 iter, loss 0.47808143496513367
23 epoch, 12 iter, loss 0.663679301738739
23 epoch, 13 iter, loss 0.73685222864151
23 epoch, 14 iter, loss 0.6467308402061462
23 epoch, 15 iter, loss 0.5654653310775757
23 epoch, 16 iter, loss 0.5859133005142212
23 epoch, 17 iter, loss 0.6000900864601135
23 epoch, 18 iter, loss 0.6719287633895874
23 epoch, 19 iter, loss 0.7589825987815857
23 epoch, 20 iter, loss 0.763773500919342
23 epoch, 21 iter, loss 0.8011649250984192
23 epoch, 22 iter, loss 0.5869441628456116
23 epoch, 23 iter, loss 0.8022001385688782
23 epoch, 24 iter, loss 0.5417261719703674
23 epoch, 25 iter, loss 0.5003948211669922
23 epoch, 26 iter, loss 0.6033656001091003
23 epoch, 27 iter, loss 0.6406326293945312
23 epoch, 28 iter, loss 0.5582384467124939
23 epoch, 29 iter, loss 0.667192816734314
23 epoch, 30 iter, loss 0.7636812329292297
23 epoch, 31 iter, loss 0.6987130045890808
23 epoch, 32 iter, loss 0.7398539781570435
23 epoch, 33 iter, loss 0.5497947931289673
23 epoch, 34 iter, loss 0.7255648970603943
23 epoch, 35 iter, loss 0.7589542865753174
23 epoch, 36 iter, loss 0.7044513821601868
23 epoch, 37 iter, loss 0.6859781742095947
23 epoch, 38 iter, loss 0.6584805846214294
23 epoch, 39 iter, loss 0.7087131142616272
23 epoch, 40 iter, loss 0.705622673034668
23 epoch, 41 iter, loss 0.6733514070510864
23 epoch, 42 iter, loss 0.6380259990692139
23 epoch, 43 iter, loss 0.5760329961776733
23 epoch, 44 iter, loss 0.6293933391571045
23 epoch, 45 iter, loss 0.8526744842529297
23 epoch, 46 iter, loss 0.8875231742858887
23 epoch, 47 iter, loss 0.654890239238739
23 epoch, 48 iter, loss 0.6655073165893555
23 epoch, 49 iter, loss 0.5184164643287659
23 epoch, 50 iter, loss 0.6320348978042603
23 epoch, 51 iter, loss 0.7660967707633972
23 epoch, 52 iter, loss 0.7705021500587463
23 epoch, 53 iter, loss 0.5306408405303955
23 epoch, 54 iter, loss 0.7114471197128296
23 epoch, 55 iter, loss 0.7185478210449219
23 epoch, 56 iter, loss 0.6243441104888916
23 epoch, 57 iter, loss 0.6513404846191406
23 epoch, Average loss 0.6688268597711596
./model/merge_model_Param_v25.pth
some of decrypted state:
tensor([[[[ 0.0640, -0.0561,  0.0532],
          [ 0.1206,  0.1344,  0.0775],
          [-0.0971, -0.0875, -0.0084]],

         [[-0.0273,  0.1198,  0.1407],
          [-0.0140,  0.0746, -0.1293],
          [-0.1357, -0.0538,  0.0732]],

         [[ 0.1115, -0.0948,  0.0195],
          [-0.0104, -0.0878,  0.0732],
          [ 0.1075,  0.1157, -0.1160]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1920, -0.1682,  0.1596],
          [ 0.3618,  0.4033,  0.2326],
          [-0.2912, -0.2626, -0.0253]],

         [[-0.0819,  0.3595,  0.4220],
          [-0.0420,  0.2238, -0.3879],
          [-0.4072, -0.1615,  0.2197]],

         [[ 0.3346, -0.2843,  0.0585],
          [-0.0311, -0.2634,  0.2197],
          [ 0.3225,  0.3470, -0.3480]]]], device='cuda:0')
start training
24 epoch, 1 iter, loss 0.6697492599487305
24 epoch, 2 iter, loss 0.6522886753082275
24 epoch, 3 iter, loss 0.9543412923812866
24 epoch, 4 iter, loss 1.0452542304992676
24 epoch, 5 iter, loss 0.5189492106437683
24 epoch, 6 iter, loss 0.6778967976570129
24 epoch, 7 iter, loss 0.49350401759147644
24 epoch, 8 iter, loss 0.5638110041618347
24 epoch, 9 iter, loss 0.513945460319519
24 epoch, 10 iter, loss 0.7180564999580383
24 epoch, 11 iter, loss 0.5651835203170776
24 epoch, 12 iter, loss 0.7062246203422546
24 epoch, 13 iter, loss 0.4707315266132355
24 epoch, 14 iter, loss 0.56088787317276
24 epoch, 15 iter, loss 0.9292160868644714
24 epoch, 16 iter, loss 0.6816772818565369
24 epoch, 17 iter, loss 0.49512091279029846
24 epoch, 18 iter, loss 0.6939852237701416
24 epoch, 19 iter, loss 0.6147155165672302
24 epoch, 20 iter, loss 0.6968705058097839
24 epoch, 21 iter, loss 0.7931225299835205
24 epoch, 22 iter, loss 0.7121981978416443
24 epoch, 23 iter, loss 0.6563154458999634
24 epoch, 24 iter, loss 0.681644856929779
24 epoch, 25 iter, loss 0.7847694754600525
24 epoch, 26 iter, loss 0.8000150918960571
24 epoch, 27 iter, loss 0.6837378740310669
24 epoch, 28 iter, loss 0.5656803846359253
24 epoch, 29 iter, loss 0.4882594645023346
24 epoch, 30 iter, loss 0.6564092040061951
24 epoch, 31 iter, loss 0.6407749056816101
24 epoch, 32 iter, loss 0.6482688784599304
24 epoch, 33 iter, loss 0.6005739569664001
24 epoch, 34 iter, loss 0.9202806949615479
24 epoch, 35 iter, loss 0.842013418674469
24 epoch, 36 iter, loss 0.5557159185409546
24 epoch, 37 iter, loss 0.7209609746932983
24 epoch, 38 iter, loss 0.6823266744613647
24 epoch, 39 iter, loss 0.6607750654220581
24 epoch, 40 iter, loss 0.5985475778579712
24 epoch, 41 iter, loss 0.7081038951873779
24 epoch, 42 iter, loss 0.7064588069915771
24 epoch, 43 iter, loss 0.7857690453529358
24 epoch, 44 iter, loss 0.5498855113983154
24 epoch, 45 iter, loss 0.8527619242668152
24 epoch, 46 iter, loss 0.724433422088623
24 epoch, 47 iter, loss 0.8002098798751831
24 epoch, 48 iter, loss 0.7675530910491943
24 epoch, 49 iter, loss 0.9283519387245178
24 epoch, 50 iter, loss 0.7520031332969666
24 epoch, 51 iter, loss 0.7287114262580872
24 epoch, 52 iter, loss 0.6549574136734009
24 epoch, 53 iter, loss 0.5959783792495728
24 epoch, 54 iter, loss 0.5025997161865234
24 epoch, 55 iter, loss 0.6739506125450134
24 epoch, 56 iter, loss 0.6968632936477661
24 epoch, 57 iter, loss 0.4586668312549591
24 epoch, Average loss 0.6807378671671215
./model/merge_model_Param_v26.pth
some of decrypted state:
tensor([[[[ 0.0644, -0.0559,  0.0527],
          [ 0.1209,  0.1346,  0.0776],
          [-0.0980, -0.0886, -0.0096]],

         [[-0.0274,  0.1195,  0.1397],
          [-0.0144,  0.0741, -0.1299],
          [-0.1377, -0.0559,  0.0712]],

         [[ 0.1107, -0.0958,  0.0180],
          [-0.0111, -0.0884,  0.0722],
          [ 0.1046,  0.1128, -0.1185]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1932, -0.1677,  0.1581],
          [ 0.3628,  0.4039,  0.2327],
          [-0.2941, -0.2659, -0.0288]],

         [[-0.0822,  0.3585,  0.4191],
          [-0.0433,  0.2222, -0.3897],
          [-0.4131, -0.1676,  0.2136]],

         [[ 0.3322, -0.2873,  0.0540],
          [-0.0334, -0.2653,  0.2166],
          [ 0.3139,  0.3384, -0.3555]]]], device='cuda:0')
start training
25 epoch, 1 iter, loss 0.8235889673233032
25 epoch, 2 iter, loss 0.6748512387275696
25 epoch, 3 iter, loss 0.9704068899154663
25 epoch, 4 iter, loss 0.8581278324127197
25 epoch, 5 iter, loss 0.6766505241394043
25 epoch, 6 iter, loss 0.694286584854126
25 epoch, 7 iter, loss 0.69374018907547
25 epoch, 8 iter, loss 0.5664581656455994
25 epoch, 9 iter, loss 0.6163989305496216
25 epoch, 10 iter, loss 0.5039727687835693
25 epoch, 11 iter, loss 0.7723534107208252
25 epoch, 12 iter, loss 0.7059918642044067
25 epoch, 13 iter, loss 0.7743597626686096
25 epoch, 14 iter, loss 0.8052114844322205
25 epoch, 15 iter, loss 0.6084911823272705
25 epoch, 16 iter, loss 0.6623003482818604
25 epoch, 17 iter, loss 0.6788830757141113
25 epoch, 18 iter, loss 0.8022743463516235
25 epoch, 19 iter, loss 0.6152005791664124
25 epoch, 20 iter, loss 0.695816695690155
25 epoch, 21 iter, loss 0.776303768157959
25 epoch, 22 iter, loss 0.6696559190750122
25 epoch, 23 iter, loss 0.6514351963996887
25 epoch, 24 iter, loss 0.8995797038078308
25 epoch, 25 iter, loss 0.7594160437583923
25 epoch, 26 iter, loss 0.7632474899291992
25 epoch, 27 iter, loss 0.5426152944564819
25 epoch, 28 iter, loss 0.7987833619117737
25 epoch, 29 iter, loss 0.5310847759246826
25 epoch, 30 iter, loss 0.5964471101760864
25 epoch, 31 iter, loss 0.4296855032444
25 epoch, 32 iter, loss 0.6825493574142456
25 epoch, 33 iter, loss 0.8420916795730591
25 epoch, 34 iter, loss 0.636672854423523
25 epoch, 35 iter, loss 0.8095906376838684
25 epoch, 36 iter, loss 0.6292303204536438
25 epoch, 37 iter, loss 0.7036268711090088
25 epoch, 38 iter, loss 0.7879878282546997
25 epoch, 39 iter, loss 0.7805858254432678
25 epoch, 40 iter, loss 0.5785390734672546
25 epoch, 41 iter, loss 0.5559832453727722
25 epoch, 42 iter, loss 0.6854119300842285
25 epoch, 43 iter, loss 0.6272822022438049
25 epoch, 44 iter, loss 0.6793177127838135
25 epoch, 45 iter, loss 0.7743018865585327
25 epoch, 46 iter, loss 0.5745733380317688
25 epoch, 47 iter, loss 0.6160050630569458
25 epoch, 48 iter, loss 0.5972253680229187
25 epoch, 49 iter, loss 0.5570544600486755
25 epoch, 50 iter, loss 0.5479465126991272
25 epoch, 51 iter, loss 0.6499048471450806
25 epoch, 52 iter, loss 0.7685043811798096
25 epoch, 53 iter, loss 0.8812367916107178
25 epoch, 54 iter, loss 0.5889999270439148
25 epoch, 55 iter, loss 0.7530211210250854
25 epoch, 56 iter, loss 0.5767347812652588
25 epoch, 57 iter, loss 0.4750709533691406
25 epoch, Average loss 0.6838082101261407
./model/merge_model_Param_v27.pth
some of decrypted state:
tensor([[[[ 0.0643, -0.0560,  0.0528],
          [ 0.1224,  0.1360,  0.0791],
          [-0.0966, -0.0876, -0.0092]],

         [[-0.0275,  0.1194,  0.1398],
          [-0.0131,  0.0754, -0.1284],
          [-0.1362, -0.0547,  0.0719]],

         [[ 0.1103, -0.0962,  0.0179],
          [-0.0098, -0.0870,  0.0736],
          [ 0.1060,  0.1140, -0.1176]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1928, -0.1679,  0.1585],
          [ 0.3672,  0.4081,  0.2372],
          [-0.2897, -0.2627, -0.0275]],

         [[-0.0825,  0.3582,  0.4195],
          [-0.0392,  0.2263, -0.3853],
          [-0.4087, -0.1640,  0.2158]],

         [[ 0.3309, -0.2885,  0.0538],
          [-0.0295, -0.2611,  0.2207],
          [ 0.3181,  0.3421, -0.3528]]]], device='cuda:0')
start training
26 epoch, 1 iter, loss 0.7645933628082275
26 epoch, 2 iter, loss 0.8076019287109375
26 epoch, 3 iter, loss 0.6375213861465454
26 epoch, 4 iter, loss 0.5329626798629761
26 epoch, 5 iter, loss 0.4991644024848938
26 epoch, 6 iter, loss 0.9305508136749268
26 epoch, 7 iter, loss 0.6337954998016357
26 epoch, 8 iter, loss 0.5061638355255127
26 epoch, 9 iter, loss 0.7385352849960327
26 epoch, 10 iter, loss 0.5467307567596436
26 epoch, 11 iter, loss 0.5414687991142273
26 epoch, 12 iter, loss 0.5664398074150085
26 epoch, 13 iter, loss 0.7172128558158875
26 epoch, 14 iter, loss 0.7903237342834473
26 epoch, 15 iter, loss 0.7328237295150757
26 epoch, 16 iter, loss 0.8435071706771851
26 epoch, 17 iter, loss 0.8630699515342712
26 epoch, 18 iter, loss 0.5630470514297485
26 epoch, 19 iter, loss 0.6738594770431519
26 epoch, 20 iter, loss 0.7101887464523315
26 epoch, 21 iter, loss 0.5196739435195923
26 epoch, 22 iter, loss 0.5796343088150024
26 epoch, 23 iter, loss 0.7241466045379639
26 epoch, 24 iter, loss 0.721160888671875
26 epoch, 25 iter, loss 0.6151670813560486
26 epoch, 26 iter, loss 0.6415475010871887
26 epoch, 27 iter, loss 0.6428692936897278
26 epoch, 28 iter, loss 0.5542119145393372
26 epoch, 29 iter, loss 0.738006055355072
26 epoch, 30 iter, loss 0.5726943016052246
26 epoch, 31 iter, loss 0.6942132711410522
26 epoch, 32 iter, loss 0.6076858043670654
26 epoch, 33 iter, loss 0.8089087605476379
26 epoch, 34 iter, loss 0.5346688032150269
26 epoch, 35 iter, loss 0.748275637626648
26 epoch, 36 iter, loss 0.6775068044662476
26 epoch, 37 iter, loss 0.6479312181472778
26 epoch, 38 iter, loss 0.7696210145950317
26 epoch, 39 iter, loss 0.6591368317604065
26 epoch, 40 iter, loss 0.7816863656044006
26 epoch, 41 iter, loss 0.9831626415252686
26 epoch, 42 iter, loss 0.4751266539096832
26 epoch, 43 iter, loss 0.3814550042152405
26 epoch, 44 iter, loss 0.5205756425857544
26 epoch, 45 iter, loss 0.7187012434005737
26 epoch, 46 iter, loss 0.6136466860771179
26 epoch, 47 iter, loss 0.4562356173992157
26 epoch, 48 iter, loss 0.5281955003738403
26 epoch, 49 iter, loss 0.8829596042633057
26 epoch, 50 iter, loss 0.6253878474235535
26 epoch, 51 iter, loss 0.7505274415016174
26 epoch, 52 iter, loss 0.6488860845565796
26 epoch, 53 iter, loss 0.4759703576564789
26 epoch, 54 iter, loss 0.4728679955005646
26 epoch, 55 iter, loss 0.717445969581604
26 epoch, 56 iter, loss 0.7066425681114197
26 epoch, 57 iter, loss 0.7601423263549805
26 epoch, Average loss 0.6588813484760753
./model/merge_model_Param_v28.pth
some of decrypted state:
tensor([[[[ 0.0641, -0.0558,  0.0526],
          [ 0.1224,  0.1365,  0.0797],
          [-0.0971, -0.0878, -0.0093]],

         [[-0.0280,  0.1193,  0.1392],
          [-0.0134,  0.0756, -0.1281],
          [-0.1373, -0.0553,  0.0714]],

         [[ 0.1098, -0.0964,  0.0174],
          [-0.0098, -0.0864,  0.0743],
          [ 0.1052,  0.1136, -0.1180]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1922, -0.1673,  0.1577],
          [ 0.3673,  0.4096,  0.2392],
          [-0.2913, -0.2633, -0.0278]],

         [[-0.0841,  0.3580,  0.4175],
          [-0.0401,  0.2269, -0.3843],
          [-0.4118, -0.1659,  0.2142]],

         [[ 0.3293, -0.2891,  0.0521],
          [-0.0293, -0.2592,  0.2229],
          [ 0.3155,  0.3409, -0.3539]]]], device='cuda:0')
start training
27 epoch, 1 iter, loss 0.798458993434906
27 epoch, 2 iter, loss 0.8794894218444824
27 epoch, 3 iter, loss 0.8165480494499207
27 epoch, 4 iter, loss 0.6107298731803894
27 epoch, 5 iter, loss 0.5403947830200195
27 epoch, 6 iter, loss 0.5362304449081421
27 epoch, 7 iter, loss 0.5209693908691406
27 epoch, 8 iter, loss 0.8211917281150818
27 epoch, 9 iter, loss 0.5579656362533569
27 epoch, 10 iter, loss 0.4848337173461914
27 epoch, 11 iter, loss 0.5541888475418091
27 epoch, 12 iter, loss 0.6965535283088684
27 epoch, 13 iter, loss 0.5116908550262451
27 epoch, 14 iter, loss 0.6777511239051819
27 epoch, 15 iter, loss 0.6584807634353638
27 epoch, 16 iter, loss 0.7449378371238708
27 epoch, 17 iter, loss 0.6354193687438965
27 epoch, 18 iter, loss 0.5739672183990479
27 epoch, 19 iter, loss 0.6429293751716614
27 epoch, 20 iter, loss 0.7201607823371887
27 epoch, 21 iter, loss 0.7119638919830322
27 epoch, 22 iter, loss 0.58497554063797
27 epoch, 23 iter, loss 0.6393262147903442
27 epoch, 24 iter, loss 0.7123618125915527
27 epoch, 25 iter, loss 0.8061853051185608
27 epoch, 26 iter, loss 0.5652451515197754
27 epoch, 27 iter, loss 0.5227466225624084
27 epoch, 28 iter, loss 0.7255829572677612
27 epoch, 29 iter, loss 0.5744284987449646
27 epoch, 30 iter, loss 0.6232576370239258
27 epoch, 31 iter, loss 0.7525011897087097
27 epoch, 32 iter, loss 0.3587394952774048
27 epoch, 33 iter, loss 0.8485752940177917
27 epoch, 34 iter, loss 0.7474658489227295
27 epoch, 35 iter, loss 0.6579138040542603
27 epoch, 36 iter, loss 0.6140273213386536
27 epoch, 37 iter, loss 0.7175913453102112
27 epoch, 38 iter, loss 0.685150682926178
27 epoch, 39 iter, loss 0.7142802476882935
27 epoch, 40 iter, loss 0.6497723460197449
27 epoch, 41 iter, loss 0.5083127617835999
27 epoch, 42 iter, loss 0.6965908408164978
27 epoch, 43 iter, loss 0.9089208841323853
27 epoch, 44 iter, loss 0.643804669380188
27 epoch, 45 iter, loss 0.4532228708267212
27 epoch, 46 iter, loss 0.6433084607124329
27 epoch, 47 iter, loss 0.8407114744186401
27 epoch, 48 iter, loss 0.6767422556877136
27 epoch, 49 iter, loss 0.626481831073761
27 epoch, 50 iter, loss 0.8186583518981934
27 epoch, 51 iter, loss 0.6433977484703064
27 epoch, 52 iter, loss 0.5509754419326782
27 epoch, 53 iter, loss 0.5257766842842102
27 epoch, 54 iter, loss 0.5963492393493652
27 epoch, 55 iter, loss 0.5118235945701599
27 epoch, 56 iter, loss 0.8058503270149231
27 epoch, 57 iter, loss 0.8972353339195251
27 epoch, Average loss 0.6586516792314094
./model/merge_model_Param_v29.pth
some of decrypted state:
tensor([[[[ 0.0637, -0.0560,  0.0522],
          [ 0.1230,  0.1364,  0.0788],
          [-0.0981, -0.0891, -0.0108]],

         [[-0.0285,  0.1193,  0.1389],
          [-0.0128,  0.0756, -0.1289],
          [-0.1384, -0.0567,  0.0698]],

         [[ 0.1086, -0.0971,  0.0165],
          [-0.0098, -0.0870,  0.0726],
          [ 0.1036,  0.1117, -0.1200]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1911, -0.1680,  0.1567],
          [ 0.3690,  0.4093,  0.2364],
          [-0.2944, -0.2673, -0.0323]],

         [[-0.0854,  0.3578,  0.4168],
          [-0.0383,  0.2268, -0.3867],
          [-0.4152, -0.1700,  0.2094]],

         [[ 0.3259, -0.2913,  0.0496],
          [-0.0295, -0.2610,  0.2178],
          [ 0.3109,  0.3351, -0.3599]]]], device='cuda:0')
start training
28 epoch, 1 iter, loss 0.7816100716590881
28 epoch, 2 iter, loss 0.645088791847229
28 epoch, 3 iter, loss 0.642182469367981
28 epoch, 4 iter, loss 0.5974822640419006
28 epoch, 5 iter, loss 0.6509326100349426
28 epoch, 6 iter, loss 0.7208372354507446
28 epoch, 7 iter, loss 0.6770663261413574
28 epoch, 8 iter, loss 0.6926401853561401
28 epoch, 9 iter, loss 0.6172344088554382
28 epoch, 10 iter, loss 0.6268056035041809
28 epoch, 11 iter, loss 0.547473132610321
28 epoch, 12 iter, loss 0.44946447014808655
28 epoch, 13 iter, loss 0.8114126920700073
28 epoch, 14 iter, loss 0.5093922019004822
28 epoch, 15 iter, loss 0.6484774351119995
28 epoch, 16 iter, loss 0.7794150114059448
28 epoch, 17 iter, loss 0.5601268410682678
28 epoch, 18 iter, loss 0.8239913582801819
28 epoch, 19 iter, loss 0.5578616261482239
28 epoch, 20 iter, loss 0.6993539333343506
28 epoch, 21 iter, loss 0.4838714897632599
28 epoch, 22 iter, loss 0.44328030943870544
28 epoch, 23 iter, loss 0.7561196684837341
28 epoch, 24 iter, loss 0.5792713761329651
28 epoch, 25 iter, loss 0.6520494818687439
28 epoch, 26 iter, loss 0.5709412693977356
28 epoch, 27 iter, loss 0.8765643835067749
28 epoch, 28 iter, loss 0.7867361903190613
28 epoch, 29 iter, loss 0.5290457010269165
28 epoch, 30 iter, loss 0.5471333861351013
28 epoch, 31 iter, loss 0.564693808555603
28 epoch, 32 iter, loss 0.5743133425712585
28 epoch, 33 iter, loss 0.4515438377857208
28 epoch, 34 iter, loss 0.7783975601196289
28 epoch, 35 iter, loss 0.8891187310218811
28 epoch, 36 iter, loss 0.8906320929527283
28 epoch, 37 iter, loss 0.6894742250442505
28 epoch, 38 iter, loss 0.5737293362617493
28 epoch, 39 iter, loss 0.607587993144989
28 epoch, 40 iter, loss 0.736886203289032
28 epoch, 41 iter, loss 0.6462607979774475
28 epoch, 42 iter, loss 0.6772177219390869
28 epoch, 43 iter, loss 0.5740033984184265
28 epoch, 44 iter, loss 0.7531878352165222
28 epoch, 45 iter, loss 0.45164310932159424
28 epoch, 46 iter, loss 0.5553159117698669
28 epoch, 47 iter, loss 0.627196192741394
28 epoch, 48 iter, loss 0.6022979617118835
28 epoch, 49 iter, loss 0.5115315318107605
28 epoch, 50 iter, loss 0.6230518221855164
28 epoch, 51 iter, loss 0.6584761142730713
28 epoch, 52 iter, loss 0.6055766940116882
28 epoch, 53 iter, loss 0.5397267937660217
28 epoch, 54 iter, loss 0.6509550213813782
28 epoch, 55 iter, loss 0.7139212489128113
28 epoch, 56 iter, loss 0.5731319785118103
28 epoch, 57 iter, loss 0.7522004246711731
28 epoch, Average loss 0.6409812914697748
./model/merge_model_Param_v30.pth
some of decrypted state:
tensor([[[[ 0.0635, -0.0554,  0.0533],
          [ 0.1246,  0.1382,  0.0802],
          [-0.0967, -0.0875, -0.0091]],

         [[-0.0290,  0.1195,  0.1396],
          [-0.0119,  0.0766, -0.1280],
          [-0.1376, -0.0556,  0.0710]],

         [[ 0.1074, -0.0979,  0.0162],
          [-0.0092, -0.0863,  0.0729],
          [ 0.1040,  0.1123, -0.1190]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1904, -0.1662,  0.1600],
          [ 0.3739,  0.4147,  0.2407],
          [-0.2901, -0.2625, -0.0273]],

         [[-0.0870,  0.3585,  0.4188],
          [-0.0357,  0.2299, -0.3839],
          [-0.4129, -0.1667,  0.2131]],

         [[ 0.3222, -0.2937,  0.0487],
          [-0.0277, -0.2588,  0.2188],
          [ 0.3119,  0.3370, -0.3570]]]], device='cuda:0')
start training
29 epoch, 1 iter, loss 0.6546835899353027
29 epoch, 2 iter, loss 0.6897082328796387
29 epoch, 3 iter, loss 0.8275279402732849
29 epoch, 4 iter, loss 0.7868286371231079
29 epoch, 5 iter, loss 0.39480483531951904
29 epoch, 6 iter, loss 0.6668456792831421
29 epoch, 7 iter, loss 0.7181313633918762
29 epoch, 8 iter, loss 0.6802680492401123
29 epoch, 9 iter, loss 0.7592855095863342
29 epoch, 10 iter, loss 0.5479899644851685
29 epoch, 11 iter, loss 0.3646538555622101
29 epoch, 12 iter, loss 0.6105468273162842
29 epoch, 13 iter, loss 0.9257074594497681
29 epoch, 14 iter, loss 0.4976792335510254
29 epoch, 15 iter, loss 0.6848398447036743
29 epoch, 16 iter, loss 0.7543579936027527
29 epoch, 17 iter, loss 0.8828664422035217
29 epoch, 18 iter, loss 0.6408361792564392
29 epoch, 19 iter, loss 0.6032472848892212
29 epoch, 20 iter, loss 0.5263048410415649
29 epoch, 21 iter, loss 0.8022977113723755
29 epoch, 22 iter, loss 0.4257873594760895
29 epoch, 23 iter, loss 0.7524787187576294
29 epoch, 24 iter, loss 0.5620627403259277
29 epoch, 25 iter, loss 0.6047240495681763
29 epoch, 26 iter, loss 0.5482571125030518
29 epoch, 27 iter, loss 0.8434990644454956
29 epoch, 28 iter, loss 0.4275089502334595
29 epoch, 29 iter, loss 0.6454175114631653
29 epoch, 30 iter, loss 0.6726762652397156
29 epoch, 31 iter, loss 0.5206314325332642
29 epoch, 32 iter, loss 0.49652567505836487
29 epoch, 33 iter, loss 0.5509458780288696
29 epoch, 34 iter, loss 0.5200122594833374
29 epoch, 35 iter, loss 0.6893959045410156
29 epoch, 36 iter, loss 0.613479495048523
29 epoch, 37 iter, loss 0.8270063996315002
29 epoch, 38 iter, loss 0.6514536738395691
29 epoch, 39 iter, loss 0.6262239813804626
29 epoch, 40 iter, loss 0.5189038515090942
29 epoch, 41 iter, loss 0.5842674970626831
29 epoch, 42 iter, loss 0.636242151260376
29 epoch, 43 iter, loss 0.4686473608016968
29 epoch, 44 iter, loss 0.7544991374015808
29 epoch, 45 iter, loss 0.6116387248039246
29 epoch, 46 iter, loss 0.8388386964797974
29 epoch, 47 iter, loss 0.601710855960846
29 epoch, 48 iter, loss 0.468111127614975
29 epoch, 49 iter, loss 0.6545277237892151
29 epoch, 50 iter, loss 0.6934069395065308
29 epoch, 51 iter, loss 0.506386935710907
29 epoch, 52 iter, loss 0.6895611882209778
29 epoch, 53 iter, loss 0.45006054639816284
29 epoch, 54 iter, loss 0.5354050993919373
29 epoch, 55 iter, loss 0.6327707767486572
29 epoch, 56 iter, loss 0.5698337554931641
29 epoch, 57 iter, loss 0.6768461465835571
29 epoch, Average loss 0.629634323873018
./model/merge_model_Param_v31.pth
some of decrypted state:
tensor([[[[ 0.0627, -0.0560,  0.0522],
          [ 0.1251,  0.1387,  0.0805],
          [-0.0980, -0.0888, -0.0106]],

         [[-0.0297,  0.1191,  0.1387],
          [-0.0111,  0.0775, -0.1275],
          [-0.1385, -0.0564,  0.0700]],

         [[ 0.1066, -0.0984,  0.0155],
          [-0.0082, -0.0850,  0.0736],
          [ 0.1032,  0.1116, -0.1197]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1880, -0.1679,  0.1567],
          [ 0.3753,  0.4160,  0.2416],
          [-0.2941, -0.2664, -0.0317]],

         [[-0.0892,  0.3573,  0.4162],
          [-0.0334,  0.2325, -0.3824],
          [-0.4156, -0.1691,  0.2101]],

         [[ 0.3199, -0.2952,  0.0466],
          [-0.0245, -0.2551,  0.2208],
          [ 0.3097,  0.3349, -0.3591]]]], device='cuda:0')
start training
30 epoch, 1 iter, loss 0.6043330430984497
30 epoch, 2 iter, loss 0.40150928497314453
30 epoch, 3 iter, loss 0.86181640625
30 epoch, 4 iter, loss 0.6592425107955933
30 epoch, 5 iter, loss 0.8766072392463684
30 epoch, 6 iter, loss 0.3391938805580139
30 epoch, 7 iter, loss 0.7001249194145203
30 epoch, 8 iter, loss 0.5093587040901184
30 epoch, 9 iter, loss 0.9815632700920105
30 epoch, 10 iter, loss 0.821807324886322
30 epoch, 11 iter, loss 0.6371854543685913
30 epoch, 12 iter, loss 0.6456847786903381
30 epoch, 13 iter, loss 0.6763702034950256
30 epoch, 14 iter, loss 0.6472004652023315
30 epoch, 15 iter, loss 0.6955845952033997
30 epoch, 16 iter, loss 0.6185204982757568
30 epoch, 17 iter, loss 0.5285241007804871
30 epoch, 18 iter, loss 0.5732147693634033
30 epoch, 19 iter, loss 0.6349548101425171
30 epoch, 20 iter, loss 0.7294083833694458
30 epoch, 21 iter, loss 0.6236774921417236
30 epoch, 22 iter, loss 0.7825134992599487
30 epoch, 23 iter, loss 0.5952837467193604
30 epoch, 24 iter, loss 0.5484771132469177
30 epoch, 25 iter, loss 0.7063513398170471
30 epoch, 26 iter, loss 0.6051125526428223
30 epoch, 27 iter, loss 0.5882191061973572
30 epoch, 28 iter, loss 0.4788612425327301
30 epoch, 29 iter, loss 0.5635932087898254
30 epoch, 30 iter, loss 0.5758377313613892
30 epoch, 31 iter, loss 0.5681042075157166
30 epoch, 32 iter, loss 0.5174980759620667
30 epoch, 33 iter, loss 0.7105057239532471
30 epoch, 34 iter, loss 0.8460856080055237
30 epoch, 35 iter, loss 0.8479626774787903
30 epoch, 36 iter, loss 0.5844326019287109
30 epoch, 37 iter, loss 0.6705353856086731
30 epoch, 38 iter, loss 0.5665698647499084
30 epoch, 39 iter, loss 0.5675289630889893
30 epoch, 40 iter, loss 0.4992048144340515
30 epoch, 41 iter, loss 0.5493952035903931
30 epoch, 42 iter, loss 0.5010986328125
30 epoch, 43 iter, loss 0.5747259855270386
30 epoch, 44 iter, loss 0.7367749810218811
30 epoch, 45 iter, loss 0.7055380344390869
30 epoch, 46 iter, loss 0.812275230884552
30 epoch, 47 iter, loss 0.7575441002845764
30 epoch, 48 iter, loss 0.756477415561676
30 epoch, 49 iter, loss 0.5604607462882996
30 epoch, 50 iter, loss 0.48690667748451233
30 epoch, 51 iter, loss 0.7212197184562683
30 epoch, 52 iter, loss 0.5945212841033936
30 epoch, 53 iter, loss 0.6449831128120422
30 epoch, 54 iter, loss 0.48463761806488037
30 epoch, 55 iter, loss 0.5333983302116394
30 epoch, 56 iter, loss 0.6369568705558777
30 epoch, 57 iter, loss 0.6625669002532959
30 epoch, Average loss 0.6369831656154833
./model/merge_model_Param_v32.pth
some of decrypted state:
tensor([[[[ 0.0624, -0.0564,  0.0515],
          [ 0.1255,  0.1388,  0.0802],
          [-0.0985, -0.0898, -0.0118]],

         [[-0.0299,  0.1191,  0.1384],
          [-0.0107,  0.0778, -0.1275],
          [-0.1391, -0.0570,  0.0690]],

         [[ 0.1062, -0.0989,  0.0149],
          [-0.0079, -0.0848,  0.0736],
          [ 0.1023,  0.1106, -0.1209]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1872, -0.1691,  0.1546],
          [ 0.3765,  0.4164,  0.2406],
          [-0.2956, -0.2693, -0.0354]],

         [[-0.0897,  0.3574,  0.4152],
          [-0.0320,  0.2334, -0.3825],
          [-0.4173, -0.1711,  0.2071]],

         [[ 0.3185, -0.2967,  0.0446],
          [-0.0237, -0.2544,  0.2209],
          [ 0.3068,  0.3319, -0.3626]]]], device='cuda:0')
start training
31 epoch, 1 iter, loss 0.6371639966964722
31 epoch, 2 iter, loss 0.7353841066360474
31 epoch, 3 iter, loss 0.5736582279205322
31 epoch, 4 iter, loss 0.633876383304596
31 epoch, 5 iter, loss 0.6699572205543518
31 epoch, 6 iter, loss 0.6152467131614685
31 epoch, 7 iter, loss 0.7082986235618591
31 epoch, 8 iter, loss 0.6087805032730103
31 epoch, 9 iter, loss 0.5536443591117859
31 epoch, 10 iter, loss 0.6436035633087158
31 epoch, 11 iter, loss 0.5653975605964661
31 epoch, 12 iter, loss 0.6407755613327026
31 epoch, 13 iter, loss 0.609335720539093
31 epoch, 14 iter, loss 0.509869396686554
31 epoch, 15 iter, loss 0.496681272983551
31 epoch, 16 iter, loss 0.548112690448761
31 epoch, 17 iter, loss 0.5876059532165527
31 epoch, 18 iter, loss 0.4459797441959381
31 epoch, 19 iter, loss 0.5436252355575562
31 epoch, 20 iter, loss 0.3602425456047058
31 epoch, 21 iter, loss 0.5136870741844177
31 epoch, 22 iter, loss 0.679712176322937
31 epoch, 23 iter, loss 0.6216832995414734
31 epoch, 24 iter, loss 0.4513738453388214
31 epoch, 25 iter, loss 0.678846538066864
31 epoch, 26 iter, loss 0.6242175102233887
31 epoch, 27 iter, loss 0.6335809826850891
31 epoch, 28 iter, loss 0.6155899167060852
31 epoch, 29 iter, loss 0.6833377480506897
31 epoch, 30 iter, loss 0.5093604326248169
31 epoch, 31 iter, loss 0.5375373363494873
31 epoch, 32 iter, loss 0.6478667259216309
31 epoch, 33 iter, loss 0.5617429614067078
31 epoch, 34 iter, loss 0.44539958238601685
31 epoch, 35 iter, loss 0.6660685539245605
31 epoch, 36 iter, loss 0.7056166529655457
31 epoch, 37 iter, loss 0.7894685864448547
31 epoch, 38 iter, loss 0.7091724872589111
31 epoch, 39 iter, loss 0.8004915118217468
31 epoch, 40 iter, loss 0.4662318527698517
31 epoch, 41 iter, loss 0.7083601355552673
31 epoch, 42 iter, loss 0.6293008923530579
31 epoch, 43 iter, loss 0.6697314381599426
31 epoch, 44 iter, loss 0.4911423623561859
31 epoch, 45 iter, loss 0.5550770163536072
31 epoch, 46 iter, loss 0.5927069783210754
31 epoch, 47 iter, loss 0.7402129769325256
31 epoch, 48 iter, loss 0.7284103631973267
31 epoch, 49 iter, loss 0.6263518333435059
31 epoch, 50 iter, loss 0.660834789276123
31 epoch, 51 iter, loss 0.7980332970619202
31 epoch, 52 iter, loss 0.6289291381835938
31 epoch, 53 iter, loss 0.5373717546463013
31 epoch, 54 iter, loss 0.5382853150367737
31 epoch, 55 iter, loss 0.6439533233642578
31 epoch, 56 iter, loss 0.6937735080718994
31 epoch, 57 iter, loss 0.5558372735977173
31 epoch, Average loss 0.6109918868332579
./model/merge_model_Param_v33.pth
some of decrypted state:
tensor([[[[ 0.0631, -0.0558,  0.0520],
          [ 0.1269,  0.1401,  0.0812],
          [-0.0966, -0.0879, -0.0103]],

         [[-0.0294,  0.1196,  0.1389],
          [-0.0092,  0.0791, -0.1266],
          [-0.1374, -0.0556,  0.0703]],

         [[ 0.1066, -0.0986,  0.0153],
          [-0.0059, -0.0830,  0.0747],
          [ 0.1042,  0.1124, -0.1191]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1894, -0.1674,  0.1560],
          [ 0.3807,  0.4204,  0.2436],
          [-0.2898, -0.2638, -0.0308]],

         [[-0.0883,  0.3587,  0.4166],
          [-0.0275,  0.2373, -0.3798],
          [-0.4123, -0.1667,  0.2109]],

         [[ 0.3197, -0.2957,  0.0458],
          [-0.0177, -0.2491,  0.2240],
          [ 0.3127,  0.3372, -0.3572]]]], device='cuda:0')
start training
32 epoch, 1 iter, loss 0.998390257358551
32 epoch, 2 iter, loss 0.6470240950584412
32 epoch, 3 iter, loss 0.564669668674469
32 epoch, 4 iter, loss 0.47714436054229736
32 epoch, 5 iter, loss 0.7006568908691406
32 epoch, 6 iter, loss 0.678837776184082
32 epoch, 7 iter, loss 0.568367600440979
32 epoch, 8 iter, loss 0.6771905422210693
32 epoch, 9 iter, loss 0.564841628074646
32 epoch, 10 iter, loss 0.53605717420578
32 epoch, 11 iter, loss 0.6201689839363098
32 epoch, 12 iter, loss 0.6591640710830688
32 epoch, 13 iter, loss 0.5855463743209839
32 epoch, 14 iter, loss 0.5514239072799683
32 epoch, 15 iter, loss 0.6667590141296387
32 epoch, 16 iter, loss 0.5620183944702148
32 epoch, 17 iter, loss 0.42063310742378235
32 epoch, 18 iter, loss 0.5452814698219299
32 epoch, 19 iter, loss 0.49255988001823425
32 epoch, 20 iter, loss 0.5930900573730469
32 epoch, 21 iter, loss 0.6578249335289001
32 epoch, 22 iter, loss 0.491122305393219
32 epoch, 23 iter, loss 0.6014420390129089
32 epoch, 24 iter, loss 0.762228786945343
32 epoch, 25 iter, loss 0.6580334305763245
32 epoch, 26 iter, loss 0.6687440872192383
32 epoch, 27 iter, loss 0.5176315307617188
32 epoch, 28 iter, loss 0.7924178838729858
32 epoch, 29 iter, loss 0.5039756298065186
32 epoch, 30 iter, loss 0.7516612410545349
32 epoch, 31 iter, loss 0.6544691920280457
32 epoch, 32 iter, loss 0.7099214792251587
32 epoch, 33 iter, loss 0.4742540419101715
32 epoch, 34 iter, loss 0.5298512578010559
32 epoch, 35 iter, loss 0.6108055114746094
32 epoch, 36 iter, loss 0.5245761275291443
32 epoch, 37 iter, loss 0.5166674256324768
32 epoch, 38 iter, loss 0.5717203617095947
32 epoch, 39 iter, loss 0.548999547958374
32 epoch, 40 iter, loss 0.7197417616844177
32 epoch, 41 iter, loss 0.7439805865287781
32 epoch, 42 iter, loss 0.5387130975723267
32 epoch, 43 iter, loss 0.7108656167984009
32 epoch, 44 iter, loss 0.5118815302848816
32 epoch, 45 iter, loss 0.6588693857192993
32 epoch, 46 iter, loss 0.4661504924297333
32 epoch, 47 iter, loss 0.5683009624481201
32 epoch, 48 iter, loss 0.7514687180519104
32 epoch, 49 iter, loss 0.7815205454826355
32 epoch, 50 iter, loss 0.47935113310813904
32 epoch, 51 iter, loss 0.6032125949859619
32 epoch, 52 iter, loss 0.6019018292427063
32 epoch, 53 iter, loss 0.5201566219329834
32 epoch, 54 iter, loss 0.5736120343208313
32 epoch, 55 iter, loss 0.6900632381439209
32 epoch, 56 iter, loss 0.618188738822937
32 epoch, 57 iter, loss 0.640802264213562
32 epoch, Average loss 0.6111395301526052
./model/merge_model_Param_v34.pth
some of decrypted state:
tensor([[[[ 0.0643, -0.0544,  0.0531],
          [ 0.1267,  0.1396,  0.0810],
          [-0.0971, -0.0882, -0.0107]],

         [[-0.0284,  0.1207,  0.1398],
          [-0.0096,  0.0785, -0.1270],
          [-0.1382, -0.0562,  0.0694]],

         [[ 0.1070, -0.0979,  0.0157],
          [-0.0063, -0.0835,  0.0742],
          [ 0.1030,  0.1114, -0.1200]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1930, -0.1631,  0.1593],
          [ 0.3801,  0.4189,  0.2430],
          [-0.2912, -0.2647, -0.0321]],

         [[-0.0852,  0.3622,  0.4193],
          [-0.0289,  0.2354, -0.3809],
          [-0.4146, -0.1686,  0.2082]],

         [[ 0.3209, -0.2938,  0.0472],
          [-0.0190, -0.2504,  0.2227],
          [ 0.3089,  0.3343, -0.3599]]]], device='cuda:0')
start training
33 epoch, 1 iter, loss 0.5935818552970886
33 epoch, 2 iter, loss 0.7217823266983032
33 epoch, 3 iter, loss 0.6134846806526184
33 epoch, 4 iter, loss 0.5924493670463562
33 epoch, 5 iter, loss 0.8176453709602356
33 epoch, 6 iter, loss 0.7431244850158691
33 epoch, 7 iter, loss 0.5620917081832886
33 epoch, 8 iter, loss 0.5275022983551025
33 epoch, 9 iter, loss 0.6475347280502319
33 epoch, 10 iter, loss 0.6305761933326721
33 epoch, 11 iter, loss 0.5859041810035706
33 epoch, 12 iter, loss 0.5563059449195862
33 epoch, 13 iter, loss 0.5665192008018494
33 epoch, 14 iter, loss 0.9220954775810242
33 epoch, 15 iter, loss 0.5842796564102173
33 epoch, 16 iter, loss 0.5259066224098206
33 epoch, 17 iter, loss 0.6828964948654175
33 epoch, 18 iter, loss 0.66739821434021
33 epoch, 19 iter, loss 0.769275963306427
33 epoch, 20 iter, loss 0.6605615019798279
33 epoch, 21 iter, loss 0.5823937058448792
33 epoch, 22 iter, loss 0.6297045946121216
33 epoch, 23 iter, loss 0.43791764974594116
33 epoch, 24 iter, loss 0.6380710005760193
33 epoch, 25 iter, loss 0.6458150744438171
33 epoch, 26 iter, loss 0.46454575657844543
33 epoch, 27 iter, loss 0.6974515318870544
33 epoch, 28 iter, loss 0.6035378575325012
33 epoch, 29 iter, loss 0.5668337941169739
33 epoch, 30 iter, loss 0.6290270686149597
33 epoch, 31 iter, loss 0.4853154718875885
33 epoch, 32 iter, loss 0.5142645239830017
33 epoch, 33 iter, loss 0.8023661971092224
33 epoch, 34 iter, loss 0.6334097981452942
33 epoch, 35 iter, loss 0.6240337491035461
33 epoch, 36 iter, loss 0.4025392532348633
33 epoch, 37 iter, loss 0.6212570667266846
33 epoch, 38 iter, loss 0.6767038106918335
33 epoch, 39 iter, loss 0.6607898473739624
33 epoch, 40 iter, loss 0.7731600999832153
33 epoch, 41 iter, loss 0.5690672397613525
33 epoch, 42 iter, loss 0.47402116656303406
33 epoch, 43 iter, loss 0.6269935965538025
33 epoch, 44 iter, loss 0.4779614210128784
33 epoch, 45 iter, loss 0.4757889211177826
33 epoch, 46 iter, loss 0.5281657576560974
33 epoch, 47 iter, loss 0.6453508138656616
33 epoch, 48 iter, loss 0.7123430371284485
33 epoch, 49 iter, loss 0.5279706120491028
33 epoch, 50 iter, loss 0.7939732074737549
33 epoch, 51 iter, loss 0.4588363468647003
33 epoch, 52 iter, loss 0.8668048977851868
33 epoch, 53 iter, loss 0.617368221282959
33 epoch, 54 iter, loss 0.5905394554138184
33 epoch, 55 iter, loss 0.6031191349029541
33 epoch, 56 iter, loss 0.42324191331863403
33 epoch, 57 iter, loss 0.689986526966095
33 epoch, Average loss 0.6165190595283843
./model/merge_model_Param_v35.pth
some of decrypted state:
tensor([[[[ 0.0646, -0.0540,  0.0537],
          [ 0.1266,  0.1397,  0.0813],
          [-0.0977, -0.0888, -0.0109]],

         [[-0.0286,  0.1208,  0.1398],
          [-0.0100,  0.0781, -0.1273],
          [-0.1394, -0.0575,  0.0684]],

         [[ 0.1062, -0.0984,  0.0151],
          [-0.0069, -0.0840,  0.0735],
          [ 0.1015,  0.1100, -0.1208]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1937, -0.1621,  0.1612],
          [ 0.3797,  0.4191,  0.2440],
          [-0.2932, -0.2663, -0.0328]],

         [[-0.0857,  0.3624,  0.4194],
          [-0.0299,  0.2342, -0.3818],
          [-0.4181, -0.1724,  0.2052]],

         [[ 0.3186, -0.2952,  0.0454],
          [-0.0206, -0.2520,  0.2206],
          [ 0.3044,  0.3300, -0.3625]]]], device='cuda:0')
start training
34 epoch, 1 iter, loss 0.6541248559951782
34 epoch, 2 iter, loss 0.6894810199737549
34 epoch, 3 iter, loss 0.5172359943389893
34 epoch, 4 iter, loss 0.47471022605895996
34 epoch, 5 iter, loss 0.7943856716156006
34 epoch, 6 iter, loss 0.668179452419281
34 epoch, 7 iter, loss 0.35681775212287903
34 epoch, 8 iter, loss 0.5978289246559143
34 epoch, 9 iter, loss 0.6222960352897644
34 epoch, 10 iter, loss 0.7585708498954773
34 epoch, 11 iter, loss 0.5553305149078369
34 epoch, 12 iter, loss 0.6443679332733154
34 epoch, 13 iter, loss 0.4976836144924164
34 epoch, 14 iter, loss 0.5274935960769653
34 epoch, 15 iter, loss 0.8199889063835144
34 epoch, 16 iter, loss 0.5527713894844055
34 epoch, 17 iter, loss 0.9450799226760864
34 epoch, 18 iter, loss 0.6346869468688965
34 epoch, 19 iter, loss 0.43628165125846863
34 epoch, 20 iter, loss 0.6530304551124573
34 epoch, 21 iter, loss 0.4858165681362152
34 epoch, 22 iter, loss 0.47571972012519836
34 epoch, 23 iter, loss 0.7216575145721436
34 epoch, 24 iter, loss 0.5286563634872437
34 epoch, 25 iter, loss 0.7403255105018616
34 epoch, 26 iter, loss 0.7010188698768616
34 epoch, 27 iter, loss 0.3909182846546173
34 epoch, 28 iter, loss 0.5507228970527649
34 epoch, 29 iter, loss 0.6431860327720642
34 epoch, 30 iter, loss 0.856083333492279
34 epoch, 31 iter, loss 0.8688808083534241
34 epoch, 32 iter, loss 0.39897796511650085
34 epoch, 33 iter, loss 0.7422760128974915
34 epoch, 34 iter, loss 0.5024456977844238
34 epoch, 35 iter, loss 0.6528017520904541
34 epoch, 36 iter, loss 0.5763149857521057
34 epoch, 37 iter, loss 0.6469067335128784
34 epoch, 38 iter, loss 0.649822473526001
34 epoch, 39 iter, loss 0.6334353089332581
34 epoch, 40 iter, loss 0.40896889567375183
34 epoch, 41 iter, loss 0.5431575775146484
34 epoch, 42 iter, loss 0.703275740146637
34 epoch, 43 iter, loss 0.7160435914993286
34 epoch, 44 iter, loss 0.6055785417556763
34 epoch, 45 iter, loss 0.5729268789291382
34 epoch, 46 iter, loss 0.6593846678733826
34 epoch, 47 iter, loss 0.5848935842514038
34 epoch, 48 iter, loss 0.6830945014953613
34 epoch, 49 iter, loss 0.5109239220619202
34 epoch, 50 iter, loss 0.5397567749023438
34 epoch, 51 iter, loss 0.6740740537643433
34 epoch, 52 iter, loss 0.5461574196815491
34 epoch, 53 iter, loss 0.6757445931434631
34 epoch, 54 iter, loss 0.5291576981544495
34 epoch, 55 iter, loss 0.5214046239852905
34 epoch, 56 iter, loss 0.6840341091156006
34 epoch, 57 iter, loss 0.5360669493675232
34 epoch, Average loss 0.6115957310325221
./model/merge_model_Param_v36.pth
some of decrypted state:
tensor([[[[ 0.0649, -0.0535,  0.0538],
          [ 0.1274,  0.1402,  0.0811],
          [-0.0975, -0.0891, -0.0114]],

         [[-0.0286,  0.1210,  0.1394],
          [-0.0098,  0.0779, -0.1280],
          [-0.1398, -0.0582,  0.0675]],

         [[ 0.1059, -0.0984,  0.0147],
          [-0.0066, -0.0837,  0.0731],
          [ 0.1011,  0.1096, -0.1212]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1948, -0.1604,  0.1613],
          [ 0.3823,  0.4206,  0.2432],
          [-0.2925, -0.2672, -0.0342]],

         [[-0.0858,  0.3631,  0.4183],
          [-0.0295,  0.2338, -0.3839],
          [-0.4193, -0.1745,  0.2026]],

         [[ 0.3177, -0.2951,  0.0440],
          [-0.0199, -0.2512,  0.2192],
          [ 0.3032,  0.3288, -0.3636]]]], device='cuda:0')
start training
35 epoch, 1 iter, loss 0.3726605474948883
35 epoch, 2 iter, loss 0.8202081918716431
35 epoch, 3 iter, loss 0.5796831846237183
35 epoch, 4 iter, loss 0.5649212598800659
35 epoch, 5 iter, loss 0.637389063835144
35 epoch, 6 iter, loss 0.6791212558746338
35 epoch, 7 iter, loss 0.36422085762023926
35 epoch, 8 iter, loss 0.6874907612800598
35 epoch, 9 iter, loss 0.5896338224411011
35 epoch, 10 iter, loss 0.6842297911643982
35 epoch, 11 iter, loss 0.5063726902008057
35 epoch, 12 iter, loss 0.5064445734024048
35 epoch, 13 iter, loss 0.5855801105499268
35 epoch, 14 iter, loss 0.5003941059112549
35 epoch, 15 iter, loss 0.6652143001556396
35 epoch, 16 iter, loss 0.5253740549087524
35 epoch, 17 iter, loss 0.6852403283119202
35 epoch, 18 iter, loss 0.9472690224647522
35 epoch, 19 iter, loss 0.62684166431427
35 epoch, 20 iter, loss 0.5389854907989502
35 epoch, 21 iter, loss 0.6254698038101196
35 epoch, 22 iter, loss 0.7734390497207642
35 epoch, 23 iter, loss 0.49471229314804077
35 epoch, 24 iter, loss 0.7059440016746521
35 epoch, 25 iter, loss 0.5345993638038635
35 epoch, 26 iter, loss 0.6863992810249329
35 epoch, 27 iter, loss 0.6692322492599487
35 epoch, 28 iter, loss 0.6372668147087097
35 epoch, 29 iter, loss 0.4764803946018219
35 epoch, 30 iter, loss 0.49739956855773926
35 epoch, 31 iter, loss 0.5309939384460449
35 epoch, 32 iter, loss 0.5110732913017273
35 epoch, 33 iter, loss 0.5109433531761169
35 epoch, 34 iter, loss 0.6713298559188843
35 epoch, 35 iter, loss 0.6662683486938477
35 epoch, 36 iter, loss 0.5288884043693542
35 epoch, 37 iter, loss 0.6124656796455383
35 epoch, 38 iter, loss 0.605740487575531
35 epoch, 39 iter, loss 0.6753677725791931
35 epoch, 40 iter, loss 0.5206497311592102
35 epoch, 41 iter, loss 0.6726656556129456
35 epoch, 42 iter, loss 0.6006163358688354
35 epoch, 43 iter, loss 0.43132108449935913
35 epoch, 44 iter, loss 0.5824234485626221
35 epoch, 45 iter, loss 0.5575928688049316
35 epoch, 46 iter, loss 0.6619455814361572
35 epoch, 47 iter, loss 0.36550959944725037
35 epoch, 48 iter, loss 0.4689522087574005
35 epoch, 49 iter, loss 0.4897992014884949
35 epoch, 50 iter, loss 0.5956541299819946
35 epoch, 51 iter, loss 0.5099185705184937
35 epoch, 52 iter, loss 0.729844331741333
35 epoch, 53 iter, loss 0.4795452952384949
35 epoch, 54 iter, loss 0.5235766172409058
35 epoch, 55 iter, loss 0.5189916491508484
35 epoch, 56 iter, loss 0.7740558981895447
35 epoch, 57 iter, loss 0.530491828918457
35 epoch, Average loss 0.5876288257147136
./model/merge_model_Param_v37.pth
some of decrypted state:
tensor([[[[ 0.0651, -0.0532,  0.0540],
          [ 0.1273,  0.1404,  0.0817],
          [-0.0981, -0.0893, -0.0115]],

         [[-0.0286,  0.1211,  0.1395],
          [-0.0099,  0.0780, -0.1275],
          [-0.1405, -0.0586,  0.0672]],

         [[ 0.1052, -0.0988,  0.0143],
          [-0.0068, -0.0837,  0.0732],
          [ 0.1001,  0.1090, -0.1215]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1952, -0.1597,  0.1620],
          [ 0.3820,  0.4213,  0.2450],
          [-0.2943, -0.2678, -0.0346]],

         [[-0.0858,  0.3632,  0.4186],
          [-0.0296,  0.2339, -0.3825],
          [-0.4215, -0.1757,  0.2015]],

         [[ 0.3156, -0.2965,  0.0430],
          [-0.0205, -0.2512,  0.2196],
          [ 0.3004,  0.3271, -0.3644]]]], device='cuda:0')
start training
36 epoch, 1 iter, loss 0.5719169974327087
36 epoch, 2 iter, loss 0.6253647208213806
36 epoch, 3 iter, loss 0.5161156058311462
36 epoch, 4 iter, loss 0.5694962739944458
36 epoch, 5 iter, loss 0.5952560901641846
36 epoch, 6 iter, loss 0.2938258945941925
36 epoch, 7 iter, loss 0.43570706248283386
36 epoch, 8 iter, loss 0.5077418684959412
36 epoch, 9 iter, loss 0.6940382122993469
36 epoch, 10 iter, loss 0.4372161030769348
36 epoch, 11 iter, loss 0.7724239826202393
36 epoch, 12 iter, loss 0.6417140960693359
36 epoch, 13 iter, loss 0.5635931491851807
36 epoch, 14 iter, loss 0.5325468182563782
36 epoch, 15 iter, loss 0.5824448466300964
36 epoch, 16 iter, loss 0.46156635880470276
36 epoch, 17 iter, loss 0.7803305387496948
36 epoch, 18 iter, loss 0.5300322771072388
36 epoch, 19 iter, loss 0.5555917620658875
36 epoch, 20 iter, loss 0.6344670057296753
36 epoch, 21 iter, loss 0.44829612970352173
36 epoch, 22 iter, loss 0.4821964204311371
36 epoch, 23 iter, loss 0.7275505661964417
36 epoch, 24 iter, loss 0.4648664891719818
36 epoch, 25 iter, loss 0.583269476890564
36 epoch, 26 iter, loss 0.724967360496521
36 epoch, 27 iter, loss 0.5481340885162354
36 epoch, 28 iter, loss 0.7039031982421875
36 epoch, 29 iter, loss 0.7347445487976074
36 epoch, 30 iter, loss 0.6187365055084229
36 epoch, 31 iter, loss 0.3321171700954437
36 epoch, 32 iter, loss 0.5435328483581543
36 epoch, 33 iter, loss 0.6410843729972839
36 epoch, 34 iter, loss 0.5087016820907593
36 epoch, 35 iter, loss 0.6967789530754089
36 epoch, 36 iter, loss 0.4412842094898224
36 epoch, 37 iter, loss 0.6930394768714905
36 epoch, 38 iter, loss 0.5407794117927551
36 epoch, 39 iter, loss 0.46922487020492554
36 epoch, 40 iter, loss 0.683063268661499
36 epoch, 41 iter, loss 0.7440775632858276
36 epoch, 42 iter, loss 0.952008843421936
36 epoch, 43 iter, loss 0.47570765018463135
36 epoch, 44 iter, loss 0.46832016110420227
36 epoch, 45 iter, loss 0.5048543810844421
36 epoch, 46 iter, loss 0.7448979616165161
36 epoch, 47 iter, loss 0.638401985168457
36 epoch, 48 iter, loss 0.7426012754440308
36 epoch, 49 iter, loss 0.3709333837032318
36 epoch, 50 iter, loss 0.7318394184112549
36 epoch, 51 iter, loss 0.6329526305198669
36 epoch, 52 iter, loss 0.4683254063129425
36 epoch, 53 iter, loss 0.5119668841362
36 epoch, 54 iter, loss 0.5220260620117188
36 epoch, 55 iter, loss 0.39256641268730164
36 epoch, 56 iter, loss 0.7255129218101501
36 epoch, 57 iter, loss 0.549258291721344
36 epoch, Average loss 0.5800686306075046
./model/merge_model_Param_v38.pth
some of decrypted state:
tensor([[[[ 0.0656, -0.0528,  0.0538],
          [ 0.1277,  0.1407,  0.0819],
          [-0.0982, -0.0894, -0.0118]],

         [[-0.0280,  0.1217,  0.1397],
          [-0.0093,  0.0785, -0.1266],
          [-0.1399, -0.0579,  0.0679]],

         [[ 0.1053, -0.0988,  0.0141],
          [-0.0061, -0.0829,  0.0743],
          [ 0.1009,  0.1102, -0.1198]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1967, -0.1583,  0.1615],
          [ 0.3831,  0.4221,  0.2458],
          [-0.2946, -0.2681, -0.0353]],

         [[-0.0839,  0.3652,  0.4191],
          [-0.0279,  0.2354, -0.3798],
          [-0.4197, -0.1737,  0.2038]],

         [[ 0.3160, -0.2964,  0.0422],
          [-0.0182, -0.2487,  0.2230],
          [ 0.3028,  0.3306, -0.3595]]]], device='cuda:0')
start training
37 epoch, 1 iter, loss 0.4375191926956177
37 epoch, 2 iter, loss 0.8229228854179382
37 epoch, 3 iter, loss 0.5854518413543701
37 epoch, 4 iter, loss 0.72274249792099
37 epoch, 5 iter, loss 0.611420214176178
37 epoch, 6 iter, loss 0.37841686606407166
37 epoch, 7 iter, loss 0.5146304965019226
37 epoch, 8 iter, loss 0.8067198395729065
37 epoch, 9 iter, loss 0.6513213515281677
37 epoch, 10 iter, loss 0.7369250059127808
37 epoch, 11 iter, loss 0.5900053977966309
37 epoch, 12 iter, loss 0.6813251376152039
37 epoch, 13 iter, loss 0.540582001209259
37 epoch, 14 iter, loss 0.7097480297088623
37 epoch, 15 iter, loss 0.4091188609600067
37 epoch, 16 iter, loss 0.5997333526611328
37 epoch, 17 iter, loss 0.4583861231803894
37 epoch, 18 iter, loss 0.5764530301094055
37 epoch, 19 iter, loss 0.3818705976009369
37 epoch, 20 iter, loss 0.47171515226364136
37 epoch, 21 iter, loss 0.5312198996543884
37 epoch, 22 iter, loss 0.537291944026947
37 epoch, 23 iter, loss 0.5228617191314697
37 epoch, 24 iter, loss 0.7745028138160706
37 epoch, 25 iter, loss 0.5955773591995239
37 epoch, 26 iter, loss 0.529735267162323
37 epoch, 27 iter, loss 0.4957302510738373
37 epoch, 28 iter, loss 0.5263500809669495
37 epoch, 29 iter, loss 0.4888926148414612
37 epoch, 30 iter, loss 0.5818693041801453
37 epoch, 31 iter, loss 0.6212233901023865
37 epoch, 32 iter, loss 0.6212098598480225
37 epoch, 33 iter, loss 0.38342684507369995
37 epoch, 34 iter, loss 0.5119597315788269
37 epoch, 35 iter, loss 0.6223742961883545
37 epoch, 36 iter, loss 0.6725221276283264
37 epoch, 37 iter, loss 0.7214780449867249
37 epoch, 38 iter, loss 0.6868830919265747
37 epoch, 39 iter, loss 0.6406311988830566
37 epoch, 40 iter, loss 0.3892855942249298
37 epoch, 41 iter, loss 0.7001814246177673
37 epoch, 42 iter, loss 0.5124750733375549
37 epoch, 43 iter, loss 0.5271480679512024
37 epoch, 44 iter, loss 0.36073508858680725
37 epoch, 45 iter, loss 0.5796002149581909
37 epoch, 46 iter, loss 0.310215026140213
37 epoch, 47 iter, loss 0.7149495482444763
37 epoch, 48 iter, loss 0.7228007912635803
37 epoch, 49 iter, loss 0.6818057894706726
37 epoch, 50 iter, loss 0.5259861350059509
37 epoch, 51 iter, loss 0.5332027673721313
37 epoch, 52 iter, loss 0.5651880502700806
37 epoch, 53 iter, loss 0.6306105256080627
37 epoch, 54 iter, loss 0.54605633020401
37 epoch, 55 iter, loss 0.6858669519424438
37 epoch, 56 iter, loss 0.5979201197624207
37 epoch, 57 iter, loss 0.5588099956512451
37 epoch, Average loss 0.5771155299847586
./model/merge_model_Param_v39.pth
some of decrypted state:
tensor([[[[ 0.0661, -0.0519,  0.0548],
          [ 0.1298,  0.1429,  0.0834],
          [-0.0959, -0.0872, -0.0102]],

         [[-0.0278,  0.1221,  0.1401],
          [-0.0075,  0.0803, -0.1253],
          [-0.1381, -0.0561,  0.0691]],

         [[ 0.1048, -0.0989,  0.0140],
          [-0.0045, -0.0813,  0.0751],
          [ 0.1020,  0.1114, -0.1187]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1983, -0.1557,  0.1644],
          [ 0.3894,  0.4287,  0.2501],
          [-0.2878, -0.2616, -0.0305]],

         [[-0.0835,  0.3662,  0.4203],
          [-0.0224,  0.2410, -0.3758],
          [-0.4143, -0.1684,  0.2074]],

         [[ 0.3143, -0.2968,  0.0420],
          [-0.0135, -0.2439,  0.2254],
          [ 0.3060,  0.3343, -0.3562]]]], device='cuda:0')
start training
38 epoch, 1 iter, loss 0.4765912592411041
38 epoch, 2 iter, loss 0.5282666087150574
38 epoch, 3 iter, loss 0.5167767405509949
38 epoch, 4 iter, loss 0.5807493329048157
38 epoch, 5 iter, loss 0.5501354336738586
38 epoch, 6 iter, loss 0.49272477626800537
38 epoch, 7 iter, loss 0.5276684165000916
38 epoch, 8 iter, loss 0.650723934173584
38 epoch, 9 iter, loss 0.5214858055114746
38 epoch, 10 iter, loss 0.5475543737411499
38 epoch, 11 iter, loss 0.300726056098938
38 epoch, 12 iter, loss 0.44430115818977356
38 epoch, 13 iter, loss 0.4965851306915283
38 epoch, 14 iter, loss 0.6575237512588501
38 epoch, 15 iter, loss 0.5394142270088196
38 epoch, 16 iter, loss 0.49796849489212036
38 epoch, 17 iter, loss 0.9003490209579468
38 epoch, 18 iter, loss 0.6268173456192017
38 epoch, 19 iter, loss 0.6481208205223083
38 epoch, 20 iter, loss 0.5249125361442566
38 epoch, 21 iter, loss 0.5324922800064087
38 epoch, 22 iter, loss 0.5264177918434143
38 epoch, 23 iter, loss 0.5115232467651367
38 epoch, 24 iter, loss 0.5001359581947327
38 epoch, 25 iter, loss 0.533845841884613
38 epoch, 26 iter, loss 0.605355978012085
38 epoch, 27 iter, loss 0.5343772172927856
38 epoch, 28 iter, loss 0.5246657133102417
38 epoch, 29 iter, loss 0.3961262106895447
38 epoch, 30 iter, loss 0.6606932878494263
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
38 epoch, 31 iter, loss 0.6054178476333618
38 epoch, 32 iter, loss 0.4595668613910675
38 epoch, 33 iter, loss 0.677385687828064
38 epoch, 34 iter, loss 0.5786466598510742
38 epoch, 35 iter, loss 0.6850786209106445
38 epoch, 36 iter, loss 0.43139660358428955
38 epoch, 37 iter, loss 0.4804670810699463
38 epoch, 38 iter, loss 0.8461017608642578
38 epoch, 39 iter, loss 0.6095617413520813
38 epoch, 40 iter, loss 0.6054173111915588
38 epoch, 41 iter, loss 0.7399678826332092
38 epoch, 42 iter, loss 0.47687461972236633
38 epoch, 43 iter, loss 0.6690753698348999
38 epoch, 44 iter, loss 0.5716143846511841
38 epoch, 45 iter, loss 0.5584555864334106
38 epoch, 46 iter, loss 0.5637402534484863
38 epoch, 47 iter, loss 0.6131834387779236
38 epoch, 48 iter, loss 0.6222115159034729
38 epoch, 49 iter, loss 0.6495979428291321
38 epoch, 50 iter, loss 0.5930988192558289
38 epoch, 51 iter, loss 0.6431302428245544
38 epoch, 52 iter, loss 0.623103678226471
38 epoch, 53 iter, loss 0.43288764357566833
38 epoch, 54 iter, loss 0.5327483415603638
38 epoch, 55 iter, loss 0.6084932684898376
38 epoch, 56 iter, loss 0.7727538347244263
38 epoch, 57 iter, loss 0.4274101257324219
38 epoch, Average loss 0.5689897521546012
./model/merge_model_Param_v40.pth
some of decrypted state:
tensor([[[[ 0.0660, -0.0519,  0.0549],
          [ 0.1294,  0.1427,  0.0833],
          [-0.0975, -0.0888, -0.0116]],

         [[-0.0281,  0.1220,  0.1400],
          [-0.0078,  0.0801, -0.1254],
          [-0.1399, -0.0580,  0.0673]],

         [[ 0.1045, -0.0989,  0.0140],
          [-0.0045, -0.0811,  0.0752],
          [ 0.0999,  0.1093, -0.1205]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1980, -0.1557,  0.1647],
          [ 0.3883,  0.4280,  0.2499],
          [-0.2924, -0.2663, -0.0349]],

         [[-0.0843,  0.3661,  0.4199],
          [-0.0235,  0.2404, -0.3761],
          [-0.4198, -0.1740,  0.2019]],

         [[ 0.3134, -0.2966,  0.0419],
          [-0.0136, -0.2433,  0.2256],
          [ 0.2997,  0.3279, -0.3614]]]], device='cuda:0')
start training
39 epoch, 1 iter, loss 0.7871007323265076
39 epoch, 2 iter, loss 0.4007797837257385
39 epoch, 3 iter, loss 0.7264498472213745
39 epoch, 4 iter, loss 0.5523646473884583
39 epoch, 5 iter, loss 0.3614189028739929
39 epoch, 6 iter, loss 0.6096972823143005
39 epoch, 7 iter, loss 0.6525660157203674
39 epoch, 8 iter, loss 0.6560981273651123
39 epoch, 9 iter, loss 0.4942185878753662
39 epoch, 10 iter, loss 0.4649789035320282
39 epoch, 11 iter, loss 0.6006112098693848
39 epoch, 12 iter, loss 0.6857091188430786
39 epoch, 13 iter, loss 0.5311375856399536
39 epoch, 14 iter, loss 0.6442877054214478
39 epoch, 15 iter, loss 0.6796415448188782
39 epoch, 16 iter, loss 0.5855554342269897
39 epoch, 17 iter, loss 0.3732263743877411
39 epoch, 18 iter, loss 0.7073758244514465
39 epoch, 19 iter, loss 0.5625609755516052
39 epoch, 20 iter, loss 0.4761623442173004
39 epoch, 21 iter, loss 0.4147542417049408
39 epoch, 22 iter, loss 0.6062444448471069
39 epoch, 23 iter, loss 0.7306022644042969
39 epoch, 24 iter, loss 0.5295810103416443
39 epoch, 25 iter, loss 0.6643006205558777
39 epoch, 26 iter, loss 0.44920989871025085
39 epoch, 27 iter, loss 0.7057394981384277
39 epoch, 28 iter, loss 0.5884390473365784
39 epoch, 29 iter, loss 0.529348611831665
39 epoch, 30 iter, loss 0.37279728055000305
39 epoch, 31 iter, loss 0.48560652136802673
39 epoch, 32 iter, loss 0.5594874024391174
39 epoch, 33 iter, loss 0.5737863779067993
39 epoch, 34 iter, loss 0.4945792555809021
39 epoch, 35 iter, loss 0.5486143231391907
39 epoch, 36 iter, loss 0.5550881624221802
39 epoch, 37 iter, loss 0.7180250883102417
39 epoch, 38 iter, loss 0.6018852591514587
39 epoch, 39 iter, loss 0.6891193389892578
39 epoch, 40 iter, loss 0.4994482100009918
39 epoch, 41 iter, loss 0.45298701524734497
39 epoch, 42 iter, loss 0.6148233413696289
39 epoch, 43 iter, loss 0.5457814335823059
39 epoch, 44 iter, loss 0.4417923092842102
39 epoch, 45 iter, loss 0.6224119067192078
39 epoch, 46 iter, loss 0.5246198773384094
39 epoch, 47 iter, loss 0.5291674733161926
39 epoch, 48 iter, loss 0.6388629078865051
39 epoch, 49 iter, loss 0.4531458020210266
39 epoch, 50 iter, loss 0.6102559566497803
39 epoch, 51 iter, loss 0.4883580207824707
39 epoch, 52 iter, loss 0.6171594858169556
39 epoch, 53 iter, loss 0.6244677901268005
39 epoch, 54 iter, loss 0.500481903553009
39 epoch, 55 iter, loss 0.4257912337779999
39 epoch, 56 iter, loss 0.8788118362426758
39 epoch, 57 iter, loss 0.3464060425758362
39 epoch, Average loss 0.5646302130138665
./model/merge_model_Param_v41.pth
some of decrypted state:
tensor([[[[ 0.0660, -0.0520,  0.0547],
          [ 0.1299,  0.1431,  0.0834],
          [-0.0972, -0.0887, -0.0118]],

         [[-0.0279,  0.1222,  0.1400],
          [-0.0070,  0.0809, -0.1249],
          [-0.1397, -0.0578,  0.0672]],

         [[ 0.1043, -0.0991,  0.0137],
          [-0.0040, -0.0805,  0.0756],
          [ 0.0999,  0.1096, -0.1203]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1979, -0.1560,  0.1640],
          [ 0.3898,  0.4292,  0.2501],
          [-0.2917, -0.2662, -0.0355]],

         [[-0.0837,  0.3667,  0.4201],
          [-0.0210,  0.2427, -0.3747],
          [-0.4190, -0.1734,  0.2015]],

         [[ 0.3129, -0.2972,  0.0411],
          [-0.0120, -0.2414,  0.2268],
          [ 0.2996,  0.3287, -0.3608]]]], device='cuda:0')
start training
40 epoch, 1 iter, loss 0.708379328250885
40 epoch, 2 iter, loss 0.39518117904663086
40 epoch, 3 iter, loss 0.7160531878471375
40 epoch, 4 iter, loss 0.4521960914134979
40 epoch, 5 iter, loss 0.47897830605506897
40 epoch, 6 iter, loss 0.6467404365539551
40 epoch, 7 iter, loss 0.6545217037200928
40 epoch, 8 iter, loss 0.600994884967804
40 epoch, 9 iter, loss 0.5564076900482178
40 epoch, 10 iter, loss 0.5243996977806091
40 epoch, 11 iter, loss 0.4488585889339447
40 epoch, 12 iter, loss 0.4572228491306305
40 epoch, 13 iter, loss 0.4525098502635956
40 epoch, 14 iter, loss 0.6156036257743835
40 epoch, 15 iter, loss 0.3577134609222412
40 epoch, 16 iter, loss 0.5212719440460205
40 epoch, 17 iter, loss 0.5273920297622681
40 epoch, 18 iter, loss 0.8351036906242371
40 epoch, 19 iter, loss 0.6339092254638672
40 epoch, 20 iter, loss 0.640636146068573
40 epoch, 21 iter, loss 0.4055202305316925
40 epoch, 22 iter, loss 0.5899521112442017
40 epoch, 23 iter, loss 0.5589113831520081
40 epoch, 24 iter, loss 0.3761838972568512
40 epoch, 25 iter, loss 0.6621262431144714
40 epoch, 26 iter, loss 0.6235975623130798
40 epoch, 27 iter, loss 0.6660472750663757
40 epoch, 28 iter, loss 0.4677036702632904
40 epoch, 29 iter, loss 0.6323277354240417
40 epoch, 30 iter, loss 0.7047470211982727
40 epoch, 31 iter, loss 0.6493737697601318
40 epoch, 32 iter, loss 0.50143963098526
40 epoch, 33 iter, loss 0.5871902108192444
40 epoch, 34 iter, loss 0.6276598572731018
40 epoch, 35 iter, loss 0.6661518812179565
40 epoch, 36 iter, loss 0.5651101469993591
40 epoch, 37 iter, loss 0.6501147747039795
40 epoch, 38 iter, loss 0.4742804169654846
40 epoch, 39 iter, loss 0.5580216646194458
40 epoch, 40 iter, loss 0.5937173366546631
40 epoch, 41 iter, loss 0.39069128036499023
40 epoch, 42 iter, loss 0.4203539490699768
40 epoch, 43 iter, loss 0.3566244840621948
40 epoch, 44 iter, loss 0.5479463934898376
40 epoch, 45 iter, loss 0.8255133628845215
40 epoch, 46 iter, loss 0.39028245210647583
40 epoch, 47 iter, loss 0.47955700755119324
40 epoch, 48 iter, loss 0.43775030970573425
40 epoch, 49 iter, loss 0.49077028036117554
40 epoch, 50 iter, loss 0.6223856806755066
40 epoch, 51 iter, loss 0.6532824635505676
40 epoch, 52 iter, loss 0.6826174855232239
40 epoch, 53 iter, loss 0.4292246699333191
40 epoch, 54 iter, loss 0.41273707151412964
40 epoch, 55 iter, loss 0.5154802203178406
40 epoch, 56 iter, loss 0.6311066746711731
40 epoch, 57 iter, loss 0.46266549825668335
40 epoch, Average loss 0.553214737197809
./model/merge_model_Param_v42.pth
some of decrypted state:
tensor([[[[ 0.0660, -0.0516,  0.0552],
          [ 0.1304,  0.1437,  0.0837],
          [-0.0968, -0.0884, -0.0118]],

         [[-0.0288,  0.1218,  0.1396],
          [-0.0079,  0.0801, -0.1260],
          [-0.1404, -0.0586,  0.0660]],

         [[ 0.1029, -0.1000,  0.0130],
          [-0.0053, -0.0816,  0.0743],
          [ 0.0986,  0.1083, -0.1216]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1981, -0.1547,  0.1657],
          [ 0.3911,  0.4311,  0.2511],
          [-0.2905, -0.2652, -0.0355]],

         [[-0.0864,  0.3654,  0.4188],
          [-0.0237,  0.2404, -0.3779],
          [-0.4213, -0.1758,  0.1980]],

         [[ 0.3088, -0.3001,  0.0389],
          [-0.0160, -0.2449,  0.2228],
          [ 0.2957,  0.3250, -0.3649]]]], device='cuda:0')
start training
41 epoch, 1 iter, loss 0.4388829171657562
41 epoch, 2 iter, loss 0.44847726821899414
41 epoch, 3 iter, loss 0.5735982656478882
41 epoch, 4 iter, loss 0.6105127930641174
41 epoch, 5 iter, loss 0.7112451791763306
41 epoch, 6 iter, loss 0.6114810705184937
41 epoch, 7 iter, loss 0.5795539021492004
41 epoch, 8 iter, loss 0.4516332745552063
41 epoch, 9 iter, loss 0.6764775514602661
41 epoch, 10 iter, loss 0.5773358941078186
41 epoch, 11 iter, loss 0.4538950026035309
41 epoch, 12 iter, loss 0.7745662331581116
41 epoch, 13 iter, loss 0.6049753427505493
41 epoch, 14 iter, loss 0.4313923120498657
41 epoch, 15 iter, loss 0.5096220374107361
41 epoch, 16 iter, loss 0.6873497366905212
41 epoch, 17 iter, loss 0.5575084090232849
41 epoch, 18 iter, loss 0.5507923364639282
41 epoch, 19 iter, loss 0.5320972204208374
41 epoch, 20 iter, loss 0.6623731255531311
41 epoch, 21 iter, loss 0.6747527718544006
41 epoch, 22 iter, loss 0.6198100447654724
41 epoch, 23 iter, loss 0.5081173181533813
41 epoch, 24 iter, loss 0.6713617444038391
41 epoch, 25 iter, loss 0.7461036443710327
41 epoch, 26 iter, loss 0.5608458518981934
41 epoch, 27 iter, loss 0.5563185811042786
41 epoch, 28 iter, loss 0.4823547601699829
41 epoch, 29 iter, loss 0.4897807240486145
41 epoch, 30 iter, loss 0.3616009056568146
41 epoch, 31 iter, loss 0.5723345875740051
41 epoch, 32 iter, loss 0.5560552477836609
41 epoch, 33 iter, loss 0.37340301275253296
41 epoch, 34 iter, loss 0.48271337151527405
41 epoch, 35 iter, loss 0.7277779579162598
41 epoch, 36 iter, loss 0.4810112714767456
41 epoch, 37 iter, loss 0.6637547016143799
41 epoch, 38 iter, loss 0.5785645842552185
41 epoch, 39 iter, loss 0.619037389755249
41 epoch, 40 iter, loss 0.4912607669830322
41 epoch, 41 iter, loss 0.5041024684906006
41 epoch, 42 iter, loss 0.732772707939148
41 epoch, 43 iter, loss 0.5616556406021118
41 epoch, 44 iter, loss 0.5026821494102478
41 epoch, 45 iter, loss 0.5408086776733398
41 epoch, 46 iter, loss 0.3921531140804291
41 epoch, 47 iter, loss 0.4493778645992279
41 epoch, 48 iter, loss 0.5993074774742126
41 epoch, 49 iter, loss 0.4826965034008026
41 epoch, 50 iter, loss 0.625896692276001
41 epoch, 51 iter, loss 0.609459400177002
41 epoch, 52 iter, loss 0.6011468768119812
41 epoch, 53 iter, loss 0.47931718826293945
41 epoch, 54 iter, loss 0.5583145618438721
41 epoch, 55 iter, loss 0.5372281670570374
41 epoch, 56 iter, loss 0.4053319990634918
41 epoch, 57 iter, loss 0.3595981001853943
41 epoch, Average loss 0.5544312052559435
./model/merge_model_Param_v43.pth
some of decrypted state:
tensor([[[[ 0.0669, -0.0506,  0.0560],
          [ 0.1304,  0.1437,  0.0839],
          [-0.0965, -0.0880, -0.0115]],

         [[-0.0279,  0.1229,  0.1404],
          [-0.0077,  0.0804, -0.1254],
          [-0.1403, -0.0582,  0.0664]],

         [[ 0.1036, -0.0993,  0.0135],
          [-0.0052, -0.0812,  0.0749],
          [ 0.0987,  0.1089, -0.1208]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2008, -0.1518,  0.1681],
          [ 0.3913,  0.4310,  0.2517],
          [-0.2895, -0.2640, -0.0345]],

         [[-0.0837,  0.3687,  0.4211],
          [-0.0231,  0.2412, -0.3763],
          [-0.4209, -0.1746,  0.1991]],

         [[ 0.3107, -0.2980,  0.0406],
          [-0.0156, -0.2437,  0.2246],
          [ 0.2962,  0.3266, -0.3624]]]], device='cuda:0')
start training
42 epoch, 1 iter, loss 0.6545048952102661
42 epoch, 2 iter, loss 0.7030038833618164
42 epoch, 3 iter, loss 0.6818392276763916
42 epoch, 4 iter, loss 0.6122157573699951
42 epoch, 5 iter, loss 0.5274792909622192
42 epoch, 6 iter, loss 0.5296319127082825
42 epoch, 7 iter, loss 0.463011771440506
42 epoch, 8 iter, loss 0.5814980864524841
42 epoch, 9 iter, loss 0.427505761384964
42 epoch, 10 iter, loss 0.47739720344543457
42 epoch, 11 iter, loss 0.5843819975852966
42 epoch, 12 iter, loss 0.6028626561164856
42 epoch, 13 iter, loss 0.4442557394504547
42 epoch, 14 iter, loss 0.5820683240890503
42 epoch, 15 iter, loss 0.7402091026306152
42 epoch, 16 iter, loss 0.4953944683074951
42 epoch, 17 iter, loss 0.6763492226600647
42 epoch, 18 iter, loss 0.33246222138404846
42 epoch, 19 iter, loss 0.4690633714199066
42 epoch, 20 iter, loss 0.6875741481781006
42 epoch, 21 iter, loss 0.44246551394462585
42 epoch, 22 iter, loss 0.31349727511405945
42 epoch, 23 iter, loss 0.44021177291870117
42 epoch, 24 iter, loss 0.6918736100196838
42 epoch, 25 iter, loss 0.48601317405700684
42 epoch, 26 iter, loss 0.6702596545219421
42 epoch, 27 iter, loss 0.5131920576095581
42 epoch, 28 iter, loss 0.5017713904380798
42 epoch, 29 iter, loss 0.564685583114624
42 epoch, 30 iter, loss 0.8404759168624878
42 epoch, 31 iter, loss 0.668437659740448
42 epoch, 32 iter, loss 0.5122889280319214
42 epoch, 33 iter, loss 0.6724632382392883
42 epoch, 34 iter, loss 0.43975722789764404
42 epoch, 35 iter, loss 0.504237174987793
42 epoch, 36 iter, loss 0.5157170295715332
42 epoch, 37 iter, loss 0.7057416439056396
42 epoch, 38 iter, loss 0.6264932155609131
42 epoch, 39 iter, loss 0.4960209131240845
42 epoch, 40 iter, loss 0.4352405071258545
42 epoch, 41 iter, loss 0.5417391061782837
42 epoch, 42 iter, loss 0.6451817154884338
42 epoch, 43 iter, loss 0.6051613688468933
42 epoch, 44 iter, loss 0.5765575766563416
42 epoch, 45 iter, loss 1.1310806274414062
42 epoch, 46 iter, loss 0.40315908193588257
42 epoch, 47 iter, loss 0.5695005059242249
42 epoch, 48 iter, loss 0.48938608169555664
42 epoch, 49 iter, loss 0.6171568036079407
42 epoch, 50 iter, loss 0.7829333543777466
42 epoch, 51 iter, loss 0.5734793543815613
42 epoch, 52 iter, loss 0.48178306221961975
42 epoch, 53 iter, loss 0.536041259765625
42 epoch, 54 iter, loss 0.5617348551750183
42 epoch, 55 iter, loss 0.5160968899726868
42 epoch, 56 iter, loss 0.42711588740348816
42 epoch, 57 iter, loss 0.48705995082855225
42 epoch, Average loss 0.5659424563248953
./model/merge_model_Param_v44.pth
some of decrypted state:
tensor([[[[ 0.0672, -0.0504,  0.0561],
          [ 0.1315,  0.1443,  0.0844],
          [-0.0954, -0.0871, -0.0111]],

         [[-0.0275,  0.1234,  0.1407],
          [-0.0065,  0.0811, -0.1248],
          [-0.1391, -0.0570,  0.0671]],

         [[ 0.1037, -0.0992,  0.0136],
          [-0.0041, -0.0805,  0.0754],
          [ 0.0996,  0.1098, -0.1201]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2015, -0.1512,  0.1684],
          [ 0.3944,  0.4328,  0.2531],
          [-0.2863, -0.2613, -0.0332]],

         [[-0.0826,  0.3701,  0.4222],
          [-0.0195,  0.2434, -0.3744],
          [-0.4173, -0.1709,  0.2014]],

         [[ 0.3110, -0.2976,  0.0407],
          [-0.0122, -0.2416,  0.2261],
          [ 0.2987,  0.3294, -0.3602]]]], device='cuda:0')
start training
43 epoch, 1 iter, loss 0.657452404499054
43 epoch, 2 iter, loss 0.39179274439811707
43 epoch, 3 iter, loss 0.4549671411514282
43 epoch, 4 iter, loss 0.8073329329490662
43 epoch, 5 iter, loss 0.5462120175361633
43 epoch, 6 iter, loss 0.5750848650932312
43 epoch, 7 iter, loss 0.5025033950805664
43 epoch, 8 iter, loss 0.47015029191970825
43 epoch, 9 iter, loss 0.5601863265037537
43 epoch, 10 iter, loss 0.4749673008918762
43 epoch, 11 iter, loss 0.6474134922027588
43 epoch, 12 iter, loss 0.38828158378601074
43 epoch, 13 iter, loss 0.7611851096153259
43 epoch, 14 iter, loss 0.8257616758346558
43 epoch, 15 iter, loss 0.48943498730659485
43 epoch, 16 iter, loss 0.33268874883651733
43 epoch, 17 iter, loss 0.48070231080055237
43 epoch, 18 iter, loss 0.6040546298027039
43 epoch, 19 iter, loss 0.5449913740158081
43 epoch, 20 iter, loss 0.47311460971832275
43 epoch, 21 iter, loss 0.5187320113182068
43 epoch, 22 iter, loss 0.36322134733200073
43 epoch, 23 iter, loss 0.6148211359977722
43 epoch, 24 iter, loss 0.44050270318984985
43 epoch, 25 iter, loss 0.6368213295936584
43 epoch, 26 iter, loss 0.3637392520904541
43 epoch, 27 iter, loss 0.43474116921424866
43 epoch, 28 iter, loss 0.49035412073135376
43 epoch, 29 iter, loss 0.4558674097061157
43 epoch, 30 iter, loss 0.6801818609237671
43 epoch, 31 iter, loss 0.6616811752319336
43 epoch, 32 iter, loss 0.513407826423645
43 epoch, 33 iter, loss 0.48003464937210083
43 epoch, 34 iter, loss 0.5810799598693848
43 epoch, 35 iter, loss 0.5807089805603027
43 epoch, 36 iter, loss 0.5010138154029846
43 epoch, 37 iter, loss 0.5396426916122437
43 epoch, 38 iter, loss 0.5990859866142273
43 epoch, 39 iter, loss 0.6288530826568604
43 epoch, 40 iter, loss 0.7149892449378967
43 epoch, 41 iter, loss 0.589255690574646
43 epoch, 42 iter, loss 0.4180605113506317
43 epoch, 43 iter, loss 0.667912483215332
43 epoch, 44 iter, loss 0.33196792006492615
43 epoch, 45 iter, loss 0.7108100652694702
43 epoch, 46 iter, loss 0.4422152638435364
43 epoch, 47 iter, loss 0.4133501350879669
43 epoch, 48 iter, loss 0.5572649240493774
43 epoch, 49 iter, loss 0.5229445099830627
43 epoch, 50 iter, loss 0.5311108231544495
43 epoch, 51 iter, loss 0.6045467257499695
43 epoch, 52 iter, loss 0.48369279503822327
43 epoch, 53 iter, loss 0.3316822946071625
43 epoch, 54 iter, loss 0.40484628081321716
43 epoch, 55 iter, loss 0.51408451795578
43 epoch, 56 iter, loss 0.7746528387069702
43 epoch, 57 iter, loss 0.5340249538421631
43 epoch, Average loss 0.5371961478601422
./model/merge_model_Param_v45.pth
some of decrypted state:
tensor([[[[ 0.0670, -0.0508,  0.0557],
          [ 0.1313,  0.1443,  0.0846],
          [-0.0962, -0.0875, -0.0112]],

         [[-0.0275,  0.1231,  0.1403],
          [-0.0064,  0.0814, -0.1243],
          [-0.1396, -0.0572,  0.0672]],

         [[ 0.1037, -0.0994,  0.0133],
          [-0.0035, -0.0798,  0.0761],
          [ 0.0995,  0.1100, -0.1194]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2011, -0.1523,  0.1670],
          [ 0.3938,  0.4330,  0.2538],
          [-0.2887, -0.2626, -0.0336]],

         [[-0.0826,  0.3694,  0.4210],
          [-0.0193,  0.2443, -0.3729],
          [-0.4189, -0.1717,  0.2015]],

         [[ 0.3112, -0.2981,  0.0398],
          [-0.0106, -0.2393,  0.2284],
          [ 0.2985,  0.3301, -0.3582]]]], device='cuda:0')
start training
44 epoch, 1 iter, loss 0.6101433634757996
44 epoch, 2 iter, loss 0.5220324993133545
44 epoch, 3 iter, loss 0.6616474390029907
44 epoch, 4 iter, loss 0.6326719522476196
44 epoch, 5 iter, loss 0.5683372616767883
44 epoch, 6 iter, loss 0.6364919543266296
44 epoch, 7 iter, loss 0.45450925827026367
44 epoch, 8 iter, loss 0.5895734429359436
44 epoch, 9 iter, loss 0.7597054839134216
44 epoch, 10 iter, loss 0.41552695631980896
44 epoch, 11 iter, loss 0.5533977150917053
44 epoch, 12 iter, loss 0.5868651866912842
44 epoch, 13 iter, loss 0.3678501546382904
44 epoch, 14 iter, loss 0.5804060697555542
44 epoch, 15 iter, loss 0.4507594108581543
44 epoch, 16 iter, loss 0.5064793229103088
44 epoch, 17 iter, loss 0.5517418384552002
44 epoch, 18 iter, loss 0.5420858860015869
44 epoch, 19 iter, loss 0.47048816084861755
44 epoch, 20 iter, loss 0.47994092106819153
44 epoch, 21 iter, loss 0.6967188715934753
44 epoch, 22 iter, loss 0.5193634033203125
44 epoch, 23 iter, loss 0.8694248795509338
44 epoch, 24 iter, loss 0.4417155981063843
44 epoch, 25 iter, loss 0.610801637172699
44 epoch, 26 iter, loss 0.4709908962249756
44 epoch, 27 iter, loss 0.7554959058761597
44 epoch, 28 iter, loss 0.5182242393493652
44 epoch, 29 iter, loss 0.5316454172134399
44 epoch, 30 iter, loss 0.48401758074760437
44 epoch, 31 iter, loss 0.6906439661979675
44 epoch, 32 iter, loss 0.6510168313980103
44 epoch, 33 iter, loss 0.7999947667121887
44 epoch, 34 iter, loss 0.3998112082481384
44 epoch, 35 iter, loss 0.6193755269050598
44 epoch, 36 iter, loss 0.6060450673103333
44 epoch, 37 iter, loss 0.43371546268463135
44 epoch, 38 iter, loss 0.7967449426651001
44 epoch, 39 iter, loss 0.6400403380393982
44 epoch, 40 iter, loss 0.4900335371494293
44 epoch, 41 iter, loss 0.5315086245536804
44 epoch, 42 iter, loss 0.5387269854545593
44 epoch, 43 iter, loss 0.5551162362098694
44 epoch, 44 iter, loss 0.599306583404541
44 epoch, 45 iter, loss 0.601768434047699
44 epoch, 46 iter, loss 0.4442066252231598
44 epoch, 47 iter, loss 0.4143381416797638
44 epoch, 48 iter, loss 0.5635058879852295
44 epoch, 49 iter, loss 0.505676805973053
44 epoch, 50 iter, loss 0.5953363180160522
44 epoch, 51 iter, loss 0.6204791069030762
44 epoch, 52 iter, loss 0.4590131342411041
44 epoch, 53 iter, loss 0.4933149516582489
44 epoch, 54 iter, loss 0.4745766520500183
44 epoch, 55 iter, loss 0.3812994360923767
44 epoch, 56 iter, loss 0.6198606491088867
44 epoch, 57 iter, loss 0.7686319351196289
44 epoch, Average loss 0.5637393133682117
./model/merge_model_Param_v46.pth
some of decrypted state:
tensor([[[[ 0.0668, -0.0510,  0.0557],
          [ 0.1316,  0.1445,  0.0844],
          [-0.0963, -0.0878, -0.0121]],

         [[-0.0281,  0.1227,  0.1400],
          [-0.0066,  0.0810, -0.1250],
          [-0.1401, -0.0580,  0.0658]],

         [[ 0.1032, -0.0999,  0.0129],
          [-0.0034, -0.0799,  0.0755],
          [ 0.0995,  0.1096, -0.1203]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2003, -0.1530,  0.1670],
          [ 0.3947,  0.4334,  0.2533],
          [-0.2889, -0.2635, -0.0363]],

         [[-0.0844,  0.3681,  0.4200],
          [-0.0198,  0.2429, -0.3751],
          [-0.4203, -0.1741,  0.1974]],

         [[ 0.3095, -0.2997,  0.0387],
          [-0.0101, -0.2398,  0.2265],
          [ 0.2984,  0.3288, -0.3608]]]], device='cuda:0')
start training
45 epoch, 1 iter, loss 0.7799242734909058
45 epoch, 2 iter, loss 0.4533674716949463
45 epoch, 3 iter, loss 0.5347083806991577
45 epoch, 4 iter, loss 0.49872133135795593
45 epoch, 5 iter, loss 0.4472326338291168
45 epoch, 6 iter, loss 0.40327969193458557
45 epoch, 7 iter, loss 0.5527940988540649
45 epoch, 8 iter, loss 0.40359872579574585
45 epoch, 9 iter, loss 0.41717588901519775
45 epoch, 10 iter, loss 0.6755723357200623
45 epoch, 11 iter, loss 0.6902825236320496
45 epoch, 12 iter, loss 0.4413096010684967
45 epoch, 13 iter, loss 0.464639812707901
45 epoch, 14 iter, loss 0.6431096792221069
45 epoch, 15 iter, loss 0.4830204248428345
45 epoch, 16 iter, loss 0.4952744245529175
45 epoch, 17 iter, loss 0.43106240034103394
45 epoch, 18 iter, loss 0.8138225674629211
45 epoch, 19 iter, loss 0.6334915161132812
45 epoch, 20 iter, loss 0.4785447418689728
45 epoch, 21 iter, loss 0.36751630902290344
45 epoch, 22 iter, loss 0.44144442677497864
45 epoch, 23 iter, loss 0.5851216316223145
45 epoch, 24 iter, loss 0.6025750637054443
45 epoch, 25 iter, loss 0.3806728720664978
45 epoch, 26 iter, loss 0.517930805683136
45 epoch, 27 iter, loss 0.6373233795166016
45 epoch, 28 iter, loss 0.5380573272705078
45 epoch, 29 iter, loss 0.48648688197135925
45 epoch, 30 iter, loss 0.40401965379714966
45 epoch, 31 iter, loss 0.4970513582229614
45 epoch, 32 iter, loss 0.6111314296722412
45 epoch, 33 iter, loss 0.38436031341552734
45 epoch, 34 iter, loss 0.795128345489502
45 epoch, 35 iter, loss 0.690216064453125
45 epoch, 36 iter, loss 0.5879857540130615
45 epoch, 37 iter, loss 0.5381331443786621
45 epoch, 38 iter, loss 0.6130239367485046
45 epoch, 39 iter, loss 0.7529271245002747
45 epoch, 40 iter, loss 0.42409294843673706
45 epoch, 41 iter, loss 0.37928685545921326
45 epoch, 42 iter, loss 0.3033692240715027
45 epoch, 43 iter, loss 0.59685879945755
45 epoch, 44 iter, loss 0.4202725887298584
45 epoch, 45 iter, loss 0.3242533504962921
45 epoch, 46 iter, loss 0.6205118894577026
45 epoch, 47 iter, loss 0.6338022351264954
45 epoch, 48 iter, loss 0.41425082087516785
45 epoch, 49 iter, loss 0.515967607498169
45 epoch, 50 iter, loss 0.47306376695632935
45 epoch, 51 iter, loss 0.4678894579410553
45 epoch, 52 iter, loss 0.6770956516265869
45 epoch, 53 iter, loss 0.5964187383651733
45 epoch, 54 iter, loss 0.596341609954834
45 epoch, 55 iter, loss 0.366607666015625
45 epoch, 56 iter, loss 0.6433905959129333
45 epoch, 57 iter, loss 0.40245145559310913
45 epoch, Average loss 0.5268063790965498
./model/merge_model_Param_v47.pth
some of decrypted state:
tensor([[[[ 0.0666, -0.0512,  0.0556],
          [ 0.1318,  0.1448,  0.0848],
          [-0.0962, -0.0880, -0.0124]],

         [[-0.0280,  0.1227,  0.1398],
          [-0.0060,  0.0816, -0.1245],
          [-0.1396, -0.0580,  0.0657]],

         [[ 0.1033, -0.0999,  0.0129],
          [-0.0025, -0.0790,  0.0762],
          [ 0.1000,  0.1099, -0.1201]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1999, -0.1537,  0.1667],
          [ 0.3953,  0.4345,  0.2544],
          [-0.2885, -0.2640, -0.0371]],

         [[-0.0840,  0.3680,  0.4195],
          [-0.0179,  0.2449, -0.3735],
          [-0.4189, -0.1739,  0.1971]],

         [[ 0.3100, -0.2996,  0.0386],
          [-0.0076, -0.2371,  0.2285],
          [ 0.3000,  0.3296, -0.3603]]]], device='cuda:0')
start training
46 epoch, 1 iter, loss 0.5055792331695557
46 epoch, 2 iter, loss 0.37717607617378235
46 epoch, 3 iter, loss 0.7494208216667175
46 epoch, 4 iter, loss 0.4259400963783264
46 epoch, 5 iter, loss 0.3948471248149872
46 epoch, 6 iter, loss 0.46632200479507446
46 epoch, 7 iter, loss 0.5784063339233398
46 epoch, 8 iter, loss 0.4146357476711273
46 epoch, 9 iter, loss 0.44990912079811096
46 epoch, 10 iter, loss 0.6844390630722046
46 epoch, 11 iter, loss 0.5201143622398376
46 epoch, 12 iter, loss 0.5042880177497864
46 epoch, 13 iter, loss 0.3762909770011902
46 epoch, 14 iter, loss 0.5770506858825684
46 epoch, 15 iter, loss 0.3976041078567505
46 epoch, 16 iter, loss 0.32382991909980774
46 epoch, 17 iter, loss 0.5679876208305359
46 epoch, 18 iter, loss 0.6904786825180054
46 epoch, 19 iter, loss 0.44396209716796875
46 epoch, 20 iter, loss 0.37463268637657166
46 epoch, 21 iter, loss 0.6010218858718872
46 epoch, 22 iter, loss 0.6950898766517639
46 epoch, 23 iter, loss 0.6894444227218628
46 epoch, 24 iter, loss 0.4267139434814453
46 epoch, 25 iter, loss 0.6453260779380798
46 epoch, 26 iter, loss 0.39740750193595886
46 epoch, 27 iter, loss 0.6571767330169678
46 epoch, 28 iter, loss 0.5590712428092957
46 epoch, 29 iter, loss 0.6330955624580383
46 epoch, 30 iter, loss 0.4939706325531006
46 epoch, 31 iter, loss 0.32167983055114746
46 epoch, 32 iter, loss 0.4067131280899048
46 epoch, 33 iter, loss 0.6082539558410645
46 epoch, 34 iter, loss 0.41259053349494934
46 epoch, 35 iter, loss 0.5394243597984314
46 epoch, 36 iter, loss 0.5613128542900085
46 epoch, 37 iter, loss 0.722602903842926
46 epoch, 38 iter, loss 0.3367759883403778
46 epoch, 39 iter, loss 0.5451902151107788
46 epoch, 40 iter, loss 0.4615943729877472
46 epoch, 41 iter, loss 0.46626555919647217
46 epoch, 42 iter, loss 0.4156288802623749
46 epoch, 43 iter, loss 0.48673108220100403
46 epoch, 44 iter, loss 0.3792312443256378
46 epoch, 45 iter, loss 0.47978776693344116
46 epoch, 46 iter, loss 0.3736296594142914
46 epoch, 47 iter, loss 0.442427396774292
46 epoch, 48 iter, loss 0.4014909863471985
46 epoch, 49 iter, loss 0.3568490743637085
46 epoch, 50 iter, loss 0.3556748926639557
46 epoch, 51 iter, loss 0.615479052066803
46 epoch, 52 iter, loss 0.8292303085327148
46 epoch, 53 iter, loss 0.4919729232788086
46 epoch, 54 iter, loss 0.40446212887763977
46 epoch, 55 iter, loss 0.5806822776794434
46 epoch, 56 iter, loss 0.3086463510990143
46 epoch, 57 iter, loss 0.7271185517311096
46 epoch, Average loss 0.5026785778371912
./model/merge_model_Param_v48.pth
some of decrypted state:
tensor([[[[ 0.0656, -0.0521,  0.0548],
          [ 0.1323,  0.1454,  0.0853],
          [-0.0965, -0.0886, -0.0130]],

         [[-0.0287,  0.1220,  0.1392],
          [-0.0052,  0.0824, -0.1239],
          [-0.1398, -0.0584,  0.0651]],

         [[ 0.1023, -0.1006,  0.0122],
          [-0.0017, -0.0781,  0.0767],
          [ 0.0998,  0.1096, -0.1205]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1969, -0.1562,  0.1645],
          [ 0.3968,  0.4362,  0.2559],
          [-0.2896, -0.2657, -0.0389]],

         [[-0.0862,  0.3660,  0.4177],
          [-0.0157,  0.2472, -0.3718],
          [-0.4195, -0.1751,  0.1952]],

         [[ 0.3070, -0.3019,  0.0365],
          [-0.0052, -0.2344,  0.2302],
          [ 0.2995,  0.3287, -0.3616]]]], device='cuda:0')
start training
47 epoch, 1 iter, loss 0.5616031289100647
47 epoch, 2 iter, loss 0.6392654776573181
47 epoch, 3 iter, loss 0.41127631068229675
47 epoch, 4 iter, loss 0.5024560689926147
47 epoch, 5 iter, loss 0.4556691646575928
47 epoch, 6 iter, loss 0.2826094329357147
47 epoch, 7 iter, loss 0.5210555791854858
47 epoch, 8 iter, loss 0.5845443606376648
47 epoch, 9 iter, loss 0.4871867895126343
47 epoch, 10 iter, loss 0.43155983090400696
47 epoch, 11 iter, loss 0.456211119890213
47 epoch, 12 iter, loss 0.35757291316986084
47 epoch, 13 iter, loss 0.611425518989563
47 epoch, 14 iter, loss 0.5581244230270386
47 epoch, 15 iter, loss 0.49716320633888245
47 epoch, 16 iter, loss 0.4795435965061188
47 epoch, 17 iter, loss 0.4425719678401947
47 epoch, 18 iter, loss 0.6048280596733093
47 epoch, 19 iter, loss 0.5088896751403809
47 epoch, 20 iter, loss 0.4248039722442627
47 epoch, 21 iter, loss 0.520480751991272
47 epoch, 22 iter, loss 0.7743497490882874
47 epoch, 23 iter, loss 0.4469151198863983
47 epoch, 24 iter, loss 0.38013023138046265
47 epoch, 25 iter, loss 0.4089658558368683
47 epoch, 26 iter, loss 0.7393529415130615
47 epoch, 27 iter, loss 0.45315858721733093
47 epoch, 28 iter, loss 0.5688357949256897
47 epoch, 29 iter, loss 0.45614442229270935
47 epoch, 30 iter, loss 0.628193736076355
47 epoch, 31 iter, loss 0.48681050539016724
47 epoch, 32 iter, loss 0.6384039521217346
47 epoch, 33 iter, loss 0.4629034399986267
47 epoch, 34 iter, loss 0.5401598811149597
47 epoch, 35 iter, loss 0.5178152322769165
47 epoch, 36 iter, loss 0.3178427219390869
47 epoch, 37 iter, loss 0.4384455680847168
47 epoch, 38 iter, loss 0.4903546869754791
47 epoch, 39 iter, loss 0.41391685605049133
47 epoch, 40 iter, loss 0.4886619448661804
47 epoch, 41 iter, loss 0.5952116847038269
47 epoch, 42 iter, loss 0.610692024230957
47 epoch, 43 iter, loss 0.33092188835144043
47 epoch, 44 iter, loss 0.6167324185371399
47 epoch, 45 iter, loss 0.31813177466392517
47 epoch, 46 iter, loss 0.49663907289505005
47 epoch, 47 iter, loss 0.49798935651779175
47 epoch, 48 iter, loss 0.47189861536026
47 epoch, 49 iter, loss 0.6229981184005737
47 epoch, 50 iter, loss 0.5308735966682434
47 epoch, 51 iter, loss 0.6979597210884094
47 epoch, 52 iter, loss 0.3106154799461365
47 epoch, 53 iter, loss 0.48795387148857117
47 epoch, 54 iter, loss 0.4112735390663147
47 epoch, 55 iter, loss 0.5180461406707764
47 epoch, 56 iter, loss 0.5101993083953857
47 epoch, 57 iter, loss 0.5156357288360596
47 epoch, Average loss 0.5005960511533838
./model/merge_model_Param_v49.pth
some of decrypted state:
tensor([[[[ 0.0664, -0.0513,  0.0552],
          [ 0.1318,  0.1451,  0.0848],
          [-0.0968, -0.0887, -0.0129]],

         [[-0.0282,  0.1228,  0.1396],
          [-0.0058,  0.0817, -0.1246],
          [-0.1402, -0.0585,  0.0650]],

         [[ 0.1029, -0.0998,  0.0127],
          [-0.0022, -0.0787,  0.0761],
          [ 0.0997,  0.1096, -0.1202]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1991, -0.1540,  0.1656],
          [ 0.3955,  0.4352,  0.2545],
          [-0.2905, -0.2660, -0.0387]],

         [[-0.0846,  0.3683,  0.4188],
          [-0.0174,  0.2452, -0.3737],
          [-0.4206, -0.1756,  0.1950]],

         [[ 0.3086, -0.2994,  0.0380],
          [-0.0067, -0.2362,  0.2284],
          [ 0.2990,  0.3289, -0.3606]]]], device='cuda:0')
start training
48 epoch, 1 iter, loss 0.5998268723487854
48 epoch, 2 iter, loss 0.6105083227157593
48 epoch, 3 iter, loss 0.5095527768135071
48 epoch, 4 iter, loss 0.4178750514984131
48 epoch, 5 iter, loss 0.4480271637439728
48 epoch, 6 iter, loss 0.24616071581840515
48 epoch, 7 iter, loss 0.5001878142356873
48 epoch, 8 iter, loss 0.614872932434082
48 epoch, 9 iter, loss 0.3798181116580963
48 epoch, 10 iter, loss 0.4855878949165344
48 epoch, 11 iter, loss 0.5035752058029175
48 epoch, 12 iter, loss 0.5438122153282166
48 epoch, 13 iter, loss 0.39587265253067017
48 epoch, 14 iter, loss 0.5076733827590942
48 epoch, 15 iter, loss 0.3878735899925232
48 epoch, 16 iter, loss 0.4061942398548126
48 epoch, 17 iter, loss 0.5848148465156555
48 epoch, 18 iter, loss 0.5006967186927795
48 epoch, 19 iter, loss 0.3506637513637543
48 epoch, 20 iter, loss 0.39814743399620056
48 epoch, 21 iter, loss 0.3625456988811493
48 epoch, 22 iter, loss 0.5705071091651917
48 epoch, 23 iter, loss 0.5584069490432739
48 epoch, 24 iter, loss 0.3012664318084717
48 epoch, 25 iter, loss 0.8308016061782837
48 epoch, 26 iter, loss 0.553398847579956
48 epoch, 27 iter, loss 0.63304603099823
48 epoch, 28 iter, loss 0.49170294404029846
48 epoch, 29 iter, loss 0.42477452754974365
48 epoch, 30 iter, loss 0.4711572527885437
48 epoch, 31 iter, loss 0.37884828448295593
48 epoch, 32 iter, loss 0.3903633654117584
48 epoch, 33 iter, loss 0.5002634525299072
48 epoch, 34 iter, loss 0.5263599157333374
48 epoch, 35 iter, loss 0.6420088410377502
48 epoch, 36 iter, loss 0.43662527203559875
48 epoch, 37 iter, loss 0.5782452821731567
48 epoch, 38 iter, loss 0.44495710730552673
48 epoch, 39 iter, loss 0.5178214311599731
48 epoch, 40 iter, loss 0.41686758399009705
48 epoch, 41 iter, loss 0.43714234232902527
48 epoch, 42 iter, loss 0.44973888993263245
48 epoch, 43 iter, loss 0.26838478446006775
48 epoch, 44 iter, loss 0.5440586805343628
48 epoch, 45 iter, loss 0.4872165024280548
48 epoch, 46 iter, loss 0.3684794008731842
48 epoch, 47 iter, loss 0.4042607545852661
48 epoch, 48 iter, loss 0.359609454870224
48 epoch, 49 iter, loss 0.5018676519393921
48 epoch, 50 iter, loss 0.4374978840351105
48 epoch, 51 iter, loss 0.5064557194709778
48 epoch, 52 iter, loss 0.5039263367652893
48 epoch, 53 iter, loss 0.5615344047546387
48 epoch, 54 iter, loss 0.4580947160720825
48 epoch, 55 iter, loss 0.4723891019821167
48 epoch, 56 iter, loss 0.39755576848983765
48 epoch, 57 iter, loss 0.39045602083206177
48 epoch, Average loss 0.47316452703977885
./model/merge_model_Param_v50.pth
some of decrypted state:
tensor([[[[ 0.0662, -0.0516,  0.0550],
          [ 0.1320,  0.1453,  0.0850],
          [-0.0974, -0.0892, -0.0134]],

         [[-0.0282,  0.1226,  0.1393],
          [-0.0057,  0.0820, -0.1243],
          [-0.1409, -0.0592,  0.0645]],

         [[ 0.1028, -0.1000,  0.0124],
          [-0.0023, -0.0786,  0.0762],
          [ 0.0988,  0.1088, -0.1207]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.1986, -0.1547,  0.1649],
          [ 0.3959,  0.4359,  0.2550],
          [-0.2922, -0.2677, -0.0402]],

         [[-0.0845,  0.3677,  0.4180],
          [-0.0172,  0.2460, -0.3728],
          [-0.4227, -0.1776,  0.1934]],

         [[ 0.3083, -0.2999,  0.0373],
          [-0.0069, -0.2358,  0.2287],
          [ 0.2964,  0.3265, -0.3620]]]], device='cuda:0')
start training
49 epoch, 1 iter, loss 0.6081244349479675
49 epoch, 2 iter, loss 0.4924657642841339
49 epoch, 3 iter, loss 0.44427576661109924
49 epoch, 4 iter, loss 0.5195153951644897
49 epoch, 5 iter, loss 0.44439372420310974
49 epoch, 6 iter, loss 0.6103665828704834
49 epoch, 7 iter, loss 0.3479408323764801
49 epoch, 8 iter, loss 0.46170398592948914
49 epoch, 9 iter, loss 0.5508443117141724
49 epoch, 10 iter, loss 0.43222758173942566
49 epoch, 11 iter, loss 0.7247984409332275
49 epoch, 12 iter, loss 0.33962756395339966
49 epoch, 13 iter, loss 0.6434784531593323
49 epoch, 14 iter, loss 0.4709591567516327
49 epoch, 15 iter, loss 0.3784681260585785
49 epoch, 16 iter, loss 0.6599481105804443
49 epoch, 17 iter, loss 0.3276858925819397
49 epoch, 18 iter, loss 0.6246585249900818
49 epoch, 19 iter, loss 0.38063737750053406
49 epoch, 20 iter, loss 0.2709457576274872
49 epoch, 21 iter, loss 0.44817063212394714
49 epoch, 22 iter, loss 0.39681264758110046
49 epoch, 23 iter, loss 0.39197754859924316
49 epoch, 24 iter, loss 0.5085611343383789
49 epoch, 25 iter, loss 0.5963495969772339
49 epoch, 26 iter, loss 0.3664857745170593
49 epoch, 27 iter, loss 0.37372323870658875
49 epoch, 28 iter, loss 0.39740607142448425
49 epoch, 29 iter, loss 0.42238736152648926
49 epoch, 30 iter, loss 0.26312848925590515
49 epoch, 31 iter, loss 0.6323462724685669
49 epoch, 32 iter, loss 0.6259784698486328
49 epoch, 33 iter, loss 0.66172194480896
49 epoch, 34 iter, loss 0.6560608148574829
49 epoch, 35 iter, loss 0.6351640224456787
49 epoch, 36 iter, loss 0.4563782811164856
49 epoch, 37 iter, loss 0.37473949790000916
49 epoch, 38 iter, loss 0.5514369606971741
49 epoch, 39 iter, loss 0.4507971405982971
49 epoch, 40 iter, loss 0.4829421937465668
49 epoch, 41 iter, loss 0.2914467453956604
49 epoch, 42 iter, loss 0.4227510988712311
49 epoch, 43 iter, loss 0.46606945991516113
49 epoch, 44 iter, loss 0.42752206325531006
49 epoch, 45 iter, loss 0.4848019778728485
49 epoch, 46 iter, loss 0.5294957756996155
49 epoch, 47 iter, loss 0.4568420648574829
49 epoch, 48 iter, loss 0.49382245540618896
49 epoch, 49 iter, loss 0.5539535284042358
49 epoch, 50 iter, loss 0.5126626491546631
49 epoch, 51 iter, loss 0.5087127089500427
49 epoch, 52 iter, loss 0.32152611017227173
49 epoch, 53 iter, loss 0.42497146129608154
49 epoch, 54 iter, loss 0.4178658723831177
49 epoch, 55 iter, loss 0.427993506193161
49 epoch, 56 iter, loss 0.46904653310775757
49 epoch, 57 iter, loss 0.5145293474197388
49 epoch, Average loss 0.4763096006293046
./model/merge_model_Param_v51.pth
some of decrypted state:
tensor([[[[ 0.0668, -0.0510,  0.0555],
          [ 0.1329,  0.1463,  0.0865],
          [-0.0958, -0.0874, -0.0118]],

         [[-0.0273,  0.1233,  0.1398],
          [-0.0047,  0.0832, -0.1227],
          [-0.1395, -0.0576,  0.0659]],

         [[ 0.1031, -0.0995,  0.0127],
          [-0.0014, -0.0776,  0.0775],
          [ 0.0997,  0.1103, -0.1193]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2004, -0.1529,  0.1665],
          [ 0.3987,  0.4390,  0.2596],
          [-0.2875, -0.2623, -0.0354]],

         [[-0.0818,  0.3698,  0.4194],
          [-0.0141,  0.2495, -0.3682],
          [-0.4185, -0.1727,  0.1977]],

         [[ 0.3094, -0.2986,  0.0382],
          [-0.0041, -0.2328,  0.2324],
          [ 0.2991,  0.3308, -0.3578]]]], device='cuda:0')
start training
50 epoch, 1 iter, loss 0.6000711917877197
50 epoch, 2 iter, loss 0.2919401526451111
50 epoch, 3 iter, loss 0.6407362818717957
50 epoch, 4 iter, loss 0.32540783286094666
50 epoch, 5 iter, loss 0.542974054813385
50 epoch, 6 iter, loss 0.4709292948246002
50 epoch, 7 iter, loss 0.2867729961872101
50 epoch, 8 iter, loss 0.3503066897392273
50 epoch, 9 iter, loss 0.47696778178215027
50 epoch, 10 iter, loss 0.5837345123291016
50 epoch, 11 iter, loss 0.5668151378631592
50 epoch, 12 iter, loss 0.3846123516559601
50 epoch, 13 iter, loss 0.632976233959198
50 epoch, 14 iter, loss 0.5844211578369141
50 epoch, 15 iter, loss 0.7352778315544128
50 epoch, 16 iter, loss 0.28503769636154175
50 epoch, 17 iter, loss 0.4739871919155121
50 epoch, 18 iter, loss 0.5541250705718994
50 epoch, 19 iter, loss 0.6461303234100342
50 epoch, 20 iter, loss 0.5732975006103516
50 epoch, 21 iter, loss 0.4194941520690918
50 epoch, 22 iter, loss 0.624434769153595
50 epoch, 23 iter, loss 0.4354792833328247
50 epoch, 24 iter, loss 0.6032037138938904
50 epoch, 25 iter, loss 0.5558589696884155
50 epoch, 26 iter, loss 0.4664156436920166
50 epoch, 27 iter, loss 0.6148709058761597
50 epoch, 28 iter, loss 0.5431790351867676
50 epoch, 29 iter, loss 0.5497406721115112
50 epoch, 30 iter, loss 0.4582401216030121
50 epoch, 31 iter, loss 0.6168467402458191
50 epoch, 32 iter, loss 0.3631341755390167
50 epoch, 33 iter, loss 0.4870778024196625
50 epoch, 34 iter, loss 0.6279894113540649
50 epoch, 35 iter, loss 0.40795639157295227
50 epoch, 36 iter, loss 0.4295175075531006
50 epoch, 37 iter, loss 0.5214633941650391
50 epoch, 38 iter, loss 0.6025484800338745
50 epoch, 39 iter, loss 0.6251639127731323
50 epoch, 40 iter, loss 0.5519833564758301
50 epoch, 41 iter, loss 0.47141754627227783
50 epoch, 42 iter, loss 0.48628732562065125
50 epoch, 43 iter, loss 0.42245906591415405
50 epoch, 44 iter, loss 0.6871076822280884
50 epoch, 45 iter, loss 0.57149338722229
50 epoch, 46 iter, loss 0.52564537525177
50 epoch, 47 iter, loss 0.3851873278617859
50 epoch, 48 iter, loss 0.4878861606121063
50 epoch, 49 iter, loss 0.47943827509880066
50 epoch, 50 iter, loss 0.47193804383277893
50 epoch, 51 iter, loss 0.5968102812767029
50 epoch, 52 iter, loss 0.3640119135379791
50 epoch, 53 iter, loss 0.4651664197444916
50 epoch, 54 iter, loss 0.5393582582473755
50 epoch, 55 iter, loss 0.4483277201652527
50 epoch, 56 iter, loss 0.5381004214286804
50 epoch, 57 iter, loss 0.3009732663631439
50 epoch, Average loss 0.5044338279648831
./model/merge_model_Param_v52.pth
some of decrypted state:
tensor([[[[ 0.0675, -0.0506,  0.0555],
          [ 0.1331,  0.1464,  0.0865],
          [-0.0952, -0.0870, -0.0117]],

         [[-0.0263,  0.1240,  0.1401],
          [-0.0046,  0.0831, -0.1230],
          [-0.1390, -0.0571,  0.0661]],

         [[ 0.1037, -0.0992,  0.0127],
          [-0.0015, -0.0779,  0.0769],
          [ 0.1000,  0.1105, -0.1190]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2026, -0.1519,  0.1664],
          [ 0.3992,  0.4393,  0.2594],
          [-0.2856, -0.2611, -0.0352]],

         [[-0.0789,  0.3720,  0.4204],
          [-0.0138,  0.2492, -0.3689],
          [-0.4169, -0.1714,  0.1983]],

         [[ 0.3110, -0.2975,  0.0380],
          [-0.0046, -0.2338,  0.2308],
          [ 0.2999,  0.3315, -0.3570]]]], device='cuda:0')
start training
51 epoch, 1 iter, loss 0.4869972765445709
51 epoch, 2 iter, loss 0.4237155020236969
51 epoch, 3 iter, loss 0.6138792037963867
51 epoch, 4 iter, loss 0.41292205452919006
51 epoch, 5 iter, loss 0.3747163414955139
51 epoch, 6 iter, loss 0.40108391642570496
51 epoch, 7 iter, loss 0.4965418577194214
51 epoch, 8 iter, loss 0.5214645862579346
51 epoch, 9 iter, loss 0.4150119423866272
51 epoch, 10 iter, loss 0.44661808013916016
51 epoch, 11 iter, loss 0.4617936313152313
51 epoch, 12 iter, loss 0.39866548776626587
51 epoch, 13 iter, loss 0.6015462279319763
51 epoch, 14 iter, loss 0.4267416298389435
51 epoch, 15 iter, loss 0.49726027250289917
51 epoch, 16 iter, loss 0.34881657361984253
51 epoch, 17 iter, loss 0.34522745013237
51 epoch, 18 iter, loss 0.3301560580730438
51 epoch, 19 iter, loss 0.5708847641944885
51 epoch, 20 iter, loss 0.47175687551498413
51 epoch, 21 iter, loss 0.5043535828590393
51 epoch, 22 iter, loss 0.485062837600708
51 epoch, 23 iter, loss 0.504584014415741
51 epoch, 24 iter, loss 0.43744179606437683
51 epoch, 25 iter, loss 0.49486997723579407
51 epoch, 26 iter, loss 0.36463648080825806
51 epoch, 27 iter, loss 0.6064146757125854
51 epoch, 28 iter, loss 0.4789492189884186
51 epoch, 29 iter, loss 0.6683869361877441
51 epoch, 30 iter, loss 0.47296181321144104
51 epoch, 31 iter, loss 0.3988209068775177
51 epoch, 32 iter, loss 0.7076332569122314
51 epoch, 33 iter, loss 0.5994519591331482
51 epoch, 34 iter, loss 0.3696403503417969
51 epoch, 35 iter, loss 0.4292149543762207
51 epoch, 36 iter, loss 0.6602523922920227
51 epoch, 37 iter, loss 0.4393085241317749
51 epoch, 38 iter, loss 0.35008227825164795
51 epoch, 39 iter, loss 0.5592342615127563
51 epoch, 40 iter, loss 0.463012158870697
51 epoch, 41 iter, loss 0.6811959147453308
51 epoch, 42 iter, loss 0.4621305465698242
51 epoch, 43 iter, loss 0.5154289603233337
51 epoch, 44 iter, loss 0.44867849349975586
51 epoch, 45 iter, loss 0.3076884150505066
51 epoch, 46 iter, loss 0.5687640309333801
51 epoch, 47 iter, loss 0.3801562786102295
51 epoch, 48 iter, loss 0.3697088658809662
51 epoch, 49 iter, loss 0.586371660232544
51 epoch, 50 iter, loss 0.5372979640960693
51 epoch, 51 iter, loss 0.45899996161460876
51 epoch, 52 iter, loss 0.43040749430656433
51 epoch, 53 iter, loss 0.5541785359382629
51 epoch, 54 iter, loss 0.4760861396789551
51 epoch, 55 iter, loss 0.5340244770050049
51 epoch, 56 iter, loss 0.6380016803741455
51 epoch, 57 iter, loss 0.7646612524986267
51 epoch, Average loss 0.4869103996377242
./model/merge_model_Param_v53.pth
some of decrypted state:
tensor([[[[ 0.0679, -0.0503,  0.0554],
          [ 0.1331,  0.1466,  0.0867],
          [-0.0951, -0.0868, -0.0116]],

         [[-0.0259,  0.1243,  0.1401],
          [-0.0042,  0.0834, -0.1226],
          [-0.1388, -0.0570,  0.0661]],

         [[ 0.1040, -0.0990,  0.0125],
          [-0.0010, -0.0775,  0.0772],
          [ 0.1001,  0.1107, -0.1189]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2036, -0.1510,  0.1662],
          [ 0.3992,  0.4399,  0.2601],
          [-0.2852, -0.2603, -0.0349]],

         [[-0.0776,  0.3730,  0.4202],
          [-0.0127,  0.2501, -0.3679],
          [-0.4165, -0.1710,  0.1983]],

         [[ 0.3119, -0.2969,  0.0374],
          [-0.0030, -0.2324,  0.2316],
          [ 0.3004,  0.3322, -0.3566]]]], device='cuda:0')
start training
52 epoch, 1 iter, loss 0.40921780467033386
52 epoch, 2 iter, loss 0.3122738003730774
52 epoch, 3 iter, loss 0.5413000583648682
52 epoch, 4 iter, loss 0.6643800735473633
52 epoch, 5 iter, loss 0.46143874526023865
52 epoch, 6 iter, loss 0.5656432509422302
52 epoch, 7 iter, loss 0.4440852403640747
52 epoch, 8 iter, loss 0.25801026821136475
52 epoch, 9 iter, loss 0.39999598264694214
52 epoch, 10 iter, loss 0.6638939380645752
52 epoch, 11 iter, loss 0.4269335865974426
52 epoch, 12 iter, loss 0.37610188126564026
52 epoch, 13 iter, loss 0.28192418813705444
52 epoch, 14 iter, loss 0.3274555206298828
52 epoch, 15 iter, loss 0.43852999806404114
52 epoch, 16 iter, loss 0.39649519324302673
52 epoch, 17 iter, loss 0.5150955319404602
52 epoch, 18 iter, loss 0.37225499749183655
52 epoch, 19 iter, loss 0.4703191816806793
52 epoch, 20 iter, loss 0.4089184105396271
52 epoch, 21 iter, loss 0.49166420102119446
52 epoch, 22 iter, loss 0.36055251955986023
52 epoch, 23 iter, loss 0.39304986596107483
52 epoch, 24 iter, loss 0.40954381227493286
52 epoch, 25 iter, loss 0.3743254244327545
52 epoch, 26 iter, loss 0.4782026708126068
52 epoch, 27 iter, loss 0.3369598388671875
52 epoch, 28 iter, loss 0.5856748819351196
52 epoch, 29 iter, loss 0.5490146279335022
52 epoch, 30 iter, loss 0.24615183472633362
52 epoch, 31 iter, loss 0.6991720199584961
52 epoch, 32 iter, loss 0.6421331167221069
52 epoch, 33 iter, loss 0.611428439617157
52 epoch, 34 iter, loss 0.5614174604415894
52 epoch, 35 iter, loss 0.7214020490646362
52 epoch, 36 iter, loss 0.4354863464832306
52 epoch, 37 iter, loss 0.3869917392730713
52 epoch, 38 iter, loss 0.5574197173118591
52 epoch, 39 iter, loss 0.5133347511291504
52 epoch, 40 iter, loss 0.5202863216400146
52 epoch, 41 iter, loss 0.43009674549102783
52 epoch, 42 iter, loss 0.4909280836582184
52 epoch, 43 iter, loss 0.4192532002925873
52 epoch, 44 iter, loss 0.2683055102825165
52 epoch, 45 iter, loss 0.5408245325088501
52 epoch, 46 iter, loss 0.5767971277236938
52 epoch, 47 iter, loss 0.5422551035881042
52 epoch, 48 iter, loss 0.4449244439601898
52 epoch, 49 iter, loss 0.3506262004375458
52 epoch, 50 iter, loss 0.4200226962566376
52 epoch, 51 iter, loss 0.4796468913555145
52 epoch, 52 iter, loss 0.4095141291618347
52 epoch, 53 iter, loss 0.5589072108268738
52 epoch, 54 iter, loss 0.36044344305992126
52 epoch, 55 iter, loss 0.3505774438381195
52 epoch, 56 iter, loss 0.5193331837654114
52 epoch, 57 iter, loss 0.4426463544368744
52 epoch, Average loss 0.4598873963481502
./model/merge_model_Param_v54.pth
some of decrypted state:
tensor([[[[ 0.0684, -0.0497,  0.0559],
          [ 0.1330,  0.1466,  0.0867],
          [-0.0947, -0.0862, -0.0112]],

         [[-0.0253,  0.1250,  0.1405],
          [-0.0042,  0.0833, -0.1227],
          [-0.1384, -0.0566,  0.0664]],

         [[ 0.1045, -0.0982,  0.0129],
          [-0.0009, -0.0774,  0.0771],
          [ 0.1006,  0.1112, -0.1185]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2053, -0.1491,  0.1677],
          [ 0.3989,  0.4397,  0.2601],
          [-0.2840, -0.2586, -0.0335]],

         [[-0.0758,  0.3750,  0.4214],
          [-0.0127,  0.2500, -0.3680],
          [-0.4153, -0.1697,  0.1993]],

         [[ 0.3136, -0.2947,  0.0388],
          [-0.0027, -0.2321,  0.2314],
          [ 0.3017,  0.3335, -0.3555]]]], device='cuda:0')
start training
53 epoch, 1 iter, loss 0.5212039947509766
53 epoch, 2 iter, loss 0.3113052248954773
53 epoch, 3 iter, loss 0.36211758852005005
53 epoch, 4 iter, loss 0.41627374291419983
53 epoch, 5 iter, loss 0.5559452176094055
53 epoch, 6 iter, loss 0.5109296441078186
53 epoch, 7 iter, loss 0.3817950189113617
53 epoch, 8 iter, loss 0.5049155950546265
53 epoch, 9 iter, loss 0.45653998851776123
53 epoch, 10 iter, loss 0.3110201954841614
53 epoch, 11 iter, loss 0.472474604845047
53 epoch, 12 iter, loss 0.484375923871994
53 epoch, 13 iter, loss 0.6270854473114014
53 epoch, 14 iter, loss 0.3334484398365021
53 epoch, 15 iter, loss 0.35199931263923645
53 epoch, 16 iter, loss 0.43777528405189514
53 epoch, 17 iter, loss 0.33099570870399475
53 epoch, 18 iter, loss 0.696783185005188
53 epoch, 19 iter, loss 0.642534077167511
53 epoch, 20 iter, loss 0.40404918789863586
53 epoch, 21 iter, loss 0.5520970225334167
53 epoch, 22 iter, loss 0.603817343711853
53 epoch, 23 iter, loss 0.7835971117019653
53 epoch, 24 iter, loss 0.40071794390678406
53 epoch, 25 iter, loss 0.493171364068985
53 epoch, 26 iter, loss 0.3683268129825592
53 epoch, 27 iter, loss 0.46869122982025146
53 epoch, 28 iter, loss 0.48249316215515137
53 epoch, 29 iter, loss 0.4666663110256195
53 epoch, 30 iter, loss 0.6093539595603943
53 epoch, 31 iter, loss 0.367618203163147
53 epoch, 32 iter, loss 0.30262789130210876
53 epoch, 33 iter, loss 0.5010632872581482
53 epoch, 34 iter, loss 0.6600103974342346
53 epoch, 35 iter, loss 0.30403217673301697
53 epoch, 36 iter, loss 0.4057207405567169
53 epoch, 37 iter, loss 0.6155717372894287
53 epoch, 38 iter, loss 0.4671338200569153
53 epoch, 39 iter, loss 0.5128369331359863
53 epoch, 40 iter, loss 0.4916873574256897
53 epoch, 41 iter, loss 0.564869225025177
53 epoch, 42 iter, loss 0.45918118953704834
53 epoch, 43 iter, loss 0.4527990221977234
53 epoch, 44 iter, loss 0.5647108554840088
53 epoch, 45 iter, loss 0.4102558195590973
53 epoch, 46 iter, loss 0.5010117292404175
53 epoch, 47 iter, loss 0.4704558253288269
53 epoch, 48 iter, loss 0.3493087589740753
53 epoch, 49 iter, loss 0.4367006719112396
53 epoch, 50 iter, loss 0.5253292322158813
53 epoch, 51 iter, loss 0.5006799101829529
53 epoch, 52 iter, loss 0.45981234312057495
53 epoch, 53 iter, loss 0.3537875711917877
53 epoch, 54 iter, loss 0.47409871220588684
53 epoch, 55 iter, loss 0.351284384727478
53 epoch, 56 iter, loss 0.49902990460395813
53 epoch, 57 iter, loss 0.2995280921459198
53 epoch, Average loss 0.46743237606266086
./model/merge_model_Param_v55.pth
some of decrypted state:
tensor([[[[ 0.0683, -0.0500,  0.0558],
          [ 0.1331,  0.1469,  0.0870],
          [-0.0950, -0.0865, -0.0113]],

         [[-0.0257,  0.1245,  0.1401],
          [-0.0044,  0.0834, -0.1227],
          [-0.1393, -0.0572,  0.0658]],

         [[ 0.1043, -0.0985,  0.0127],
          [-0.0010, -0.0772,  0.0770],
          [ 0.0997,  0.1105, -0.1190]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2049, -0.1499,  0.1674],
          [ 0.3992,  0.4406,  0.2609],
          [-0.2850, -0.2595, -0.0338]],

         [[-0.0770,  0.3736,  0.4203],
          [-0.0131,  0.2501, -0.3682],
          [-0.4178, -0.1717,  0.1975]],

         [[ 0.3128, -0.2954,  0.0380],
          [-0.0030, -0.2317,  0.2311],
          [ 0.2990,  0.3316, -0.3569]]]], device='cuda:0')
start training
54 epoch, 1 iter, loss 0.3649422824382782
54 epoch, 2 iter, loss 0.48995912075042725
54 epoch, 3 iter, loss 0.532984733581543
54 epoch, 4 iter, loss 0.27978992462158203
54 epoch, 5 iter, loss 0.29192879796028137
54 epoch, 6 iter, loss 0.4900240898132324
54 epoch, 7 iter, loss 0.44291070103645325
54 epoch, 8 iter, loss 0.527863085269928
54 epoch, 9 iter, loss 0.38984647393226624
54 epoch, 10 iter, loss 0.42431995272636414
54 epoch, 11 iter, loss 0.4417450428009033
54 epoch, 12 iter, loss 0.35785892605781555
54 epoch, 13 iter, loss 0.4414246678352356
54 epoch, 14 iter, loss 0.29902687668800354
54 epoch, 15 iter, loss 0.43956485390663147
54 epoch, 16 iter, loss 0.5789996981620789
54 epoch, 17 iter, loss 0.4272001385688782
54 epoch, 18 iter, loss 0.48935744166374207
54 epoch, 19 iter, loss 0.31646642088890076
54 epoch, 20 iter, loss 0.8730452656745911
54 epoch, 21 iter, loss 0.4311304986476898
54 epoch, 22 iter, loss 0.4622645676136017
54 epoch, 23 iter, loss 0.33902689814567566
54 epoch, 24 iter, loss 0.5348073244094849
54 epoch, 25 iter, loss 0.4751838445663452
54 epoch, 26 iter, loss 0.3774537742137909
54 epoch, 27 iter, loss 0.543677568435669
54 epoch, 28 iter, loss 0.6471041440963745
54 epoch, 29 iter, loss 0.27422207593917847
54 epoch, 30 iter, loss 0.6046164035797119
54 epoch, 31 iter, loss 0.46844732761383057
54 epoch, 32 iter, loss 0.5276713371276855
54 epoch, 33 iter, loss 0.6121875643730164
54 epoch, 34 iter, loss 0.46773436665534973
54 epoch, 35 iter, loss 0.46220433712005615
54 epoch, 36 iter, loss 0.4201936423778534
54 epoch, 37 iter, loss 0.42450132966041565
54 epoch, 38 iter, loss 0.49161291122436523
54 epoch, 39 iter, loss 0.35101327300071716
54 epoch, 40 iter, loss 0.49123552441596985
54 epoch, 41 iter, loss 0.45595407485961914
54 epoch, 42 iter, loss 0.319681853055954
54 epoch, 43 iter, loss 0.5691307783126831
54 epoch, 44 iter, loss 0.43847569823265076
54 epoch, 45 iter, loss 0.3304983675479889
54 epoch, 46 iter, loss 0.5040898323059082
54 epoch, 47 iter, loss 0.41679561138153076
54 epoch, 48 iter, loss 0.6669063568115234
54 epoch, 49 iter, loss 0.6016314029693604
54 epoch, 50 iter, loss 0.524962842464447
54 epoch, 51 iter, loss 0.3068923056125641
54 epoch, 52 iter, loss 0.5359127521514893
54 epoch, 53 iter, loss 0.35254424810409546
54 epoch, 54 iter, loss 0.46998924016952515
54 epoch, 55 iter, loss 0.5132064819335938
54 epoch, 56 iter, loss 0.33675655722618103
54 epoch, 57 iter, loss 0.3055204749107361
54 epoch, Average loss 0.45534203659024153
./model/merge_model_Param_v56.pth
some of decrypted state:
tensor([[[[ 0.0681, -0.0502,  0.0555],
          [ 0.1329,  0.1470,  0.0872],
          [-0.0955, -0.0867, -0.0112]],

         [[-0.0255,  0.1246,  0.1400],
          [-0.0041,  0.0839, -0.1221],
          [-0.1394, -0.0572,  0.0660]],

         [[ 0.1044, -0.0985,  0.0125],
          [-0.0006, -0.0765,  0.0777],
          [ 0.0997,  0.1108, -0.1185]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2043, -0.1505,  0.1666],
          [ 0.3988,  0.4410,  0.2616],
          [-0.2865, -0.2601, -0.0335]],

         [[-0.0765,  0.3737,  0.4201],
          [-0.0123,  0.2518, -0.3663],
          [-0.4183, -0.1717,  0.1980]],

         [[ 0.3131, -0.2954,  0.0374],
          [-0.0019, -0.2296,  0.2331],
          [ 0.2990,  0.3323, -0.3555]]]], device='cuda:0')
start training
55 epoch, 1 iter, loss 0.25012052059173584
55 epoch, 2 iter, loss 0.2996149957180023
55 epoch, 3 iter, loss 0.38959813117980957
55 epoch, 4 iter, loss 0.6152344346046448
55 epoch, 5 iter, loss 0.4090024530887604
55 epoch, 6 iter, loss 0.1851586103439331
55 epoch, 7 iter, loss 0.23889800906181335
55 epoch, 8 iter, loss 0.4107704758644104
55 epoch, 9 iter, loss 0.36638328433036804
55 epoch, 10 iter, loss 0.39700958132743835
55 epoch, 11 iter, loss 0.45404449105262756
55 epoch, 12 iter, loss 0.30319744348526
55 epoch, 13 iter, loss 0.463040292263031
55 epoch, 14 iter, loss 0.40296033024787903
55 epoch, 15 iter, loss 0.34127452969551086
55 epoch, 16 iter, loss 0.5562242865562439
55 epoch, 17 iter, loss 0.3875787556171417
55 epoch, 18 iter, loss 0.5524382591247559
55 epoch, 19 iter, loss 0.5122730135917664
55 epoch, 20 iter, loss 0.6077070832252502
55 epoch, 21 iter, loss 0.38233909010887146
55 epoch, 22 iter, loss 0.34898003935813904
55 epoch, 23 iter, loss 0.3333199918270111
55 epoch, 24 iter, loss 0.47869613766670227
55 epoch, 25 iter, loss 0.31224486231803894
55 epoch, 26 iter, loss 0.4019448757171631
55 epoch, 27 iter, loss 0.5108110904693604
55 epoch, 28 iter, loss 0.4303508996963501
55 epoch, 29 iter, loss 0.4850103557109833
55 epoch, 30 iter, loss 0.3257231116294861
55 epoch, 31 iter, loss 0.39513343572616577
55 epoch, 32 iter, loss 0.5957607626914978
55 epoch, 33 iter, loss 0.4043479263782501
55 epoch, 34 iter, loss 0.30756932497024536
55 epoch, 35 iter, loss 0.590836763381958
55 epoch, 36 iter, loss 0.4858334958553314
55 epoch, 37 iter, loss 0.5477886199951172
55 epoch, 38 iter, loss 0.42953258752822876
55 epoch, 39 iter, loss 0.44481346011161804
55 epoch, 40 iter, loss 0.4016018807888031
55 epoch, 41 iter, loss 0.5226626396179199
55 epoch, 42 iter, loss 0.41409891843795776
55 epoch, 43 iter, loss 0.2100643366575241
55 epoch, 44 iter, loss 0.39392444491386414
55 epoch, 45 iter, loss 0.3414073586463928
55 epoch, 46 iter, loss 0.3490089774131775
55 epoch, 47 iter, loss 0.3694508969783783
55 epoch, 48 iter, loss 0.44052067399024963
55 epoch, 49 iter, loss 0.5382741689682007
55 epoch, 50 iter, loss 0.4858870506286621
55 epoch, 51 iter, loss 0.41201382875442505
55 epoch, 52 iter, loss 0.42149949073791504
55 epoch, 53 iter, loss 0.5907891392707825
55 epoch, 54 iter, loss 0.7128061056137085
55 epoch, 55 iter, loss 0.8956626057624817
55 epoch, 56 iter, loss 0.6500022411346436
55 epoch, 57 iter, loss 0.6265621781349182
55 epoch, Average loss 0.44087373243089306
./model/merge_model_Param_v57.pth
some of decrypted state:
tensor([[[[ 0.0680, -0.0503,  0.0553],
          [ 0.1331,  0.1471,  0.0870],
          [-0.0957, -0.0870, -0.0115]],

         [[-0.0254,  0.1247,  0.1401],
          [-0.0037,  0.0842, -0.1219],
          [-0.1397, -0.0574,  0.0659]],

         [[ 0.1043, -0.0984,  0.0125],
          [-0.0004, -0.0763,  0.0778],
          [ 0.0991,  0.1104, -0.1187]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2041, -0.1508,  0.1660],
          [ 0.3994,  0.4413,  0.2611],
          [-0.2871, -0.2610, -0.0344]],

         [[-0.0762,  0.3741,  0.4204],
          [-0.0110,  0.2526, -0.3657],
          [-0.4191, -0.1722,  0.1977]],

         [[ 0.3130, -0.2951,  0.0376],
          [-0.0013, -0.2288,  0.2333],
          [ 0.2973,  0.3311, -0.3560]]]], device='cuda:0')
start training
56 epoch, 1 iter, loss 0.4129538834095001
56 epoch, 2 iter, loss 0.6967424750328064
56 epoch, 3 iter, loss 0.43881627917289734
56 epoch, 4 iter, loss 0.4982477128505707
56 epoch, 5 iter, loss 0.5313604474067688
56 epoch, 6 iter, loss 0.29520556330680847
56 epoch, 7 iter, loss 0.4474622309207916
56 epoch, 8 iter, loss 0.3825005292892456
56 epoch, 9 iter, loss 0.38179296255111694
56 epoch, 10 iter, loss 0.2843547463417053
56 epoch, 11 iter, loss 0.45346641540527344
56 epoch, 12 iter, loss 0.47790077328681946
56 epoch, 13 iter, loss 0.5230329632759094
56 epoch, 14 iter, loss 0.3069458305835724
56 epoch, 15 iter, loss 0.5871050357818604
56 epoch, 16 iter, loss 0.4149623513221741
56 epoch, 17 iter, loss 0.41946226358413696
56 epoch, 18 iter, loss 0.45866140723228455
56 epoch, 19 iter, loss 0.5212917923927307
56 epoch, 20 iter, loss 0.582486093044281
56 epoch, 21 iter, loss 0.48447385430336
56 epoch, 22 iter, loss 0.36975082755088806
56 epoch, 23 iter, loss 0.44737762212753296
56 epoch, 24 iter, loss 0.4761654734611511
56 epoch, 25 iter, loss 0.5670779347419739
56 epoch, 26 iter, loss 0.4104935824871063
56 epoch, 27 iter, loss 0.4413854479789734
56 epoch, 28 iter, loss 0.3254462480545044
56 epoch, 29 iter, loss 0.5070315599441528
56 epoch, 30 iter, loss 0.47615665197372437
56 epoch, 31 iter, loss 0.3712853789329529
56 epoch, 32 iter, loss 0.4368807375431061
56 epoch, 33 iter, loss 0.6449993252754211
56 epoch, 34 iter, loss 0.6147375702857971
56 epoch, 35 iter, loss 0.4467865228652954
56 epoch, 36 iter, loss 0.5435656309127808
56 epoch, 37 iter, loss 0.32973986864089966
56 epoch, 38 iter, loss 0.37599289417266846
56 epoch, 39 iter, loss 0.41773295402526855
56 epoch, 40 iter, loss 0.4324586093425751
56 epoch, 41 iter, loss 0.374031126499176
56 epoch, 42 iter, loss 0.29297176003456116
56 epoch, 43 iter, loss 0.4827275574207306
56 epoch, 44 iter, loss 0.4744633734226227
56 epoch, 45 iter, loss 0.23725245893001556
56 epoch, 46 iter, loss 0.6719982624053955
56 epoch, 47 iter, loss 0.5029090046882629
56 epoch, 48 iter, loss 0.3189615309238434
56 epoch, 49 iter, loss 0.36905407905578613
56 epoch, 50 iter, loss 0.3911530077457428
56 epoch, 51 iter, loss 0.44510453939437866
56 epoch, 52 iter, loss 0.5426111221313477
56 epoch, 53 iter, loss 0.47461214661598206
56 epoch, 54 iter, loss 0.5978441834449768
56 epoch, 55 iter, loss 0.336277037858963
56 epoch, 56 iter, loss 0.43393856287002563
56 epoch, 57 iter, loss 0.45524242520332336
56 epoch, Average loss 0.44974460753432494
./model/merge_model_Param_v58.pth
some of decrypted state:
tensor([[[[ 0.0676, -0.0505,  0.0553],
          [ 0.1330,  0.1468,  0.0867],
          [-0.0968, -0.0880, -0.0123]],

         [[-0.0259,  0.1245,  0.1400],
          [-0.0039,  0.0839, -0.1222],
          [-0.1408, -0.0583,  0.0652]],

         [[ 0.1037, -0.0987,  0.0123],
          [-0.0009, -0.0768,  0.0771],
          [ 0.0977,  0.1093, -0.1193]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2028, -0.1514,  0.1659],
          [ 0.3990,  0.4404,  0.2601],
          [-0.2904, -0.2641, -0.0369]],

         [[-0.0776,  0.3734,  0.4201],
          [-0.0116,  0.2518, -0.3666],
          [-0.4225, -0.1750,  0.1956]],

         [[ 0.3111, -0.2962,  0.0368],
          [-0.0028, -0.2305,  0.2314],
          [ 0.2931,  0.3280, -0.3580]]]], device='cuda:0')
start training
57 epoch, 1 iter, loss 0.3089962899684906
57 epoch, 2 iter, loss 0.581584632396698
57 epoch, 3 iter, loss 0.34714624285697937
57 epoch, 4 iter, loss 0.34338247776031494
57 epoch, 5 iter, loss 0.30880206823349
57 epoch, 6 iter, loss 0.34158316254615784
57 epoch, 7 iter, loss 0.2911883294582367
57 epoch, 8 iter, loss 0.32343974709510803
57 epoch, 9 iter, loss 0.4264959394931793
57 epoch, 10 iter, loss 0.4184763729572296
57 epoch, 11 iter, loss 0.4375747740268707
57 epoch, 12 iter, loss 0.437967449426651
57 epoch, 13 iter, loss 0.3785400688648224
57 epoch, 14 iter, loss 0.5383748412132263
57 epoch, 15 iter, loss 0.44427433609962463
57 epoch, 16 iter, loss 0.4691234230995178
57 epoch, 17 iter, loss 0.624174952507019
57 epoch, 18 iter, loss 0.32181110978126526
57 epoch, 19 iter, loss 0.28872784972190857
57 epoch, 20 iter, loss 0.39612072706222534
57 epoch, 21 iter, loss 0.41157475113868713
57 epoch, 22 iter, loss 0.29074734449386597
57 epoch, 23 iter, loss 0.4037565588951111
57 epoch, 24 iter, loss 0.3962995707988739
57 epoch, 25 iter, loss 0.5273841619491577
57 epoch, 26 iter, loss 0.34661054611206055
57 epoch, 27 iter, loss 0.3154430687427521
57 epoch, 28 iter, loss 0.5117167234420776
57 epoch, 29 iter, loss 0.3338884115219116
57 epoch, 30 iter, loss 0.5597588419914246
57 epoch, 31 iter, loss 0.5149774551391602
57 epoch, 32 iter, loss 0.5145466327667236
57 epoch, 33 iter, loss 0.4578082263469696
57 epoch, 34 iter, loss 0.3059089779853821
57 epoch, 35 iter, loss 0.3102414608001709
57 epoch, 36 iter, loss 0.2872399389743805
57 epoch, 37 iter, loss 0.3290364742279053
57 epoch, 38 iter, loss 0.49938032031059265
57 epoch, 39 iter, loss 0.47393468022346497
57 epoch, 40 iter, loss 0.4368897080421448
57 epoch, 41 iter, loss 0.6393647193908691
57 epoch, 42 iter, loss 0.5430539846420288
57 epoch, 43 iter, loss 0.5995023250579834
57 epoch, 44 iter, loss 0.4876525104045868
57 epoch, 45 iter, loss 0.28427985310554504
57 epoch, 46 iter, loss 0.2941581904888153
57 epoch, 47 iter, loss 0.3552141785621643
57 epoch, 48 iter, loss 0.4027823507785797
57 epoch, 49 iter, loss 0.39680054783821106
57 epoch, 50 iter, loss 0.4763152003288269
57 epoch, 51 iter, loss 0.5119993090629578
57 epoch, 52 iter, loss 0.3441254496574402
57 epoch, 53 iter, loss 0.44449925422668457
57 epoch, 54 iter, loss 0.26630884408950806
57 epoch, 55 iter, loss 0.49991902709007263
57 epoch, 56 iter, loss 0.4697408676147461
57 epoch, 57 iter, loss 0.7308177351951599
57 epoch, Average loss 0.4210782981755441
./model/merge_model_Param_v59.pth
some of decrypted state:
tensor([[[[ 0.0677, -0.0504,  0.0553],
          [ 0.1334,  0.1471,  0.0870],
          [-0.0964, -0.0877, -0.0121]],

         [[-0.0259,  0.1244,  0.1401],
          [-0.0035,  0.0841, -0.1221],
          [-0.1405, -0.0581,  0.0654]],

         [[ 0.1034, -0.0989,  0.0122],
          [-0.0008, -0.0768,  0.0772],
          [ 0.0979,  0.1096, -0.1191]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2030, -0.1513,  0.1660],
          [ 0.4002,  0.4414,  0.2610],
          [-0.2892, -0.2632, -0.0363]],

         [[-0.0778,  0.3733,  0.4202],
          [-0.0105,  0.2523, -0.3663],
          [-0.4215, -0.1742,  0.1961]],

         [[ 0.3102, -0.2968,  0.0365],
          [-0.0023, -0.2303,  0.2315],
          [ 0.2938,  0.3288, -0.3572]]]], device='cuda:0')
start training
58 epoch, 1 iter, loss 0.5058808922767639
58 epoch, 2 iter, loss 0.48979422450065613
58 epoch, 3 iter, loss 0.28043022751808167
58 epoch, 4 iter, loss 0.31508803367614746
58 epoch, 5 iter, loss 0.546040952205658
58 epoch, 6 iter, loss 0.46703624725341797
58 epoch, 7 iter, loss 0.2884277403354645
58 epoch, 8 iter, loss 0.8572171330451965
58 epoch, 9 iter, loss 0.35639867186546326
58 epoch, 10 iter, loss 0.28208428621292114
58 epoch, 11 iter, loss 0.38488098978996277
58 epoch, 12 iter, loss 0.3719206750392914
58 epoch, 13 iter, loss 0.43832847476005554
58 epoch, 14 iter, loss 0.26172521710395813
58 epoch, 15 iter, loss 0.3272247612476349
58 epoch, 16 iter, loss 0.456432044506073
58 epoch, 17 iter, loss 0.26961594820022583
58 epoch, 18 iter, loss 0.48313623666763306
58 epoch, 19 iter, loss 0.5293735861778259
58 epoch, 20 iter, loss 0.3829762041568756
58 epoch, 21 iter, loss 0.39551156759262085
58 epoch, 22 iter, loss 0.366779088973999
58 epoch, 23 iter, loss 0.299683541059494
58 epoch, 24 iter, loss 0.27292585372924805
58 epoch, 25 iter, loss 0.6648465991020203
58 epoch, 26 iter, loss 0.37232908606529236
58 epoch, 27 iter, loss 0.46111899614334106
58 epoch, 28 iter, loss 0.25311797857284546
58 epoch, 29 iter, loss 0.28993213176727295
58 epoch, 30 iter, loss 0.6004087328910828
58 epoch, 31 iter, loss 0.5543876886367798
58 epoch, 32 iter, loss 0.4708271324634552
58 epoch, 33 iter, loss 0.2976332902908325
58 epoch, 34 iter, loss 0.33887895941734314
58 epoch, 35 iter, loss 0.5576899647712708
58 epoch, 36 iter, loss 0.5594931840896606
58 epoch, 37 iter, loss 0.41450321674346924
58 epoch, 38 iter, loss 0.5674877166748047
58 epoch, 39 iter, loss 0.3634958863258362
58 epoch, 40 iter, loss 0.38109591603279114
58 epoch, 41 iter, loss 0.5233163833618164
58 epoch, 42 iter, loss 0.372196227312088
58 epoch, 43 iter, loss 0.4733799695968628
58 epoch, 44 iter, loss 0.4466515779495239
58 epoch, 45 iter, loss 0.4848884344100952
58 epoch, 46 iter, loss 0.610316812992096
58 epoch, 47 iter, loss 0.39005231857299805
58 epoch, 48 iter, loss 0.33303302526474
58 epoch, 49 iter, loss 0.4801989197731018
58 epoch, 50 iter, loss 0.4607428312301636
58 epoch, 51 iter, loss 0.4566670358181
58 epoch, 52 iter, loss 0.37076425552368164
58 epoch, 53 iter, loss 0.44463682174682617
58 epoch, 54 iter, loss 0.28427284955978394
58 epoch, 55 iter, loss 0.5248884558677673
58 epoch, 56 iter, loss 0.41525405645370483
58 epoch, 57 iter, loss 0.5679348111152649
58 epoch, Average loss 0.4283395414812523
./model/merge_model_Param_v60.pth
some of decrypted state:
tensor([[[[ 0.0682, -0.0501,  0.0555],
          [ 0.1335,  0.1474,  0.0873],
          [-0.0961, -0.0876, -0.0118]],

         [[-0.0255,  0.1246,  0.1401],
          [-0.0033,  0.0844, -0.1218],
          [-0.1402, -0.0580,  0.0654]],

         [[ 0.1037, -0.0987,  0.0121],
          [-0.0006, -0.0764,  0.0773],
          [ 0.0979,  0.1095, -0.1191]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2046, -0.1504,  0.1666],
          [ 0.4005,  0.4423,  0.2620],
          [-0.2882, -0.2627, -0.0355]],

         [[-0.0764,  0.3739,  0.4202],
          [-0.0099,  0.2533, -0.3654],
          [-0.4207, -0.1740,  0.1961]],

         [[ 0.3112, -0.2962,  0.0364],
          [-0.0017, -0.2291,  0.2320],
          [ 0.2937,  0.3284, -0.3572]]]], device='cuda:0')
start training
59 epoch, 1 iter, loss 0.511823832988739
59 epoch, 2 iter, loss 0.5067567229270935
59 epoch, 3 iter, loss 0.3861001431941986
59 epoch, 4 iter, loss 0.4176611304283142
59 epoch, 5 iter, loss 0.45072615146636963
59 epoch, 6 iter, loss 0.34502559900283813
59 epoch, 7 iter, loss 0.3674051761627197
59 epoch, 8 iter, loss 0.34573814272880554
59 epoch, 9 iter, loss 0.40810588002204895
59 epoch, 10 iter, loss 0.5366616249084473
59 epoch, 11 iter, loss 0.39962902665138245
59 epoch, 12 iter, loss 0.4496231973171234
59 epoch, 13 iter, loss 0.4203820824623108
59 epoch, 14 iter, loss 0.3959745466709137
59 epoch, 15 iter, loss 0.39976951479911804
59 epoch, 16 iter, loss 0.46653488278388977
59 epoch, 17 iter, loss 0.40492352843284607
59 epoch, 18 iter, loss 0.4698716402053833
59 epoch, 19 iter, loss 0.31529539823532104
59 epoch, 20 iter, loss 0.3895329236984253
59 epoch, 21 iter, loss 0.5218769311904907
59 epoch, 22 iter, loss 0.4642047584056854
59 epoch, 23 iter, loss 0.34243065118789673
59 epoch, 24 iter, loss 0.4992305338382721
59 epoch, 25 iter, loss 0.3109366297721863
59 epoch, 26 iter, loss 0.3168764114379883
59 epoch, 27 iter, loss 0.4518447518348694
59 epoch, 28 iter, loss 0.41212454438209534
59 epoch, 29 iter, loss 0.3389572203159332
59 epoch, 30 iter, loss 0.6511107683181763
59 epoch, 31 iter, loss 0.5646873712539673
59 epoch, 32 iter, loss 0.4518875479698181
59 epoch, 33 iter, loss 0.2135499268770218
59 epoch, 34 iter, loss 0.3033459484577179
59 epoch, 35 iter, loss 0.5316019058227539
59 epoch, 36 iter, loss 0.5093218684196472
59 epoch, 37 iter, loss 0.45911282300949097
59 epoch, 38 iter, loss 0.41302672028541565
59 epoch, 39 iter, loss 0.41802626848220825
59 epoch, 40 iter, loss 0.3983176350593567
59 epoch, 41 iter, loss 0.4566047191619873
59 epoch, 42 iter, loss 0.5345525741577148
59 epoch, 43 iter, loss 0.3909810185432434
59 epoch, 44 iter, loss 0.48252442479133606
59 epoch, 45 iter, loss 0.4592072069644928
59 epoch, 46 iter, loss 0.26461514830589294
59 epoch, 47 iter, loss 0.302486777305603
59 epoch, 48 iter, loss 0.3936070501804352
59 epoch, 49 iter, loss 0.4266837239265442
59 epoch, 50 iter, loss 0.38680300116539
59 epoch, 51 iter, loss 0.3680712878704071
59 epoch, 52 iter, loss 0.35618677735328674
59 epoch, 53 iter, loss 0.2709836959838867
59 epoch, 54 iter, loss 0.4307570159435272
59 epoch, 55 iter, loss 0.367628812789917
59 epoch, 56 iter, loss 0.3766566812992096
59 epoch, 57 iter, loss 0.35336706042289734
59 epoch, Average loss 0.41371454978198335
./model/merge_model_Param_v61.pth
some of decrypted state:
tensor([[[[ 0.0683, -0.0501,  0.0554],
          [ 0.1332,  0.1472,  0.0874],
          [-0.0968, -0.0883, -0.0123]],

         [[-0.0255,  0.1246,  0.1398],
          [-0.0038,  0.0840, -0.1220],
          [-0.1412, -0.0589,  0.0647]],

         [[ 0.1033, -0.0992,  0.0116],
          [-0.0013, -0.0771,  0.0768],
          [ 0.0968,  0.1085, -0.1196]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2050, -0.1504,  0.1663],
          [ 0.3996,  0.4417,  0.2622],
          [-0.2903, -0.2648, -0.0370]],

         [[-0.0764,  0.3737,  0.4195],
          [-0.0113,  0.2519, -0.3659],
          [-0.4235, -0.1767,  0.1942]],

         [[ 0.3100, -0.2975,  0.0349],
          [-0.0039, -0.2313,  0.2305],
          [ 0.2904,  0.3255, -0.3587]]]], device='cuda:0')
start training
60 epoch, 1 iter, loss 0.2578558623790741
60 epoch, 2 iter, loss 0.5267831087112427
60 epoch, 3 iter, loss 0.26941215991973877
60 epoch, 4 iter, loss 0.41569072008132935
60 epoch, 5 iter, loss 0.2939762771129608
60 epoch, 6 iter, loss 0.26757973432540894
60 epoch, 7 iter, loss 0.43171000480651855
60 epoch, 8 iter, loss 0.27057382464408875
60 epoch, 9 iter, loss 0.4372517168521881
60 epoch, 10 iter, loss 0.3222031593322754
60 epoch, 11 iter, loss 0.3384624719619751
60 epoch, 12 iter, loss 0.7386361360549927
60 epoch, 13 iter, loss 0.4979279637336731
60 epoch, 14 iter, loss 0.3782586455345154
60 epoch, 15 iter, loss 0.1981355845928192
60 epoch, 16 iter, loss 0.3753356635570526
60 epoch, 17 iter, loss 0.6327685117721558
60 epoch, 18 iter, loss 0.31860968470573425
60 epoch, 19 iter, loss 0.28342562913894653
60 epoch, 20 iter, loss 0.38301509618759155
60 epoch, 21 iter, loss 0.4759116470813751
60 epoch, 22 iter, loss 0.2851320505142212
60 epoch, 23 iter, loss 0.32782021164894104
60 epoch, 24 iter, loss 0.6153779625892639
60 epoch, 25 iter, loss 0.4190216362476349
60 epoch, 26 iter, loss 0.31776121258735657
60 epoch, 27 iter, loss 0.45381441712379456
60 epoch, 28 iter, loss 0.4246470630168915
60 epoch, 29 iter, loss 0.36119335889816284
60 epoch, 30 iter, loss 0.42624950408935547
60 epoch, 31 iter, loss 0.6730924844741821
60 epoch, 32 iter, loss 0.4683550298213959
60 epoch, 33 iter, loss 0.3263097405433655
60 epoch, 34 iter, loss 0.4411909878253937
60 epoch, 35 iter, loss 0.3264040946960449
60 epoch, 36 iter, loss 0.35549476742744446
60 epoch, 37 iter, loss 0.5760157704353333
60 epoch, 38 iter, loss 0.37093526124954224
60 epoch, 39 iter, loss 0.4443082809448242
60 epoch, 40 iter, loss 0.3825792372226715
60 epoch, 41 iter, loss 0.3757017254829407
60 epoch, 42 iter, loss 0.508251965045929
60 epoch, 43 iter, loss 0.3133029639720917
60 epoch, 44 iter, loss 0.39465442299842834
60 epoch, 45 iter, loss 0.6703175902366638
60 epoch, 46 iter, loss 0.4561663269996643
60 epoch, 47 iter, loss 0.35394182801246643
60 epoch, 48 iter, loss 0.3362930715084076
60 epoch, 49 iter, loss 0.40356865525245667
60 epoch, 50 iter, loss 0.3550315499305725
60 epoch, 51 iter, loss 0.4161747097969055
60 epoch, 52 iter, loss 0.4364854395389557
60 epoch, 53 iter, loss 0.31303104758262634
60 epoch, 54 iter, loss 0.7672616243362427
60 epoch, 55 iter, loss 0.31842005252838135
60 epoch, 56 iter, loss 0.23748716711997986
60 epoch, 57 iter, loss 0.5294657945632935
60 epoch, Average loss 0.4086803966446927
./model/merge_model_Param_v62.pth
some of decrypted state:
tensor([[[[ 0.0680, -0.0504,  0.0553],
          [ 0.1339,  0.1481,  0.0880],
          [-0.0961, -0.0876, -0.0117]],

         [[-0.0256,  0.1245,  0.1398],
          [-0.0029,  0.0848, -0.1214],
          [-0.1406, -0.0582,  0.0655]],

         [[ 0.1032, -0.0993,  0.0115],
          [-0.0006, -0.0763,  0.0773],
          [ 0.0972,  0.1092, -0.1188]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2040, -0.1511,  0.1659],
          [ 0.4017,  0.4442,  0.2640],
          [-0.2884, -0.2628, -0.0351]],

         [[-0.0767,  0.3734,  0.4194],
          [-0.0088,  0.2543, -0.3642],
          [-0.4218, -0.1745,  0.1965]],

         [[ 0.3095, -0.2978,  0.0344],
          [-0.0019, -0.2290,  0.2320],
          [ 0.2917,  0.3275, -0.3564]]]], device='cuda:0')
start training
61 epoch, 1 iter, loss 0.49918481707572937
61 epoch, 2 iter, loss 0.3539276123046875
61 epoch, 3 iter, loss 0.35912594199180603
61 epoch, 4 iter, loss 0.4013518989086151
61 epoch, 5 iter, loss 0.4367813766002655
61 epoch, 6 iter, loss 0.23529058694839478
61 epoch, 7 iter, loss 0.24931399524211884
61 epoch, 8 iter, loss 0.33941373229026794
61 epoch, 9 iter, loss 0.47623777389526367
61 epoch, 10 iter, loss 0.33681461215019226
61 epoch, 11 iter, loss 0.5815856456756592
61 epoch, 12 iter, loss 0.33123359084129333
61 epoch, 13 iter, loss 0.3396815359592438
61 epoch, 14 iter, loss 0.28754034638404846
61 epoch, 15 iter, loss 0.46148401498794556
61 epoch, 16 iter, loss 0.5270323157310486
61 epoch, 17 iter, loss 0.38380271196365356
61 epoch, 18 iter, loss 0.3484378159046173
61 epoch, 19 iter, loss 0.545182466506958
61 epoch, 20 iter, loss 0.572860836982727
61 epoch, 21 iter, loss 0.26300927996635437
61 epoch, 22 iter, loss 0.3852296471595764
61 epoch, 23 iter, loss 0.4850773215293884
61 epoch, 24 iter, loss 0.5098503232002258
61 epoch, 25 iter, loss 0.32981637120246887
61 epoch, 26 iter, loss 0.410800963640213
61 epoch, 27 iter, loss 0.4848451614379883
61 epoch, 28 iter, loss 0.44508200883865356
61 epoch, 29 iter, loss 0.3825664520263672
61 epoch, 30 iter, loss 0.5099952220916748
61 epoch, 31 iter, loss 0.46526840329170227
61 epoch, 32 iter, loss 0.34157896041870117
61 epoch, 33 iter, loss 0.4949638247489929
61 epoch, 34 iter, loss 0.35981982946395874
61 epoch, 35 iter, loss 0.5570831298828125
61 epoch, 36 iter, loss 0.33781760931015015
61 epoch, 37 iter, loss 0.39986640214920044
61 epoch, 38 iter, loss 0.31494569778442383
61 epoch, 39 iter, loss 0.4764285385608673
61 epoch, 40 iter, loss 0.29581376910209656
61 epoch, 41 iter, loss 0.3980572819709778
61 epoch, 42 iter, loss 0.29034778475761414
61 epoch, 43 iter, loss 0.3683249056339264
61 epoch, 44 iter, loss 0.3046257197856903
61 epoch, 45 iter, loss 0.3180373013019562
61 epoch, 46 iter, loss 0.3050224781036377
61 epoch, 47 iter, loss 0.4583800435066223
61 epoch, 48 iter, loss 0.34455326199531555
61 epoch, 49 iter, loss 0.45044779777526855
61 epoch, 50 iter, loss 0.3989090323448181
61 epoch, 51 iter, loss 0.2724382281303406
61 epoch, 52 iter, loss 0.3811453580856323
61 epoch, 53 iter, loss 0.4306544065475464
61 epoch, 54 iter, loss 0.4138340651988983
61 epoch, 55 iter, loss 0.3182447552680969
61 epoch, 56 iter, loss 0.3708810806274414
61 epoch, 57 iter, loss 0.6394140124320984
61 epoch, Average loss 0.39963965013361813
./model/merge_model_Param_v63.pth
some of decrypted state:
tensor([[[[ 0.0682, -0.0503,  0.0554],
          [ 0.1337,  0.1482,  0.0881],
          [-0.0962, -0.0878, -0.0118]],

         [[-0.0255,  0.1245,  0.1398],
          [-0.0032,  0.0848, -0.1213],
          [-0.1410, -0.0586,  0.0653]],

         [[ 0.1033, -0.0993,  0.0114],
          [-0.0010, -0.0764,  0.0774],
          [ 0.0966,  0.1086, -0.1191]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2045, -0.1510,  0.1663],
          [ 0.4012,  0.4445,  0.2644],
          [-0.2886, -0.2635, -0.0353]],

         [[-0.0764,  0.3735,  0.4194],
          [-0.0095,  0.2543, -0.3640],
          [-0.4229, -0.1757,  0.1960]],

         [[ 0.3098, -0.2979,  0.0342],
          [-0.0029, -0.2292,  0.2322],
          [ 0.2899,  0.3257, -0.3572]]]], device='cuda:0')
start training
62 epoch, 1 iter, loss 0.2396988421678543
62 epoch, 2 iter, loss 0.7400515675544739
62 epoch, 3 iter, loss 0.5390788912773132
62 epoch, 4 iter, loss 0.40685412287712097
62 epoch, 5 iter, loss 0.182497039437294
62 epoch, 6 iter, loss 0.3195897042751312
62 epoch, 7 iter, loss 0.3425060212612152
62 epoch, 8 iter, loss 0.390990674495697
62 epoch, 9 iter, loss 0.40146392583847046
62 epoch, 10 iter, loss 0.3807832896709442
62 epoch, 11 iter, loss 0.2167632281780243
62 epoch, 12 iter, loss 0.33545663952827454
62 epoch, 13 iter, loss 0.38440224528312683
62 epoch, 14 iter, loss 0.3608814477920532
62 epoch, 15 iter, loss 0.2781665623188019
62 epoch, 16 iter, loss 0.2725476920604706
62 epoch, 17 iter, loss 0.3289198875427246
62 epoch, 18 iter, loss 0.2967750132083893
62 epoch, 19 iter, loss 0.3732303977012634
62 epoch, 20 iter, loss 0.5499536395072937
62 epoch, 21 iter, loss 0.5213489532470703
62 epoch, 22 iter, loss 0.45904478430747986
62 epoch, 23 iter, loss 0.3061757981777191
62 epoch, 24 iter, loss 0.43094027042388916
62 epoch, 25 iter, loss 0.5082196593284607
62 epoch, 26 iter, loss 0.3354225754737854
62 epoch, 27 iter, loss 0.3940986096858978
62 epoch, 28 iter, loss 0.3354623317718506
62 epoch, 29 iter, loss 0.31071019172668457
62 epoch, 30 iter, loss 0.49345844984054565
62 epoch, 31 iter, loss 0.5073631405830383
62 epoch, 32 iter, loss 0.4784017503261566
62 epoch, 33 iter, loss 0.3564486503601074
62 epoch, 34 iter, loss 0.26287925243377686
62 epoch, 35 iter, loss 0.38168060779571533
62 epoch, 36 iter, loss 0.3681177794933319
62 epoch, 37 iter, loss 0.40520215034484863
62 epoch, 38 iter, loss 0.19359618425369263
62 epoch, 39 iter, loss 0.6840810179710388
62 epoch, 40 iter, loss 0.39581558108329773
62 epoch, 41 iter, loss 0.5080409646034241
62 epoch, 42 iter, loss 0.3177587389945984
62 epoch, 43 iter, loss 0.3832979202270508
62 epoch, 44 iter, loss 0.3855350613594055
62 epoch, 45 iter, loss 0.5651113986968994
62 epoch, 46 iter, loss 0.3983760178089142
62 epoch, 47 iter, loss 0.5280197262763977
62 epoch, 48 iter, loss 0.29355910420417786
62 epoch, 49 iter, loss 0.5141735076904297
62 epoch, 50 iter, loss 0.34392666816711426
62 epoch, 51 iter, loss 0.348823219537735
62 epoch, 52 iter, loss 0.46812763810157776
62 epoch, 53 iter, loss 0.3223671317100525
62 epoch, 54 iter, loss 0.4643916189670563
62 epoch, 55 iter, loss 0.4101877808570862
62 epoch, 56 iter, loss 0.4850309193134308
62 epoch, 57 iter, loss 0.5598118901252747
62 epoch, Average loss 0.39939680486394646
./model/merge_model_Param_v64.pth
some of decrypted state:
tensor([[[[ 0.0682, -0.0505,  0.0551],
          [ 0.1336,  0.1482,  0.0882],
          [-0.0962, -0.0878, -0.0118]],

         [[-0.0249,  0.1247,  0.1399],
          [-0.0027,  0.0852, -0.1208],
          [-0.1405, -0.0582,  0.0656]],

         [[ 0.1037, -0.0991,  0.0114],
          [-0.0005, -0.0759,  0.0779],
          [ 0.0972,  0.1091, -0.1186]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2046, -0.1516,  0.1654],
          [ 0.4009,  0.4445,  0.2647],
          [-0.2885, -0.2635, -0.0353]],

         [[-0.0748,  0.3742,  0.4197],
          [-0.0081,  0.2556, -0.3625],
          [-0.4215, -0.1746,  0.1969]],

         [[ 0.3110, -0.2973,  0.0343],
          [-0.0015, -0.2278,  0.2337],
          [ 0.2915,  0.3273, -0.3558]]]], device='cuda:0')
start training
63 epoch, 1 iter, loss 0.6348249912261963
63 epoch, 2 iter, loss 0.3682241141796112
63 epoch, 3 iter, loss 0.3848429322242737
63 epoch, 4 iter, loss 0.38188207149505615
63 epoch, 5 iter, loss 0.3831566572189331
63 epoch, 6 iter, loss 0.3697330057621002
63 epoch, 7 iter, loss 0.5490477085113525
63 epoch, 8 iter, loss 0.49825751781463623
63 epoch, 9 iter, loss 0.3045864999294281
63 epoch, 10 iter, loss 0.37525230646133423
63 epoch, 11 iter, loss 0.4006880223751068
63 epoch, 12 iter, loss 0.32488352060317993
63 epoch, 13 iter, loss 0.3268228769302368
63 epoch, 14 iter, loss 0.3410675823688507
63 epoch, 15 iter, loss 0.4060628414154053
63 epoch, 16 iter, loss 0.27487486600875854
63 epoch, 17 iter, loss 0.38447868824005127
63 epoch, 18 iter, loss 0.26269885897636414
63 epoch, 19 iter, loss 0.5582445859909058
63 epoch, 20 iter, loss 0.44008463621139526
63 epoch, 21 iter, loss 0.5420812964439392
63 epoch, 22 iter, loss 0.4502109885215759
63 epoch, 23 iter, loss 0.49958765506744385
63 epoch, 24 iter, loss 0.38119080662727356
63 epoch, 25 iter, loss 0.26478537917137146
63 epoch, 26 iter, loss 0.2670261263847351
63 epoch, 27 iter, loss 0.4527727961540222
63 epoch, 28 iter, loss 0.463706374168396
63 epoch, 29 iter, loss 0.4895875155925751
63 epoch, 30 iter, loss 0.27061304450035095
63 epoch, 31 iter, loss 0.4490968883037567
63 epoch, 32 iter, loss 0.49045106768608093
63 epoch, 33 iter, loss 0.2798399031162262
63 epoch, 34 iter, loss 0.350253164768219
63 epoch, 35 iter, loss 0.26979702711105347
63 epoch, 36 iter, loss 0.36616250872612
63 epoch, 37 iter, loss 0.47908830642700195
63 epoch, 38 iter, loss 0.3466085195541382
63 epoch, 39 iter, loss 0.2968168258666992
63 epoch, 40 iter, loss 0.6695080995559692
63 epoch, 41 iter, loss 0.43032777309417725
63 epoch, 42 iter, loss 0.6088511347770691
63 epoch, 43 iter, loss 0.24348759651184082
63 epoch, 44 iter, loss 0.5569056868553162
63 epoch, 45 iter, loss 0.3604283630847931
63 epoch, 46 iter, loss 0.272826611995697
63 epoch, 47 iter, loss 0.44860658049583435
63 epoch, 48 iter, loss 0.3244739770889282
63 epoch, 49 iter, loss 0.4870522916316986
63 epoch, 50 iter, loss 0.24334771931171417
63 epoch, 51 iter, loss 0.31519845128059387
63 epoch, 52 iter, loss 0.30366191267967224
63 epoch, 53 iter, loss 0.4216420650482178
63 epoch, 54 iter, loss 0.4150797128677368
63 epoch, 55 iter, loss 0.49274152517318726
63 epoch, 56 iter, loss 0.4274660646915436
63 epoch, 57 iter, loss 0.34269094467163086
63 epoch, Average loss 0.39901205243771537
./model/merge_model_Param_v65.pth
some of decrypted state:
tensor([[[[ 6.8515e-02, -5.0211e-02,  5.5403e-02],
          [ 1.3390e-01,  1.4846e-01,  8.8740e-02],
          [-9.5555e-02, -8.6982e-02, -1.0830e-02]],

         [[-2.4443e-02,  1.2522e-01,  1.4032e-01],
          [-2.2550e-03,  8.5600e-02, -1.2026e-01],
          [-1.3980e-01, -5.7293e-02,  6.6677e-02]],

         [[ 1.0401e-01, -9.8715e-02,  1.1728e-02],
          [-1.4114e-04, -7.5673e-02,  7.8180e-02],
          [ 9.7579e-02,  1.0974e-01, -1.1776e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0554e-01, -1.5063e-01,  1.6621e-01],
          [ 4.0169e-01,  4.4538e-01,  2.6622e-01],
          [-2.8666e-01, -2.6095e-01, -3.2491e-02]],

         [[-7.3328e-02,  3.7566e-01,  4.2095e-01],
          [-6.7649e-03,  2.5680e-01, -3.6079e-01],
          [-4.1940e-01, -1.7188e-01,  2.0003e-01]],

         [[ 3.1204e-01, -2.9614e-01,  3.5185e-02],
          [-4.2343e-04, -2.2702e-01,  2.3454e-01],
          [ 2.9274e-01,  3.2922e-01, -3.5328e-01]]]], device='cuda:0')
start training
64 epoch, 1 iter, loss 0.40373703837394714
64 epoch, 2 iter, loss 0.495424747467041
64 epoch, 3 iter, loss 0.30195948481559753
64 epoch, 4 iter, loss 0.26982924342155457
64 epoch, 5 iter, loss 0.5674247741699219
64 epoch, 6 iter, loss 0.43498700857162476
64 epoch, 7 iter, loss 0.3752764165401459
64 epoch, 8 iter, loss 0.4299772381782532
64 epoch, 9 iter, loss 0.3707396388053894
64 epoch, 10 iter, loss 0.21602818369865417
64 epoch, 11 iter, loss 0.5180889368057251
64 epoch, 12 iter, loss 0.32387492060661316
64 epoch, 13 iter, loss 0.6342720985412598
64 epoch, 14 iter, loss 0.5300272703170776
64 epoch, 15 iter, loss 0.5445777773857117
64 epoch, 16 iter, loss 0.3167154788970947
64 epoch, 17 iter, loss 0.47627827525138855
64 epoch, 18 iter, loss 0.2226501703262329
64 epoch, 19 iter, loss 0.3021174669265747
64 epoch, 20 iter, loss 0.4044050872325897
64 epoch, 21 iter, loss 0.4367227256298065
64 epoch, 22 iter, loss 0.4770471453666687
64 epoch, 23 iter, loss 0.3846625089645386
64 epoch, 24 iter, loss 0.30307310819625854
64 epoch, 25 iter, loss 0.394472599029541
64 epoch, 26 iter, loss 0.31506505608558655
64 epoch, 27 iter, loss 0.3483419120311737
64 epoch, 28 iter, loss 0.3377864956855774
64 epoch, 29 iter, loss 0.23518866300582886
64 epoch, 30 iter, loss 0.35074201226234436
64 epoch, 31 iter, loss 0.4410790801048279
64 epoch, 32 iter, loss 0.40211325883865356
64 epoch, 33 iter, loss 0.4064466059207916
64 epoch, 34 iter, loss 0.2438843846321106
64 epoch, 35 iter, loss 0.301644504070282
64 epoch, 36 iter, loss 0.4551407992839813
64 epoch, 37 iter, loss 0.3265129029750824
64 epoch, 38 iter, loss 0.42662882804870605
64 epoch, 39 iter, loss 0.5203390121459961
64 epoch, 40 iter, loss 0.2215663492679596
64 epoch, 41 iter, loss 0.4577888548374176
64 epoch, 42 iter, loss 0.37289097905158997
64 epoch, 43 iter, loss 0.5270028710365295
64 epoch, 44 iter, loss 0.43068867921829224
64 epoch, 45 iter, loss 0.457146555185318
64 epoch, 46 iter, loss 0.502510666847229
64 epoch, 47 iter, loss 0.47289326786994934
64 epoch, 48 iter, loss 0.25401484966278076
64 epoch, 49 iter, loss 0.3994826078414917
64 epoch, 50 iter, loss 0.39522621035575867
64 epoch, 51 iter, loss 0.36277496814727783
64 epoch, 52 iter, loss 0.5170148611068726
64 epoch, 53 iter, loss 0.2634800374507904
64 epoch, 54 iter, loss 0.4441803991794586
64 epoch, 55 iter, loss 0.5415768027305603
64 epoch, 56 iter, loss 0.27629464864730835
64 epoch, 57 iter, loss 0.23988302052021027
64 epoch, Average loss 0.3926613945187184
./model/merge_model_Param_v66.pth
some of decrypted state:
tensor([[[[ 0.0685, -0.0502,  0.0553],
          [ 0.1335,  0.1481,  0.0883],
          [-0.0963, -0.0878, -0.0119]],

         [[-0.0243,  0.1254,  0.1403],
          [-0.0025,  0.0852, -0.1207],
          [-0.1406, -0.0581,  0.0657]],

         [[ 0.1040, -0.0986,  0.0116],
          [-0.0005, -0.0761,  0.0776],
          [ 0.0966,  0.1088, -0.1187]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2056, -0.1505,  0.1658],
          [ 0.4006,  0.4442,  0.2648],
          [-0.2888, -0.2634, -0.0356]],

         [[-0.0729,  0.3763,  0.4208],
          [-0.0076,  0.2556, -0.3622],
          [-0.4217, -0.1743,  0.1971]],

         [[ 0.3121, -0.2958,  0.0349],
          [-0.0015, -0.2284,  0.2327],
          [ 0.2898,  0.3264, -0.3562]]]], device='cuda:0')
start training
65 epoch, 1 iter, loss 0.31106340885162354
65 epoch, 2 iter, loss 0.3594204783439636
65 epoch, 3 iter, loss 0.40211135149002075
65 epoch, 4 iter, loss 0.2774047255516052
65 epoch, 5 iter, loss 0.3045541048049927
65 epoch, 6 iter, loss 0.34447357058525085
65 epoch, 7 iter, loss 0.33432045578956604
65 epoch, 8 iter, loss 0.21770772337913513
65 epoch, 9 iter, loss 0.35894718766212463
65 epoch, 10 iter, loss 0.29021453857421875
65 epoch, 11 iter, loss 0.305360347032547
65 epoch, 12 iter, loss 0.30297356843948364
65 epoch, 13 iter, loss 0.37875694036483765
65 epoch, 14 iter, loss 0.3743656277656555
65 epoch, 15 iter, loss 0.43900811672210693
65 epoch, 16 iter, loss 0.38790494203567505
65 epoch, 17 iter, loss 0.3566775321960449
65 epoch, 18 iter, loss 0.2899346351623535
65 epoch, 19 iter, loss 0.3703625202178955
65 epoch, 20 iter, loss 0.2699228823184967
65 epoch, 21 iter, loss 0.41101592779159546
65 epoch, 22 iter, loss 0.49883851408958435
65 epoch, 23 iter, loss 0.43088778853416443
65 epoch, 24 iter, loss 0.28538089990615845
65 epoch, 25 iter, loss 0.32095807790756226
65 epoch, 26 iter, loss 0.27961820363998413
65 epoch, 27 iter, loss 0.45747822523117065
65 epoch, 28 iter, loss 0.2760108709335327
65 epoch, 29 iter, loss 0.3508331775665283
65 epoch, 30 iter, loss 0.4694899022579193
65 epoch, 31 iter, loss 0.33444124460220337
65 epoch, 32 iter, loss 0.3261438012123108
65 epoch, 33 iter, loss 0.30992159247398376
65 epoch, 34 iter, loss 0.3804261386394501
65 epoch, 35 iter, loss 0.36036959290504456
65 epoch, 36 iter, loss 0.245335653424263
65 epoch, 37 iter, loss 0.3538605570793152
65 epoch, 38 iter, loss 0.4009130597114563
65 epoch, 39 iter, loss 0.34110933542251587
65 epoch, 40 iter, loss 0.4585186839103699
65 epoch, 41 iter, loss 0.47857537865638733
65 epoch, 42 iter, loss 0.45444244146347046
65 epoch, 43 iter, loss 0.4545920193195343
65 epoch, 44 iter, loss 0.41385579109191895
65 epoch, 45 iter, loss 0.3442997634410858
65 epoch, 46 iter, loss 0.27408427000045776
65 epoch, 47 iter, loss 0.28039243817329407
65 epoch, 48 iter, loss 0.3498392105102539
65 epoch, 49 iter, loss 0.2998679578304291
65 epoch, 50 iter, loss 0.4787043631076813
65 epoch, 51 iter, loss 0.4575144946575165
65 epoch, 52 iter, loss 0.2864357531070709
65 epoch, 53 iter, loss 0.49213603138923645
65 epoch, 54 iter, loss 0.2357369363307953
65 epoch, 55 iter, loss 0.5689204335212708
65 epoch, 56 iter, loss 0.3349083662033081
65 epoch, 57 iter, loss 0.3339347839355469
65 epoch, Average loss 0.35974169012747315
./model/merge_model_Param_v67.pth
some of decrypted state:
tensor([[[[ 6.8529e-02, -5.0245e-02,  5.5030e-02],
          [ 1.3398e-01,  1.4856e-01,  8.8818e-02],
          [-9.6008e-02, -8.7577e-02, -1.1525e-02]],

         [[-2.4233e-02,  1.2541e-01,  1.4004e-01],
          [-2.0332e-03,  8.5677e-02, -1.2025e-01],
          [-1.4034e-01, -5.7890e-02,  6.5960e-02]],

         [[ 1.0404e-01, -9.8657e-02,  1.1423e-02],
          [-1.4305e-04, -7.5789e-02,  7.7885e-02],
          [ 9.6567e-02,  1.0880e-01, -1.1862e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0559e-01, -1.5074e-01,  1.6509e-01],
          [ 4.0195e-01,  4.4568e-01,  2.6645e-01],
          [-2.8802e-01, -2.6273e-01, -3.4574e-02]],

         [[-7.2700e-02,  3.7624e-01,  4.2011e-01],
          [-6.0997e-03,  2.5703e-01, -3.6076e-01],
          [-4.2102e-01, -1.7367e-01,  1.9788e-01]],

         [[ 3.1211e-01, -2.9597e-01,  3.4269e-02],
          [-4.2915e-04, -2.2737e-01,  2.3365e-01],
          [ 2.8970e-01,  3.2639e-01, -3.5585e-01]]]], device='cuda:0')
start training
66 epoch, 1 iter, loss 0.5064722895622253
66 epoch, 2 iter, loss 0.514618456363678
66 epoch, 3 iter, loss 0.3286415934562683
66 epoch, 4 iter, loss 0.267579048871994
66 epoch, 5 iter, loss 0.42131656408309937
66 epoch, 6 iter, loss 0.3734498620033264
66 epoch, 7 iter, loss 0.45331040024757385
66 epoch, 8 iter, loss 0.35435956716537476
66 epoch, 9 iter, loss 0.38897228240966797
66 epoch, 10 iter, loss 0.23014412820339203
66 epoch, 11 iter, loss 0.30902761220932007
66 epoch, 12 iter, loss 0.4127918481826782
66 epoch, 13 iter, loss 0.3993852734565735
66 epoch, 14 iter, loss 0.33617112040519714
66 epoch, 15 iter, loss 0.4379175901412964
66 epoch, 16 iter, loss 0.32931774854660034
66 epoch, 17 iter, loss 0.3781973421573639
66 epoch, 18 iter, loss 0.2773972451686859
66 epoch, 19 iter, loss 0.48809483647346497
66 epoch, 20 iter, loss 0.42788785696029663
66 epoch, 21 iter, loss 0.33971211314201355
66 epoch, 22 iter, loss 0.32202720642089844
66 epoch, 23 iter, loss 0.360289067029953
66 epoch, 24 iter, loss 0.23633693158626556
66 epoch, 25 iter, loss 0.2775075137615204
66 epoch, 26 iter, loss 0.29003816843032837
66 epoch, 27 iter, loss 0.3655960261821747
66 epoch, 28 iter, loss 0.255487859249115
66 epoch, 29 iter, loss 0.37694382667541504
66 epoch, 30 iter, loss 0.33901700377464294
66 epoch, 31 iter, loss 0.4325002133846283
66 epoch, 32 iter, loss 0.28160566091537476
66 epoch, 33 iter, loss 0.4320375323295593
66 epoch, 34 iter, loss 0.39134299755096436
66 epoch, 35 iter, loss 0.30820170044898987
66 epoch, 36 iter, loss 0.51235032081604
66 epoch, 37 iter, loss 0.2520501911640167
66 epoch, 38 iter, loss 0.26851463317871094
66 epoch, 39 iter, loss 0.4137987196445465
66 epoch, 40 iter, loss 0.5168938636779785
66 epoch, 41 iter, loss 0.5007326602935791
66 epoch, 42 iter, loss 0.4206106960773468
66 epoch, 43 iter, loss 0.44757959246635437
66 epoch, 44 iter, loss 0.445761114358902
66 epoch, 45 iter, loss 0.36260026693344116
66 epoch, 46 iter, loss 0.3562762439250946
66 epoch, 47 iter, loss 0.293951153755188
66 epoch, 48 iter, loss 0.2985597848892212
66 epoch, 49 iter, loss 0.3798324763774872
66 epoch, 50 iter, loss 0.356012761592865
66 epoch, 51 iter, loss 0.48681753873825073
66 epoch, 52 iter, loss 0.34600794315338135
66 epoch, 53 iter, loss 0.40065619349479675
66 epoch, 54 iter, loss 0.21994231641292572
66 epoch, 55 iter, loss 0.25410085916519165
66 epoch, 56 iter, loss 0.21372172236442566
66 epoch, 57 iter, loss 0.2930864691734314
66 epoch, Average loss 0.36286936857198415
./model/merge_model_Param_v68.pth
some of decrypted state:
tensor([[[[ 6.8655e-02, -5.0066e-02,  5.5106e-02],
          [ 1.3393e-01,  1.4856e-01,  8.8827e-02],
          [-9.5675e-02, -8.7228e-02, -1.1372e-02]],

         [[-2.3948e-02,  1.2575e-01,  1.4021e-01],
          [-2.0814e-03,  8.5682e-02, -1.2025e-01],
          [-1.4005e-01, -5.7549e-02,  6.6056e-02]],

         [[ 1.0437e-01, -9.8258e-02,  1.1673e-02],
          [-1.2636e-04, -7.5727e-02,  7.7890e-02],
          [ 9.6928e-02,  1.0925e-01, -1.1833e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0597e-01, -1.5020e-01,  1.6532e-01],
          [ 4.0179e-01,  4.4569e-01,  2.6648e-01],
          [-2.8702e-01, -2.6168e-01, -3.4116e-02]],

         [[-7.1843e-02,  3.7724e-01,  4.2064e-01],
          [-6.2442e-03,  2.5705e-01, -3.6076e-01],
          [-4.2014e-01, -1.7265e-01,  1.9817e-01]],

         [[ 3.1312e-01, -2.9477e-01,  3.5019e-02],
          [-3.7909e-04, -2.2718e-01,  2.3367e-01],
          [ 2.9078e-01,  3.2774e-01, -3.5499e-01]]]], device='cuda:0')
start training
67 epoch, 1 iter, loss 0.3824006915092468
67 epoch, 2 iter, loss 0.4284166693687439
67 epoch, 3 iter, loss 0.2774287462234497
67 epoch, 4 iter, loss 0.3753184676170349
67 epoch, 5 iter, loss 0.24677181243896484
67 epoch, 6 iter, loss 0.5067614316940308
67 epoch, 7 iter, loss 0.3532758355140686
67 epoch, 8 iter, loss 0.27849480509757996
67 epoch, 9 iter, loss 0.31938624382019043
67 epoch, 10 iter, loss 0.2873472273349762
67 epoch, 11 iter, loss 0.2460949569940567
67 epoch, 12 iter, loss 0.4476100504398346
67 epoch, 13 iter, loss 0.46549203991889954
67 epoch, 14 iter, loss 0.34776222705841064
67 epoch, 15 iter, loss 0.29685184359550476
67 epoch, 16 iter, loss 0.2895403802394867
67 epoch, 17 iter, loss 0.4203476309776306
67 epoch, 18 iter, loss 0.32113105058670044
67 epoch, 19 iter, loss 0.42198696732521057
67 epoch, 20 iter, loss 0.4706605076789856
67 epoch, 21 iter, loss 0.3260950446128845
67 epoch, 22 iter, loss 0.18240727484226227
67 epoch, 23 iter, loss 0.29876595735549927
67 epoch, 24 iter, loss 0.35107511281967163
67 epoch, 25 iter, loss 0.5191137790679932
67 epoch, 26 iter, loss 0.2999459505081177
67 epoch, 27 iter, loss 0.4161399304866791
67 epoch, 28 iter, loss 0.3096422851085663
67 epoch, 29 iter, loss 0.24032793939113617
67 epoch, 30 iter, loss 0.3770587146282196
67 epoch, 31 iter, loss 0.5026496052742004
67 epoch, 32 iter, loss 0.5211912989616394
67 epoch, 33 iter, loss 0.4998445212841034
67 epoch, 34 iter, loss 0.45720088481903076
67 epoch, 35 iter, loss 0.3770740032196045
67 epoch, 36 iter, loss 0.47608083486557007
67 epoch, 37 iter, loss 0.34719711542129517
67 epoch, 38 iter, loss 0.5108290314674377
67 epoch, 39 iter, loss 0.19282275438308716
67 epoch, 40 iter, loss 0.36166447401046753
67 epoch, 41 iter, loss 0.42151886224746704
67 epoch, 42 iter, loss 0.2611474096775055
67 epoch, 43 iter, loss 0.6126408576965332
67 epoch, 44 iter, loss 0.3887939155101776
67 epoch, 45 iter, loss 0.2129446268081665
67 epoch, 46 iter, loss 0.32470470666885376
67 epoch, 47 iter, loss 0.48111021518707275
67 epoch, 48 iter, loss 0.20409022271633148
67 epoch, 49 iter, loss 0.26851898431777954
67 epoch, 50 iter, loss 0.37030988931655884
67 epoch, 51 iter, loss 0.279832124710083
67 epoch, 52 iter, loss 0.3330453336238861
67 epoch, 53 iter, loss 0.37980425357818604
67 epoch, 54 iter, loss 0.39710065722465515
67 epoch, 55 iter, loss 0.3734374940395355
67 epoch, 56 iter, loss 0.2007225751876831
67 epoch, 57 iter, loss 0.4208247661590576
67 epoch, Average loss 0.36282022794087726
./model/merge_model_Param_v69.pth
some of decrypted state:
tensor([[[[ 0.0689, -0.0498,  0.0552],
          [ 0.1338,  0.1485,  0.0889],
          [-0.0957, -0.0871, -0.0110]],

         [[-0.0238,  0.1259,  0.1403],
          [-0.0022,  0.0857, -0.1202],
          [-0.1403, -0.0575,  0.0662]],

         [[ 0.1044, -0.0982,  0.0116],
          [-0.0003, -0.0758,  0.0778],
          [ 0.0966,  0.1091, -0.1182]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2067, -0.1495,  0.1657],
          [ 0.4014,  0.4456,  0.2667],
          [-0.2871, -0.2612, -0.0331]],

         [[-0.0713,  0.3777,  0.4209],
          [-0.0066,  0.2570, -0.3606],
          [-0.4208, -0.1726,  0.1987]],

         [[ 0.3133, -0.2947,  0.0349],
          [-0.0010, -0.2275,  0.2335],
          [ 0.2898,  0.3274, -0.3545]]]], device='cuda:0')
start training
68 epoch, 1 iter, loss 0.27983614802360535
68 epoch, 2 iter, loss 0.3285428285598755
68 epoch, 3 iter, loss 0.3760925233364105
68 epoch, 4 iter, loss 0.3553847670555115
68 epoch, 5 iter, loss 0.5285624861717224
68 epoch, 6 iter, loss 0.4977731704711914
68 epoch, 7 iter, loss 0.43013936281204224
68 epoch, 8 iter, loss 0.3520902395248413
68 epoch, 9 iter, loss 0.27157291769981384
68 epoch, 10 iter, loss 0.3433432877063751
68 epoch, 11 iter, loss 0.4364124536514282
68 epoch, 12 iter, loss 0.3552147448062897
68 epoch, 13 iter, loss 0.4864857792854309
68 epoch, 14 iter, loss 0.25143367052078247
68 epoch, 15 iter, loss 0.28482770919799805
68 epoch, 16 iter, loss 0.3467934727668762
68 epoch, 17 iter, loss 0.3012996017932892
68 epoch, 18 iter, loss 0.3344557583332062
68 epoch, 19 iter, loss 0.40531691908836365
68 epoch, 20 iter, loss 0.4541693925857544
68 epoch, 21 iter, loss 0.3568436801433563
68 epoch, 22 iter, loss 0.30834099650382996
68 epoch, 23 iter, loss 0.32071515917778015
68 epoch, 24 iter, loss 0.2777842879295349
68 epoch, 25 iter, loss 0.34286582469940186
68 epoch, 26 iter, loss 0.2527684271335602
68 epoch, 27 iter, loss 0.7304677367210388
68 epoch, 28 iter, loss 0.3917720317840576
68 epoch, 29 iter, loss 0.31552135944366455
68 epoch, 30 iter, loss 0.2162853628396988
68 epoch, 31 iter, loss 0.23045827448368073
68 epoch, 32 iter, loss 0.4109049141407013
68 epoch, 33 iter, loss 0.4023553431034088
68 epoch, 34 iter, loss 0.1439177244901657
68 epoch, 35 iter, loss 0.5876336097717285
68 epoch, 36 iter, loss 0.44725391268730164
68 epoch, 37 iter, loss 0.3493427336215973
68 epoch, 38 iter, loss 0.340867280960083
68 epoch, 39 iter, loss 0.407655268907547
68 epoch, 40 iter, loss 0.4253949522972107
68 epoch, 41 iter, loss 0.43653547763824463
68 epoch, 42 iter, loss 0.317148894071579
68 epoch, 43 iter, loss 0.24582090973854065
68 epoch, 44 iter, loss 0.2776187062263489
68 epoch, 45 iter, loss 0.22862514853477478
68 epoch, 46 iter, loss 0.3872183561325073
68 epoch, 47 iter, loss 0.37213650345802307
68 epoch, 48 iter, loss 0.44045490026474
68 epoch, 49 iter, loss 0.377236008644104
68 epoch, 50 iter, loss 0.28076818585395813
68 epoch, 51 iter, loss 0.33356696367263794
68 epoch, 52 iter, loss 0.27936139702796936
68 epoch, 53 iter, loss 0.30327874422073364
68 epoch, 54 iter, loss 0.2978881001472473
68 epoch, 55 iter, loss 0.32401466369628906
68 epoch, 56 iter, loss 0.3133793771266937
68 epoch, 57 iter, loss 0.36516550183296204
68 epoch, Average loss 0.3554230517985528
./model/merge_model_Param_v70.pth
some of decrypted state:
tensor([[[[ 6.8910e-02, -4.9915e-02,  5.5031e-02],
          [ 1.3371e-01,  1.4841e-01,  8.8698e-02],
          [-9.6132e-02, -8.7502e-02, -1.1443e-02]],

         [[-2.3576e-02,  1.2597e-01,  1.4027e-01],
          [-1.9608e-03,  8.5876e-02, -1.2008e-01],
          [-1.4044e-01, -5.7651e-02,  6.6089e-02]],

         [[ 1.0442e-01, -9.8312e-02,  1.1511e-02],
          [-8.2016e-05, -7.5648e-02,  7.7902e-02],
          [ 9.6408e-02,  1.0900e-01, -1.1820e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0673e-01, -1.4975e-01,  1.6509e-01],
          [ 4.0114e-01,  4.4524e-01,  2.6610e-01],
          [-2.8840e-01, -2.6251e-01, -3.4328e-02]],

         [[-7.0727e-02,  3.7792e-01,  4.2081e-01],
          [-5.8823e-03,  2.5763e-01, -3.6023e-01],
          [-4.2131e-01, -1.7295e-01,  1.9827e-01]],

         [[ 3.1325e-01, -2.9494e-01,  3.4533e-02],
          [-2.4605e-04, -2.2694e-01,  2.3371e-01],
          [ 2.8922e-01,  3.2699e-01, -3.5461e-01]]]], device='cuda:0')
start training
69 epoch, 1 iter, loss 0.22808809578418732
69 epoch, 2 iter, loss 0.37892404198646545
69 epoch, 3 iter, loss 0.31767210364341736
69 epoch, 4 iter, loss 0.47860878705978394
69 epoch, 5 iter, loss 0.16836486756801605
69 epoch, 6 iter, loss 0.4129747450351715
69 epoch, 7 iter, loss 0.3237275779247284
69 epoch, 8 iter, loss 0.29998061060905457
69 epoch, 9 iter, loss 0.28059855103492737
69 epoch, 10 iter, loss 0.41580110788345337
69 epoch, 11 iter, loss 0.5249351859092712
69 epoch, 12 iter, loss 0.5052793622016907
69 epoch, 13 iter, loss 0.26426562666893005
69 epoch, 14 iter, loss 0.32433459162712097
69 epoch, 15 iter, loss 0.22232799232006073
69 epoch, 16 iter, loss 0.2663511335849762
69 epoch, 17 iter, loss 0.3914220929145813
69 epoch, 18 iter, loss 0.31833598017692566
69 epoch, 19 iter, loss 0.2398710995912552
69 epoch, 20 iter, loss 0.39736416935920715
69 epoch, 21 iter, loss 0.4548020660877228
69 epoch, 22 iter, loss 0.3105381429195404
69 epoch, 23 iter, loss 0.38417574763298035
69 epoch, 24 iter, loss 0.31428465247154236
69 epoch, 25 iter, loss 0.26424530148506165
69 epoch, 26 iter, loss 0.3418363034725189
69 epoch, 27 iter, loss 0.21378038823604584
69 epoch, 28 iter, loss 0.16958031058311462
69 epoch, 29 iter, loss 0.24674032628536224
69 epoch, 30 iter, loss 0.3439873158931732
69 epoch, 31 iter, loss 0.34505191445350647
69 epoch, 32 iter, loss 0.21511124074459076
69 epoch, 33 iter, loss 0.4100683331489563
69 epoch, 34 iter, loss 0.46600714325904846
69 epoch, 35 iter, loss 0.41068190336227417
69 epoch, 36 iter, loss 0.2781223952770233
69 epoch, 37 iter, loss 0.19770310819149017
69 epoch, 38 iter, loss 0.40876907110214233
69 epoch, 39 iter, loss 0.3317893147468567
69 epoch, 40 iter, loss 0.33857008814811707
69 epoch, 41 iter, loss 0.38630756735801697
69 epoch, 42 iter, loss 0.20647364854812622
69 epoch, 43 iter, loss 0.44721442461013794
69 epoch, 44 iter, loss 0.5646972060203552
69 epoch, 45 iter, loss 0.23875489830970764
69 epoch, 46 iter, loss 0.3631502687931061
69 epoch, 47 iter, loss 0.39719197154045105
69 epoch, 48 iter, loss 0.20654959976673126
69 epoch, 49 iter, loss 0.33481666445732117
69 epoch, 50 iter, loss 0.3405574858188629
69 epoch, 51 iter, loss 0.308115154504776
69 epoch, 52 iter, loss 0.3736162781715393
69 epoch, 53 iter, loss 0.3576968014240265
69 epoch, 54 iter, loss 0.426220566034317
69 epoch, 55 iter, loss 0.32423919439315796
69 epoch, 56 iter, loss 0.23473091423511505
69 epoch, 57 iter, loss 0.46900540590286255
69 epoch, Average loss 0.336568611232858
./model/merge_model_Param_v71.pth
some of decrypted state:
tensor([[[[ 6.9205e-02, -4.9571e-02,  5.5384e-02],
          [ 1.3362e-01,  1.4838e-01,  8.8771e-02],
          [-9.5963e-02, -8.7164e-02, -1.1033e-02]],

         [[-2.3182e-02,  1.2633e-01,  1.4059e-01],
          [-1.8501e-03,  8.5976e-02, -1.1992e-01],
          [-1.4015e-01, -5.7258e-02,  6.6525e-02]],

         [[ 1.0463e-01, -9.8053e-02,  1.1715e-02],
          [-4.8637e-05, -7.5587e-02,  7.7971e-02],
          [ 9.6666e-02,  1.0940e-01, -1.1772e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0762e-01, -1.4871e-01,  1.6615e-01],
          [ 4.0087e-01,  4.4515e-01,  2.6631e-01],
          [-2.8789e-01, -2.6149e-01, -3.3099e-02]],

         [[-6.9546e-02,  3.7899e-01,  4.2176e-01],
          [-5.5504e-03,  2.5793e-01, -3.5975e-01],
          [-4.2045e-01, -1.7177e-01,  1.9958e-01]],

         [[ 3.1390e-01, -2.9416e-01,  3.5145e-02],
          [-1.4591e-04, -2.2676e-01,  2.3391e-01],
          [ 2.9000e-01,  3.2821e-01, -3.5316e-01]]]], device='cuda:0')
start training
70 epoch, 1 iter, loss 0.42544740438461304
70 epoch, 2 iter, loss 0.34972500801086426
70 epoch, 3 iter, loss 0.6062475442886353
70 epoch, 4 iter, loss 0.24144302308559418
70 epoch, 5 iter, loss 0.2805844843387604
70 epoch, 6 iter, loss 0.3305691182613373
70 epoch, 7 iter, loss 0.4505966007709503
70 epoch, 8 iter, loss 0.22948512434959412
70 epoch, 9 iter, loss 0.2959578037261963
70 epoch, 10 iter, loss 0.3335925042629242
70 epoch, 11 iter, loss 0.23901739716529846
70 epoch, 12 iter, loss 0.2565639019012451
70 epoch, 13 iter, loss 0.4269919991493225
70 epoch, 14 iter, loss 0.3169693946838379
70 epoch, 15 iter, loss 0.46547970175743103
70 epoch, 16 iter, loss 0.23909802734851837
70 epoch, 17 iter, loss 0.25255852937698364
70 epoch, 18 iter, loss 0.576183557510376
70 epoch, 19 iter, loss 0.4766247868537903
70 epoch, 20 iter, loss 0.33202260732650757
70 epoch, 21 iter, loss 0.3434879779815674
70 epoch, 22 iter, loss 0.25633373856544495
70 epoch, 23 iter, loss 0.47914764285087585
70 epoch, 24 iter, loss 0.40546345710754395
70 epoch, 25 iter, loss 0.24324317276477814
70 epoch, 26 iter, loss 0.3071768283843994
70 epoch, 27 iter, loss 0.4393267333507538
70 epoch, 28 iter, loss 0.3041050136089325
70 epoch, 29 iter, loss 0.4149142801761627
70 epoch, 30 iter, loss 0.3185458183288574
70 epoch, 31 iter, loss 0.26711687445640564
70 epoch, 32 iter, loss 0.28488895297050476
70 epoch, 33 iter, loss 0.4326770007610321
70 epoch, 34 iter, loss 0.26301220059394836
70 epoch, 35 iter, loss 0.2853877544403076
70 epoch, 36 iter, loss 0.4291626811027527
70 epoch, 37 iter, loss 0.3430728018283844
70 epoch, 38 iter, loss 0.4099334180355072
70 epoch, 39 iter, loss 0.38346439599990845
70 epoch, 40 iter, loss 0.47442230582237244
70 epoch, 41 iter, loss 0.34315556287765503
70 epoch, 42 iter, loss 0.26196083426475525
70 epoch, 43 iter, loss 0.3110320568084717
70 epoch, 44 iter, loss 0.46585023403167725
70 epoch, 45 iter, loss 0.30617600679397583
70 epoch, 46 iter, loss 0.2316094934940338
70 epoch, 47 iter, loss 0.2944904565811157
70 epoch, 48 iter, loss 0.33966299891471863
70 epoch, 49 iter, loss 0.26867836713790894
70 epoch, 50 iter, loss 0.38330528140068054
70 epoch, 51 iter, loss 0.30442988872528076
70 epoch, 52 iter, loss 0.31293290853500366
70 epoch, 53 iter, loss 0.261021226644516
70 epoch, 54 iter, loss 0.2981230616569519
70 epoch, 55 iter, loss 0.2736143469810486
70 epoch, 56 iter, loss 0.45876196026802063
70 epoch, 57 iter, loss 0.1599300503730774
70 epoch, Average loss 0.34183818075740546
./model/merge_model_Param_v72.pth
some of decrypted state:
tensor([[[[ 6.9120e-02, -4.9777e-02,  5.5082e-02],
          [ 1.3362e-01,  1.4842e-01,  8.8836e-02],
          [-9.6272e-02, -8.7470e-02, -1.1259e-02]],

         [[-2.3196e-02,  1.2621e-01,  1.4036e-01],
          [-1.8640e-03,  8.6007e-02, -1.1985e-01],
          [-1.4045e-01, -5.7597e-02,  6.6247e-02]],

         [[ 1.0445e-01, -9.8345e-02,  1.1388e-02],
          [-1.2970e-04, -7.5608e-02,  7.7929e-02],
          [ 9.6299e-02,  1.0906e-01, -1.1802e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0736e-01, -1.4933e-01,  1.6525e-01],
          [ 4.0085e-01,  4.4527e-01,  2.6651e-01],
          [-2.8882e-01, -2.6241e-01, -3.3777e-02]],

         [[-6.9589e-02,  3.7864e-01,  4.2107e-01],
          [-5.5919e-03,  2.5802e-01, -3.5954e-01],
          [-4.2134e-01, -1.7279e-01,  1.9874e-01]],

         [[ 3.1334e-01, -2.9504e-01,  3.4163e-02],
          [-3.8910e-04, -2.2682e-01,  2.3379e-01],
          [ 2.8890e-01,  3.2717e-01, -3.5405e-01]]]], device='cuda:0')
start training
71 epoch, 1 iter, loss 0.3048814833164215
71 epoch, 2 iter, loss 0.2750450074672699
71 epoch, 3 iter, loss 0.309154212474823
71 epoch, 4 iter, loss 0.3838600516319275
71 epoch, 5 iter, loss 0.17494115233421326
71 epoch, 6 iter, loss 0.3169158399105072
71 epoch, 7 iter, loss 0.3169228434562683
71 epoch, 8 iter, loss 0.3032638430595398
71 epoch, 9 iter, loss 0.39800381660461426
71 epoch, 10 iter, loss 0.34292516112327576
71 epoch, 11 iter, loss 0.18247096240520477
71 epoch, 12 iter, loss 0.438198447227478
71 epoch, 13 iter, loss 0.24177412688732147
71 epoch, 14 iter, loss 0.28198060393333435
71 epoch, 15 iter, loss 0.38264375925064087
71 epoch, 16 iter, loss 0.4079602062702179
71 epoch, 17 iter, loss 0.3043667674064636
71 epoch, 18 iter, loss 0.43240368366241455
71 epoch, 19 iter, loss 0.33042988181114197
71 epoch, 20 iter, loss 0.31029731035232544
71 epoch, 21 iter, loss 0.23763558268547058
71 epoch, 22 iter, loss 0.3149941861629486
71 epoch, 23 iter, loss 0.3250938653945923
71 epoch, 24 iter, loss 0.4797095060348511
71 epoch, 25 iter, loss 0.2598091959953308
71 epoch, 26 iter, loss 0.37645772099494934
71 epoch, 27 iter, loss 0.3297622799873352
71 epoch, 28 iter, loss 0.28313493728637695
71 epoch, 29 iter, loss 0.16766290366649628
71 epoch, 30 iter, loss 0.3075271248817444
71 epoch, 31 iter, loss 0.28994208574295044
71 epoch, 32 iter, loss 0.19160407781600952
71 epoch, 33 iter, loss 0.5575227737426758
71 epoch, 34 iter, loss 0.40547123551368713
71 epoch, 35 iter, loss 0.25761058926582336
71 epoch, 36 iter, loss 0.34049078822135925
71 epoch, 37 iter, loss 0.3329322338104248
71 epoch, 38 iter, loss 0.20276036858558655
71 epoch, 39 iter, loss 0.321559339761734
71 epoch, 40 iter, loss 0.5082585215568542
71 epoch, 41 iter, loss 0.41391345858573914
71 epoch, 42 iter, loss 0.25332704186439514
71 epoch, 43 iter, loss 0.22412921488285065
71 epoch, 44 iter, loss 0.4079315960407257
71 epoch, 45 iter, loss 0.3325306475162506
71 epoch, 46 iter, loss 0.23018299043178558
71 epoch, 47 iter, loss 0.277553528547287
71 epoch, 48 iter, loss 0.24946820735931396
71 epoch, 49 iter, loss 0.5697880983352661
71 epoch, 50 iter, loss 0.15184898674488068
71 epoch, 51 iter, loss 0.28575238585472107
71 epoch, 52 iter, loss 0.2666836082935333
71 epoch, 53 iter, loss 0.30513420701026917
71 epoch, 54 iter, loss 0.2903030216693878
71 epoch, 55 iter, loss 0.46026939153671265
71 epoch, 56 iter, loss 0.27105486392974854
71 epoch, 57 iter, loss 0.44038453698158264
71 epoch, Average loss 0.3220813028645097
./model/merge_model_Param_v73.pth
some of decrypted state:
tensor([[[[ 0.0692, -0.0497,  0.0552],
          [ 0.1336,  0.1486,  0.0892],
          [-0.0962, -0.0872, -0.0108]],

         [[-0.0230,  0.1264,  0.1406],
          [-0.0019,  0.0861, -0.1195],
          [-0.1403, -0.0573,  0.0667]],

         [[ 0.1045, -0.0982,  0.0115],
          [-0.0002, -0.0756,  0.0780],
          [ 0.0963,  0.1092, -0.1177]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2076, -0.1490,  0.1657],
          [ 0.4008,  0.4457,  0.2677],
          [-0.2885, -0.2615, -0.0325]],

         [[-0.0691,  0.3793,  0.4217],
          [-0.0056,  0.2583, -0.3585],
          [-0.4209, -0.1719,  0.2000]],

         [[ 0.3136, -0.2946,  0.0345],
          [-0.0006, -0.2269,  0.2340],
          [ 0.2889,  0.3275, -0.3532]]]], device='cuda:0')
start training
72 epoch, 1 iter, loss 0.30172720551490784
72 epoch, 2 iter, loss 0.34618398547172546
72 epoch, 3 iter, loss 0.31154221296310425
72 epoch, 4 iter, loss 0.41292911767959595
72 epoch, 5 iter, loss 0.38352468609809875
72 epoch, 6 iter, loss 0.473296582698822
72 epoch, 7 iter, loss 0.41193076968193054
72 epoch, 8 iter, loss 0.27913224697113037
72 epoch, 9 iter, loss 0.6588576436042786
72 epoch, 10 iter, loss 0.28275975584983826
72 epoch, 11 iter, loss 0.28583458065986633
72 epoch, 12 iter, loss 0.5071622133255005
72 epoch, 13 iter, loss 0.38994812965393066
72 epoch, 14 iter, loss 0.27330297231674194
72 epoch, 15 iter, loss 0.2536045014858246
72 epoch, 16 iter, loss 0.3229227066040039
72 epoch, 17 iter, loss 0.34046879410743713
72 epoch, 18 iter, loss 0.35174664855003357
72 epoch, 19 iter, loss 0.2432360202074051
72 epoch, 20 iter, loss 0.18960538506507874
72 epoch, 21 iter, loss 0.27679359912872314
72 epoch, 22 iter, loss 0.39973241090774536
72 epoch, 23 iter, loss 0.3345359265804291
72 epoch, 24 iter, loss 0.35536620020866394
72 epoch, 25 iter, loss 0.2829436659812927
72 epoch, 26 iter, loss 0.27248454093933105
72 epoch, 27 iter, loss 0.444839209318161
72 epoch, 28 iter, loss 0.35691308975219727
72 epoch, 29 iter, loss 0.32547512650489807
72 epoch, 30 iter, loss 0.29625144600868225
72 epoch, 31 iter, loss 0.36808064579963684
72 epoch, 32 iter, loss 0.38403335213661194
72 epoch, 33 iter, loss 0.39369574189186096
72 epoch, 34 iter, loss 0.45223742723464966
72 epoch, 35 iter, loss 0.17938761413097382
72 epoch, 36 iter, loss 0.35364478826522827
72 epoch, 37 iter, loss 0.40295884013175964
72 epoch, 38 iter, loss 0.46053194999694824
72 epoch, 39 iter, loss 0.2723505198955536
72 epoch, 40 iter, loss 0.4175339937210083
72 epoch, 41 iter, loss 0.42404866218566895
72 epoch, 42 iter, loss 0.26988667249679565
72 epoch, 43 iter, loss 0.29059192538261414
72 epoch, 44 iter, loss 0.3474404513835907
72 epoch, 45 iter, loss 0.22378292679786682
72 epoch, 46 iter, loss 0.27553433179855347
72 epoch, 47 iter, loss 0.22697366774082184
72 epoch, 48 iter, loss 0.2858647406101227
72 epoch, 49 iter, loss 0.36757442355155945
72 epoch, 50 iter, loss 0.3517613112926483
72 epoch, 51 iter, loss 0.2501377761363983
72 epoch, 52 iter, loss 0.28437045216560364
72 epoch, 53 iter, loss 0.42696669697761536
72 epoch, 54 iter, loss 0.4343705177307129
72 epoch, 55 iter, loss 0.4589598774909973
72 epoch, 56 iter, loss 0.24742092192173004
72 epoch, 57 iter, loss 0.500985860824585
72 epoch, Average loss 0.3458978502373946
./model/merge_model_Param_v74.pth
some of decrypted state:
tensor([[[[ 0.0693, -0.0495,  0.0553],
          [ 0.1338,  0.1487,  0.0892],
          [-0.0958, -0.0869, -0.0106]],

         [[-0.0228,  0.1267,  0.1407],
          [-0.0015,  0.0863, -0.1194],
          [-0.1398, -0.0569,  0.0670]],

         [[ 0.1046, -0.0981,  0.0115],
          [ 0.0002, -0.0755,  0.0780],
          [ 0.0968,  0.1096, -0.1175]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2080, -0.1486,  0.1658],
          [ 0.4015,  0.4460,  0.2677],
          [-0.2873, -0.2606, -0.0319]],

         [[-0.0684,  0.3800,  0.4221],
          [-0.0044,  0.2590, -0.3583],
          [-0.4195, -0.1708,  0.2009]],

         [[ 0.3138, -0.2944,  0.0344],
          [ 0.0005, -0.2265,  0.2339],
          [ 0.2904,  0.3288, -0.3524]]]], device='cuda:0')
start training
73 epoch, 1 iter, loss 0.26425641775131226
73 epoch, 2 iter, loss 0.3553106486797333
73 epoch, 3 iter, loss 0.3489786386489868
73 epoch, 4 iter, loss 0.2178935557603836
73 epoch, 5 iter, loss 0.1774372160434723
73 epoch, 6 iter, loss 0.2708702087402344
73 epoch, 7 iter, loss 0.23436084389686584
73 epoch, 8 iter, loss 0.2770721912384033
73 epoch, 9 iter, loss 0.27457866072654724
73 epoch, 10 iter, loss 0.303090363740921
73 epoch, 11 iter, loss 0.17836415767669678
73 epoch, 12 iter, loss 0.28162187337875366
73 epoch, 13 iter, loss 0.23951001465320587
73 epoch, 14 iter, loss 0.32492655515670776
73 epoch, 15 iter, loss 0.39508959650993347
73 epoch, 16 iter, loss 0.20740900933742523
73 epoch, 17 iter, loss 0.20853084325790405
73 epoch, 18 iter, loss 0.5417531728744507
73 epoch, 19 iter, loss 0.21322962641716003
73 epoch, 20 iter, loss 0.32619351148605347
73 epoch, 21 iter, loss 0.2223392128944397
73 epoch, 22 iter, loss 0.33685314655303955
73 epoch, 23 iter, loss 0.30352121591567993
73 epoch, 24 iter, loss 0.3148042559623718
73 epoch, 25 iter, loss 0.28153252601623535
73 epoch, 26 iter, loss 0.21577243506908417
73 epoch, 27 iter, loss 0.22214195132255554
73 epoch, 28 iter, loss 0.35556352138519287
73 epoch, 29 iter, loss 0.30113548040390015
73 epoch, 30 iter, loss 0.30061212182044983
73 epoch, 31 iter, loss 0.25316375494003296
73 epoch, 32 iter, loss 0.24260692298412323
73 epoch, 33 iter, loss 0.2777770161628723
73 epoch, 34 iter, loss 0.354394793510437
73 epoch, 35 iter, loss 0.3079538941383362
73 epoch, 36 iter, loss 0.32616138458251953
73 epoch, 37 iter, loss 0.3647138178348541
73 epoch, 38 iter, loss 0.39107003808021545
73 epoch, 39 iter, loss 0.3390561640262604
73 epoch, 40 iter, loss 0.298371285200119
73 epoch, 41 iter, loss 0.2912842035293579
73 epoch, 42 iter, loss 0.28826355934143066
73 epoch, 43 iter, loss 0.2250976860523224
73 epoch, 44 iter, loss 0.266495943069458
73 epoch, 45 iter, loss 0.19271156191825867
73 epoch, 46 iter, loss 0.3239639103412628
73 epoch, 47 iter, loss 0.2609279751777649
73 epoch, 48 iter, loss 0.5276672840118408
73 epoch, 49 iter, loss 0.33378008008003235
73 epoch, 50 iter, loss 0.37404951453208923
73 epoch, 51 iter, loss 0.30949804186820984
73 epoch, 52 iter, loss 0.33001893758773804
73 epoch, 53 iter, loss 0.3415163457393646
73 epoch, 54 iter, loss 0.3525889217853546
73 epoch, 55 iter, loss 0.38347914814949036
73 epoch, 56 iter, loss 0.2791958153247833
73 epoch, 57 iter, loss 0.27275320887565613
73 epoch, Average loss 0.29830375758179445
./model/merge_model_Param_v75.pth
some of decrypted state:
tensor([[[[ 6.9244e-02, -4.9567e-02,  5.5189e-02],
          [ 1.3380e-01,  1.4872e-01,  8.9329e-02],
          [-9.5891e-02, -8.6928e-02, -1.0542e-02]],

         [[-2.2856e-02,  1.2663e-01,  1.4068e-01],
          [-1.5354e-03,  8.6349e-02, -1.1929e-01],
          [-1.4000e-01, -5.7002e-02,  6.7036e-02]],

         [[ 1.0451e-01, -9.8166e-02,  1.1477e-02],
          [ 3.8147e-06, -7.5517e-02,  7.8020e-02],
          [ 9.6587e-02,  1.0952e-01, -1.1738e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0773e-01, -1.4870e-01,  1.6557e-01],
          [ 4.0139e-01,  4.4617e-01,  2.6799e-01],
          [-2.8767e-01, -2.6079e-01, -3.1627e-02]],

         [[-6.8569e-02,  3.7989e-01,  4.2205e-01],
          [-4.6062e-03,  2.5905e-01, -3.5788e-01],
          [-4.1999e-01, -1.7101e-01,  2.0111e-01]],

         [[ 3.1354e-01, -2.9450e-01,  3.4430e-02],
          [ 1.1444e-05, -2.2655e-01,  2.3406e-01],
          [ 2.8976e-01,  3.2855e-01, -3.5214e-01]]]], device='cuda:0')
start training
74 epoch, 1 iter, loss 0.47708189487457275
74 epoch, 2 iter, loss 0.2993471622467041
74 epoch, 3 iter, loss 0.31701377034187317
74 epoch, 4 iter, loss 0.4145662486553192
74 epoch, 5 iter, loss 0.2826545834541321
74 epoch, 6 iter, loss 0.20249535143375397
74 epoch, 7 iter, loss 0.21633745729923248
74 epoch, 8 iter, loss 0.22004950046539307
74 epoch, 9 iter, loss 0.2893601357936859
74 epoch, 10 iter, loss 0.29312047362327576
74 epoch, 11 iter, loss 0.2802186608314514
74 epoch, 12 iter, loss 0.28567036986351013
74 epoch, 13 iter, loss 0.2462056279182434
74 epoch, 14 iter, loss 0.24360036849975586
74 epoch, 15 iter, loss 0.24987401068210602
74 epoch, 16 iter, loss 0.30231332778930664
74 epoch, 17 iter, loss 0.25529491901397705
74 epoch, 18 iter, loss 0.26071491837501526
74 epoch, 19 iter, loss 0.2751971483230591
74 epoch, 20 iter, loss 0.3654567003250122
74 epoch, 21 iter, loss 0.29361692070961
74 epoch, 22 iter, loss 0.3153908848762512
74 epoch, 23 iter, loss 0.4544684886932373
74 epoch, 24 iter, loss 0.4088019132614136
74 epoch, 25 iter, loss 0.2736731469631195
74 epoch, 26 iter, loss 0.300680547952652
74 epoch, 27 iter, loss 0.34335485100746155
74 epoch, 28 iter, loss 0.1586616039276123
74 epoch, 29 iter, loss 0.34931161999702454
74 epoch, 30 iter, loss 0.3638708293437958
74 epoch, 31 iter, loss 0.46125996112823486
74 epoch, 32 iter, loss 0.28178170323371887
74 epoch, 33 iter, loss 0.3192650377750397
74 epoch, 34 iter, loss 0.252653568983078
74 epoch, 35 iter, loss 0.5222212672233582
74 epoch, 36 iter, loss 0.27011334896087646
74 epoch, 37 iter, loss 0.3117431700229645
74 epoch, 38 iter, loss 0.3397600054740906
74 epoch, 39 iter, loss 0.2579701840877533
74 epoch, 40 iter, loss 0.3120788633823395
74 epoch, 41 iter, loss 0.2820417881011963
74 epoch, 42 iter, loss 0.2153366506099701
74 epoch, 43 iter, loss 0.29998376965522766
74 epoch, 44 iter, loss 0.46665579080581665
74 epoch, 45 iter, loss 0.23191505670547485
74 epoch, 46 iter, loss 0.2590816915035248
74 epoch, 47 iter, loss 0.21548554301261902
74 epoch, 48 iter, loss 0.30851617455482483
74 epoch, 49 iter, loss 0.2872592806816101
74 epoch, 50 iter, loss 0.30279475450515747
74 epoch, 51 iter, loss 0.606314480304718
74 epoch, 52 iter, loss 0.355241060256958
74 epoch, 53 iter, loss 0.3899794816970825
74 epoch, 54 iter, loss 0.2620086371898651
74 epoch, 55 iter, loss 0.2889743447303772
74 epoch, 56 iter, loss 0.33323273062705994
74 epoch, 57 iter, loss 0.15857037901878357
74 epoch, Average loss 0.30930951159251363
./model/merge_model_Param_v76.pth
some of decrypted state:
tensor([[[[ 6.9152e-02, -4.9632e-02,  5.5082e-02],
          [ 1.3383e-01,  1.4884e-01,  8.9396e-02],
          [-9.6076e-02, -8.7079e-02, -1.0677e-02]],

         [[-2.3029e-02,  1.2647e-01,  1.4052e-01],
          [-1.5688e-03,  8.6342e-02, -1.1933e-01],
          [-1.4021e-01, -5.7220e-02,  6.6818e-02]],

         [[ 1.0432e-01, -9.8311e-02,  1.1328e-02],
          [-1.0920e-04, -7.5612e-02,  7.7887e-02],
          [ 9.6340e-02,  1.0928e-01, -1.1760e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0746e-01, -1.4889e-01,  1.6525e-01],
          [ 4.0148e-01,  4.4651e-01,  2.6819e-01],
          [-2.8823e-01, -2.6124e-01, -3.2032e-02]],

         [[-6.9088e-02,  3.7942e-01,  4.2155e-01],
          [-4.7064e-03,  2.5903e-01, -3.5799e-01],
          [-4.2064e-01, -1.7166e-01,  2.0045e-01]],

         [[ 3.1295e-01, -2.9493e-01,  3.3983e-02],
          [-3.2759e-04, -2.2684e-01,  2.3366e-01],
          [ 2.8902e-01,  3.2784e-01, -3.5281e-01]]]], device='cuda:0')
start training
75 epoch, 1 iter, loss 0.2398359179496765
75 epoch, 2 iter, loss 0.4931693375110626
75 epoch, 3 iter, loss 0.17548422515392303
75 epoch, 4 iter, loss 0.2847997546195984
75 epoch, 5 iter, loss 0.2942533791065216
75 epoch, 6 iter, loss 0.28229251503944397
75 epoch, 7 iter, loss 0.46123450994491577
75 epoch, 8 iter, loss 0.2713860273361206
75 epoch, 9 iter, loss 0.26873305439949036
75 epoch, 10 iter, loss 0.27550482749938965
75 epoch, 11 iter, loss 0.23244725167751312
75 epoch, 12 iter, loss 0.27452149987220764
75 epoch, 13 iter, loss 0.5791116952896118
75 epoch, 14 iter, loss 0.619629442691803
75 epoch, 15 iter, loss 0.2543732225894928
75 epoch, 16 iter, loss 0.3166638910770416
75 epoch, 17 iter, loss 0.2614494264125824
75 epoch, 18 iter, loss 0.311267614364624
75 epoch, 19 iter, loss 0.2494088113307953
75 epoch, 20 iter, loss 0.2320927083492279
75 epoch, 21 iter, loss 0.16901999711990356
75 epoch, 22 iter, loss 0.5604411363601685
75 epoch, 23 iter, loss 0.193690687417984
75 epoch, 24 iter, loss 0.20655515789985657
75 epoch, 25 iter, loss 0.3256149888038635
75 epoch, 26 iter, loss 0.39763158559799194
75 epoch, 27 iter, loss 0.19933409988880157
75 epoch, 28 iter, loss 0.20180025696754456
75 epoch, 29 iter, loss 0.37770411372184753
75 epoch, 30 iter, loss 0.27300089597702026
75 epoch, 31 iter, loss 0.25464627146720886
75 epoch, 32 iter, loss 0.24563337862491608
75 epoch, 33 iter, loss 0.34451308846473694
75 epoch, 34 iter, loss 0.2713233232498169
75 epoch, 35 iter, loss 0.40634089708328247
75 epoch, 36 iter, loss 0.326113224029541
75 epoch, 37 iter, loss 0.3019154667854309
75 epoch, 38 iter, loss 0.5258198976516724
75 epoch, 39 iter, loss 0.2511548399925232
75 epoch, 40 iter, loss 0.2247685194015503
75 epoch, 41 iter, loss 0.42330577969551086
75 epoch, 42 iter, loss 0.28087398409843445
75 epoch, 43 iter, loss 0.2840389311313629
75 epoch, 44 iter, loss 0.25446459650993347
75 epoch, 45 iter, loss 0.2676877975463867
75 epoch, 46 iter, loss 0.2916331887245178
75 epoch, 47 iter, loss 0.3265712857246399
75 epoch, 48 iter, loss 0.3087012469768524
75 epoch, 49 iter, loss 0.375508189201355
75 epoch, 50 iter, loss 0.22506418824195862
75 epoch, 51 iter, loss 0.3946124017238617
75 epoch, 52 iter, loss 0.2950029671192169
75 epoch, 53 iter, loss 0.2655462622642517
75 epoch, 54 iter, loss 0.3361484408378601
75 epoch, 55 iter, loss 0.43398404121398926
75 epoch, 56 iter, loss 0.20385600626468658
75 epoch, 57 iter, loss 0.5614462494850159
75 epoch, Average loss 0.31514257009614977
./model/merge_model_Param_v77.pth
some of decrypted state:
tensor([[[[ 6.9251e-02, -4.9607e-02,  5.4931e-02],
          [ 1.3401e-01,  1.4902e-01,  8.9545e-02],
          [-9.5836e-02, -8.6849e-02, -1.0453e-02]],

         [[-2.2812e-02,  1.2661e-01,  1.4047e-01],
          [-1.2894e-03,  8.6634e-02, -1.1907e-01],
          [-1.3998e-01, -5.7007e-02,  6.7051e-02]],

         [[ 1.0453e-01, -9.8170e-02,  1.1318e-02],
          [ 1.0681e-04, -7.5340e-02,  7.8116e-02],
          [ 9.6477e-02,  1.0943e-01, -1.1736e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0775e-01, -1.4882e-01,  1.6479e-01],
          [ 4.0204e-01,  4.4707e-01,  2.6864e-01],
          [-2.8751e-01, -2.6055e-01, -3.1358e-02]],

         [[-6.8436e-02,  3.7982e-01,  4.2141e-01],
          [-3.8681e-03,  2.5990e-01, -3.5720e-01],
          [-4.1994e-01, -1.7102e-01,  2.0115e-01]],

         [[ 3.1358e-01, -2.9451e-01,  3.3955e-02],
          [ 3.2043e-04, -2.2602e-01,  2.3435e-01],
          [ 2.8943e-01,  3.2828e-01, -3.5209e-01]]]], device='cuda:0')
start training
76 epoch, 1 iter, loss 0.25757357478141785
76 epoch, 2 iter, loss 0.4233493506908417
76 epoch, 3 iter, loss 0.3289814591407776
76 epoch, 4 iter, loss 0.37727779150009155
76 epoch, 5 iter, loss 0.44260406494140625
76 epoch, 6 iter, loss 0.26649266481399536
76 epoch, 7 iter, loss 0.307366281747818
76 epoch, 8 iter, loss 0.24646919965744019
76 epoch, 9 iter, loss 0.3177948296070099
76 epoch, 10 iter, loss 0.23310495913028717
76 epoch, 11 iter, loss 0.21525664627552032
76 epoch, 12 iter, loss 0.3452005386352539
76 epoch, 13 iter, loss 0.2598837614059448
76 epoch, 14 iter, loss 0.26865601539611816
76 epoch, 15 iter, loss 0.33469972014427185
76 epoch, 16 iter, loss 0.3919545114040375
76 epoch, 17 iter, loss 0.3090064823627472
76 epoch, 18 iter, loss 0.2599825859069824
76 epoch, 19 iter, loss 0.21478156745433807
76 epoch, 20 iter, loss 0.33090347051620483
76 epoch, 21 iter, loss 0.25885409116744995
76 epoch, 22 iter, loss 0.3521701395511627
76 epoch, 23 iter, loss 0.2114533931016922
76 epoch, 24 iter, loss 0.27881214022636414
76 epoch, 25 iter, loss 0.33582836389541626
76 epoch, 26 iter, loss 0.1953379213809967
76 epoch, 27 iter, loss 0.3573637306690216
76 epoch, 28 iter, loss 0.2686985433101654
76 epoch, 29 iter, loss 0.2196977138519287
76 epoch, 30 iter, loss 0.28973332047462463
76 epoch, 31 iter, loss 0.31851816177368164
76 epoch, 32 iter, loss 0.2806110382080078
76 epoch, 33 iter, loss 0.2150234580039978
76 epoch, 34 iter, loss 0.2117580622434616
76 epoch, 35 iter, loss 0.519489586353302
76 epoch, 36 iter, loss 0.45434343814849854
76 epoch, 37 iter, loss 0.2863467037677765
76 epoch, 38 iter, loss 0.3691635727882385
76 epoch, 39 iter, loss 0.20121127367019653
76 epoch, 40 iter, loss 0.30328288674354553
76 epoch, 41 iter, loss 0.24774233996868134
76 epoch, 42 iter, loss 0.1802845150232315
76 epoch, 43 iter, loss 0.13202573359012604
76 epoch, 44 iter, loss 0.2646277844905853
76 epoch, 45 iter, loss 0.36553531885147095
76 epoch, 46 iter, loss 0.36921459436416626
76 epoch, 47 iter, loss 0.27880385518074036
76 epoch, 48 iter, loss 0.3644525706768036
76 epoch, 49 iter, loss 0.33076927065849304
76 epoch, 50 iter, loss 0.37929391860961914
76 epoch, 51 iter, loss 0.32387587428092957
76 epoch, 52 iter, loss 0.30316591262817383
76 epoch, 53 iter, loss 0.26370182633399963
76 epoch, 54 iter, loss 0.18718379735946655
76 epoch, 55 iter, loss 0.42510557174682617
76 epoch, 56 iter, loss 0.396030068397522
76 epoch, 57 iter, loss 0.2721444070339203
76 epoch, Average loss 0.3007542872638033
./model/merge_model_Param_v78.pth
some of decrypted state:
tensor([[[[ 0.0691, -0.0498,  0.0548],
          [ 0.1342,  0.1491,  0.0896],
          [-0.0958, -0.0869, -0.0105]],

         [[-0.0229,  0.1264,  0.1403],
          [-0.0011,  0.0868, -0.1190],
          [-0.1400, -0.0571,  0.0670]],

         [[ 0.1044, -0.0983,  0.0112],
          [ 0.0003, -0.0752,  0.0782],
          [ 0.0965,  0.1094, -0.1174]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2072, -0.1494,  0.1643],
          [ 0.4025,  0.4474,  0.2688],
          [-0.2875, -0.2606, -0.0315]],

         [[-0.0688,  0.3793,  0.4210],
          [-0.0033,  0.2604, -0.3570],
          [-0.4199, -0.1712,  0.2009]],

         [[ 0.3133, -0.2949,  0.0336],
          [ 0.0008, -0.2256,  0.2346],
          [ 0.2896,  0.3283, -0.3521]]]], device='cuda:0')
start training
77 epoch, 1 iter, loss 0.22171059250831604
77 epoch, 2 iter, loss 0.23983146250247955
77 epoch, 3 iter, loss 0.2642451226711273
77 epoch, 4 iter, loss 0.2581067979335785
77 epoch, 5 iter, loss 0.1966085582971573
77 epoch, 6 iter, loss 0.21024282276630402
77 epoch, 7 iter, loss 0.2696884572505951
77 epoch, 8 iter, loss 0.23793090879917145
77 epoch, 9 iter, loss 0.270058274269104
77 epoch, 10 iter, loss 0.19252710044384003
77 epoch, 11 iter, loss 0.3414298892021179
77 epoch, 12 iter, loss 0.22621046006679535
77 epoch, 13 iter, loss 0.33347296714782715
77 epoch, 14 iter, loss 0.2363722175359726
77 epoch, 15 iter, loss 0.2479378581047058
77 epoch, 16 iter, loss 0.26387718319892883
77 epoch, 17 iter, loss 0.3381204903125763
77 epoch, 18 iter, loss 0.24483928084373474
77 epoch, 19 iter, loss 0.2570149004459381
77 epoch, 20 iter, loss 0.28113028407096863
77 epoch, 21 iter, loss 0.32372188568115234
77 epoch, 22 iter, loss 0.1849517524242401
77 epoch, 23 iter, loss 0.33754920959472656
77 epoch, 24 iter, loss 0.38276517391204834
77 epoch, 25 iter, loss 0.21219108998775482
77 epoch, 26 iter, loss 0.3619643449783325
77 epoch, 27 iter, loss 0.41496583819389343
77 epoch, 28 iter, loss 0.2705341875553131
77 epoch, 29 iter, loss 0.19984963536262512
77 epoch, 30 iter, loss 0.1810532808303833
77 epoch, 31 iter, loss 0.19123925268650055
77 epoch, 32 iter, loss 0.42189285159111023
77 epoch, 33 iter, loss 0.3276784420013428
77 epoch, 34 iter, loss 0.26307275891304016
77 epoch, 35 iter, loss 0.3462362587451935
77 epoch, 36 iter, loss 0.5307416915893555
77 epoch, 37 iter, loss 0.311325341463089
77 epoch, 38 iter, loss 0.22311781346797943
77 epoch, 39 iter, loss 0.1527918577194214
77 epoch, 40 iter, loss 0.2950855791568756
77 epoch, 41 iter, loss 0.37578141689300537
77 epoch, 42 iter, loss 0.34978315234184265
77 epoch, 43 iter, loss 0.3159277141094208
77 epoch, 44 iter, loss 0.2737290561199188
77 epoch, 45 iter, loss 0.2961839735507965
77 epoch, 46 iter, loss 0.22575023770332336
77 epoch, 47 iter, loss 0.25430214405059814
77 epoch, 48 iter, loss 0.3086213767528534
77 epoch, 49 iter, loss 0.16323770582675934
77 epoch, 50 iter, loss 0.2582896649837494
77 epoch, 51 iter, loss 0.20210690796375275
77 epoch, 52 iter, loss 0.29166609048843384
77 epoch, 53 iter, loss 0.30655479431152344
77 epoch, 54 iter, loss 0.3416203260421753
77 epoch, 55 iter, loss 0.2434871643781662
77 epoch, 56 iter, loss 0.2613738775253296
77 epoch, 57 iter, loss 0.3632919490337372
77 epoch, Average loss 0.27887353379475444
./model/merge_model_Param_v79.pth
some of decrypted state:
tensor([[[[ 0.0691, -0.0497,  0.0548],
          [ 0.1342,  0.1492,  0.0897],
          [-0.0959, -0.0869, -0.0105]],

         [[-0.0230,  0.1264,  0.1403],
          [-0.0011,  0.0868, -0.1190],
          [-0.1401, -0.0571,  0.0669]],

         [[ 0.1043, -0.0984,  0.0111],
          [ 0.0002, -0.0753,  0.0781],
          [ 0.0964,  0.1093, -0.1174]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2073, -0.1491,  0.1644],
          [ 0.4026,  0.4476,  0.2691],
          [-0.2876, -0.2606, -0.0314]],

         [[-0.0689,  0.3792,  0.4208],
          [-0.0034,  0.2603, -0.3570],
          [-0.4202, -0.1714,  0.2007]],

         [[ 0.3130, -0.2951,  0.0333],
          [ 0.0006, -0.2258,  0.2344],
          [ 0.2891,  0.3280, -0.3522]]]], device='cuda:0')
start training
78 epoch, 1 iter, loss 0.35369253158569336
78 epoch, 2 iter, loss 0.3010578453540802
78 epoch, 3 iter, loss 0.2568301558494568
78 epoch, 4 iter, loss 0.30532383918762207
78 epoch, 5 iter, loss 0.24781706929206848
78 epoch, 6 iter, loss 0.15307025611400604
78 epoch, 7 iter, loss 0.26151660084724426
78 epoch, 8 iter, loss 0.28854987025260925
78 epoch, 9 iter, loss 0.2909795343875885
78 epoch, 10 iter, loss 0.24700981378555298
78 epoch, 11 iter, loss 0.2953281104564667
78 epoch, 12 iter, loss 0.3319254219532013
78 epoch, 13 iter, loss 0.18942350149154663
78 epoch, 14 iter, loss 0.3664887249469757
78 epoch, 15 iter, loss 0.39477014541625977
78 epoch, 16 iter, loss 0.24695907533168793
78 epoch, 17 iter, loss 0.23371662199497223
78 epoch, 18 iter, loss 0.19238990545272827
78 epoch, 19 iter, loss 0.28057360649108887
78 epoch, 20 iter, loss 0.21116171777248383
78 epoch, 21 iter, loss 0.28096622228622437
78 epoch, 22 iter, loss 0.22768528759479523
78 epoch, 23 iter, loss 0.34753093123435974
78 epoch, 24 iter, loss 0.21904908120632172
78 epoch, 25 iter, loss 0.3692787289619446
78 epoch, 26 iter, loss 0.31922560930252075
78 epoch, 27 iter, loss 0.22259987890720367
78 epoch, 28 iter, loss 0.4636166989803314
78 epoch, 29 iter, loss 0.2278093695640564
78 epoch, 30 iter, loss 0.345388263463974
78 epoch, 31 iter, loss 0.2784603536128998
78 epoch, 32 iter, loss 0.2416359931230545
78 epoch, 33 iter, loss 0.26612362265586853
78 epoch, 34 iter, loss 0.3077812194824219
78 epoch, 35 iter, loss 0.38800185918807983
78 epoch, 36 iter, loss 0.3983268737792969
78 epoch, 37 iter, loss 0.3552723228931427
78 epoch, 38 iter, loss 0.26772060990333557
78 epoch, 39 iter, loss 0.372861385345459
78 epoch, 40 iter, loss 0.2900537848472595
78 epoch, 41 iter, loss 0.33706212043762207
78 epoch, 42 iter, loss 0.19753126800060272
78 epoch, 43 iter, loss 0.3608601689338684
78 epoch, 44 iter, loss 0.20616009831428528
78 epoch, 45 iter, loss 0.46261072158813477
78 epoch, 46 iter, loss 0.314913272857666
78 epoch, 47 iter, loss 0.20077429711818695
78 epoch, 48 iter, loss 0.3137263059616089
78 epoch, 49 iter, loss 0.3032071590423584
78 epoch, 50 iter, loss 0.34375524520874023
78 epoch, 51 iter, loss 0.513874351978302
78 epoch, 52 iter, loss 0.18150965869426727
78 epoch, 53 iter, loss 0.29857906699180603
78 epoch, 54 iter, loss 0.20589135587215424
78 epoch, 55 iter, loss 0.3242512345314026
78 epoch, 56 iter, loss 0.34872370958328247
78 epoch, 57 iter, loss 0.4071824550628662
78 epoch, Average loss 0.29751903393812346
./model/merge_model_Param_v80.pth
some of decrypted state:
tensor([[[[ 0.0692, -0.0496,  0.0549],
          [ 0.1343,  0.1494,  0.0899],
          [-0.0957, -0.0867, -0.0104]],

         [[-0.0229,  0.1264,  0.1403],
          [-0.0011,  0.0868, -0.1189],
          [-0.1400, -0.0571,  0.0669]],

         [[ 0.1043, -0.0984,  0.0111],
          [ 0.0002, -0.0753,  0.0781],
          [ 0.0964,  0.1093, -0.1174]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2076, -0.1487,  0.1648],
          [ 0.4029,  0.4481,  0.2696],
          [-0.2870, -0.2602, -0.0312]],

         [[-0.0688,  0.3793,  0.4209],
          [-0.0032,  0.2605, -0.3567],
          [-0.4199, -0.1714,  0.2006]],

         [[ 0.3130, -0.2951,  0.0333],
          [ 0.0006, -0.2258,  0.2343],
          [ 0.2891,  0.3279, -0.3522]]]], device='cuda:0')
start training
79 epoch, 1 iter, loss 0.20361460745334625
79 epoch, 2 iter, loss 0.34910276532173157
79 epoch, 3 iter, loss 0.41748523712158203
79 epoch, 4 iter, loss 0.22331523895263672
79 epoch, 5 iter, loss 0.1631772816181183
79 epoch, 6 iter, loss 0.3788292109966278
79 epoch, 7 iter, loss 0.575808584690094
79 epoch, 8 iter, loss 0.27737176418304443
79 epoch, 9 iter, loss 0.20228402316570282
79 epoch, 10 iter, loss 0.2580007016658783
79 epoch, 11 iter, loss 0.26045992970466614
79 epoch, 12 iter, loss 0.37627729773521423
79 epoch, 13 iter, loss 0.26433515548706055
79 epoch, 14 iter, loss 0.2579479217529297
79 epoch, 15 iter, loss 0.22979606688022614
79 epoch, 16 iter, loss 0.2894081175327301
79 epoch, 17 iter, loss 0.31908902525901794
79 epoch, 18 iter, loss 0.24499277770519257
79 epoch, 19 iter, loss 0.22209583222866058
79 epoch, 20 iter, loss 0.26967236399650574
79 epoch, 21 iter, loss 0.4963514804840088
79 epoch, 22 iter, loss 0.2988247871398926
79 epoch, 23 iter, loss 0.2404152750968933
79 epoch, 24 iter, loss 0.29420921206474304
79 epoch, 25 iter, loss 0.21924832463264465
79 epoch, 26 iter, loss 0.35687991976737976
79 epoch, 27 iter, loss 0.3020974099636078
79 epoch, 28 iter, loss 0.2780979871749878
79 epoch, 29 iter, loss 0.27238601446151733
79 epoch, 30 iter, loss 0.6880139112472534
79 epoch, 31 iter, loss 0.2540293037891388
79 epoch, 32 iter, loss 0.24916517734527588
79 epoch, 33 iter, loss 0.33676955103874207
79 epoch, 34 iter, loss 0.22805309295654297
79 epoch, 35 iter, loss 0.3078484535217285
79 epoch, 36 iter, loss 0.25892406702041626
79 epoch, 37 iter, loss 0.2994025945663452
79 epoch, 38 iter, loss 0.2033095508813858
79 epoch, 39 iter, loss 0.22120551764965057
79 epoch, 40 iter, loss 0.25784599781036377
79 epoch, 41 iter, loss 0.2657998204231262
79 epoch, 42 iter, loss 0.16548356413841248
79 epoch, 43 iter, loss 0.3116828501224518
79 epoch, 44 iter, loss 0.20660920441150665
79 epoch, 45 iter, loss 0.30709943175315857
79 epoch, 46 iter, loss 0.17985381186008453
79 epoch, 47 iter, loss 0.14734873175621033
79 epoch, 48 iter, loss 0.2726668119430542
79 epoch, 49 iter, loss 0.21294830739498138
79 epoch, 50 iter, loss 0.4831368327140808
79 epoch, 51 iter, loss 0.2843857705593109
79 epoch, 52 iter, loss 0.35439473390579224
79 epoch, 53 iter, loss 0.17887596786022186
79 epoch, 54 iter, loss 0.2569960355758667
79 epoch, 55 iter, loss 0.24042610824108124
79 epoch, 56 iter, loss 0.211824432015419
79 epoch, 57 iter, loss 0.2495526224374771
79 epoch, Average loss 0.28377590472238107
./model/merge_model_Param_v81.pth
some of decrypted state:
tensor([[[[ 0.0693, -0.0495,  0.0549],
          [ 0.1344,  0.1494,  0.0898],
          [-0.0957, -0.0867, -0.0104]],

         [[-0.0228,  0.1265,  0.1403],
          [-0.0010,  0.0869, -0.1189],
          [-0.1399, -0.0571,  0.0668]],

         [[ 0.1044, -0.0983,  0.0111],
          [ 0.0002, -0.0752,  0.0781],
          [ 0.0963,  0.1093, -0.1174]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2079, -0.1485,  0.1647],
          [ 0.4031,  0.4481,  0.2694],
          [-0.2870, -0.2602, -0.0312]],

         [[-0.0684,  0.3795,  0.4208],
          [-0.0029,  0.2606, -0.3567],
          [-0.4198, -0.1713,  0.2005]],

         [[ 0.3132, -0.2949,  0.0333],
          [ 0.0007, -0.2257,  0.2343],
          [ 0.2890,  0.3280, -0.3522]]]], device='cuda:0')
start training
80 epoch, 1 iter, loss 0.4253956377506256
80 epoch, 2 iter, loss 0.3256481885910034
80 epoch, 3 iter, loss 0.2820369005203247
80 epoch, 4 iter, loss 0.32281750440597534
80 epoch, 5 iter, loss 0.24072958528995514
80 epoch, 6 iter, loss 0.273103266954422
80 epoch, 7 iter, loss 0.2508796453475952
80 epoch, 8 iter, loss 0.33181896805763245
80 epoch, 9 iter, loss 0.3475130498409271
80 epoch, 10 iter, loss 0.207500159740448
80 epoch, 11 iter, loss 0.23561923205852509
80 epoch, 12 iter, loss 0.26188924908638
80 epoch, 13 iter, loss 0.22901998460292816
80 epoch, 14 iter, loss 0.3213861882686615
80 epoch, 15 iter, loss 0.30151134729385376
80 epoch, 16 iter, loss 0.4334580898284912
80 epoch, 17 iter, loss 0.29251226782798767
80 epoch, 18 iter, loss 0.19876471161842346
80 epoch, 19 iter, loss 0.22931817173957825
80 epoch, 20 iter, loss 0.48784130811691284
80 epoch, 21 iter, loss 0.32138195633888245
80 epoch, 22 iter, loss 0.26043984293937683
80 epoch, 23 iter, loss 0.2939152419567108
80 epoch, 24 iter, loss 0.3066340982913971
80 epoch, 25 iter, loss 0.26450932025909424
80 epoch, 26 iter, loss 0.32094916701316833
80 epoch, 27 iter, loss 0.4010944664478302
80 epoch, 28 iter, loss 0.21171703934669495
80 epoch, 29 iter, loss 0.2351723462343216
80 epoch, 30 iter, loss 0.3876495957374573
80 epoch, 31 iter, loss 0.25199514627456665
80 epoch, 32 iter, loss 0.4923587441444397
80 epoch, 33 iter, loss 0.2502680718898773
80 epoch, 34 iter, loss 0.27097463607788086
80 epoch, 35 iter, loss 0.20790083706378937
80 epoch, 36 iter, loss 0.31404709815979004
80 epoch, 37 iter, loss 0.2613869607448578
80 epoch, 38 iter, loss 0.20429767668247223
80 epoch, 39 iter, loss 0.3796103000640869
80 epoch, 40 iter, loss 0.2804100513458252
80 epoch, 41 iter, loss 0.26658448576927185
80 epoch, 42 iter, loss 0.253845751285553
80 epoch, 43 iter, loss 0.19107778370380402
80 epoch, 44 iter, loss 0.35621631145477295
80 epoch, 45 iter, loss 0.17160575091838837
80 epoch, 46 iter, loss 0.23015455901622772
80 epoch, 47 iter, loss 0.2353605180978775
80 epoch, 48 iter, loss 0.1147092655301094
80 epoch, 49 iter, loss 0.21974927186965942
80 epoch, 50 iter, loss 0.3108520805835724
80 epoch, 51 iter, loss 0.2413914054632187
80 epoch, 52 iter, loss 0.21320568025112152
80 epoch, 53 iter, loss 0.4263618588447571
80 epoch, 54 iter, loss 0.3698829412460327
80 epoch, 55 iter, loss 0.27275750041007996
80 epoch, 56 iter, loss 0.19695612788200378
80 epoch, 57 iter, loss 0.2744693160057068
80 epoch, Average loss 0.2852746782857075
./model/merge_model_Param_v82.pth
some of decrypted state:
tensor([[[[ 0.0694, -0.0494,  0.0549],
          [ 0.1345,  0.1495,  0.0900],
          [-0.0955, -0.0865, -0.0101]],

         [[-0.0227,  0.1265,  0.1402],
          [-0.0009,  0.0870, -0.1187],
          [-0.1398, -0.0569,  0.0671]],

         [[ 0.1044, -0.0984,  0.0110],
          [ 0.0002, -0.0753,  0.0781],
          [ 0.0963,  0.1094, -0.1172]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2082, -0.1483,  0.1647],
          [ 0.4035,  0.4485,  0.2701],
          [-0.2865, -0.2594, -0.0303]],

         [[-0.0682,  0.3796,  0.4207],
          [-0.0026,  0.2609, -0.3562],
          [-0.4195, -0.1708,  0.2013]],

         [[ 0.3131, -0.2951,  0.0330],
          [ 0.0006, -0.2258,  0.2344],
          [ 0.2890,  0.3283, -0.3517]]]], device='cuda:0')
start training
81 epoch, 1 iter, loss 0.23537103831768036
81 epoch, 2 iter, loss 0.25980696082115173
81 epoch, 3 iter, loss 0.28676462173461914
81 epoch, 4 iter, loss 0.2790960371494293
81 epoch, 5 iter, loss 0.2515992820262909
81 epoch, 6 iter, loss 0.4303726851940155
81 epoch, 7 iter, loss 0.2016880065202713
81 epoch, 8 iter, loss 0.26172950863838196
81 epoch, 9 iter, loss 0.20465008914470673
81 epoch, 10 iter, loss 0.41707757115364075
81 epoch, 11 iter, loss 0.28624314069747925
81 epoch, 12 iter, loss 0.22449645400047302
81 epoch, 13 iter, loss 0.42001450061798096
81 epoch, 14 iter, loss 0.3047720491886139
81 epoch, 15 iter, loss 0.23723606765270233
81 epoch, 16 iter, loss 0.21539916098117828
81 epoch, 17 iter, loss 0.37526723742485046
81 epoch, 18 iter, loss 0.2695029675960541
81 epoch, 19 iter, loss 0.1346353143453598
81 epoch, 20 iter, loss 0.12803681194782257
81 epoch, 21 iter, loss 0.17885033786296844
81 epoch, 22 iter, loss 0.23587580025196075
81 epoch, 23 iter, loss 0.49207067489624023
81 epoch, 24 iter, loss 0.21212539076805115
81 epoch, 25 iter, loss 0.2788311243057251
81 epoch, 26 iter, loss 0.20883134007453918
81 epoch, 27 iter, loss 0.2748669981956482
81 epoch, 28 iter, loss 0.22142855823040009
81 epoch, 29 iter, loss 0.29561278223991394
81 epoch, 30 iter, loss 0.42019057273864746
81 epoch, 31 iter, loss 0.20406976342201233
81 epoch, 32 iter, loss 0.30266571044921875
81 epoch, 33 iter, loss 0.365532785654068
81 epoch, 34 iter, loss 0.18878066539764404
81 epoch, 35 iter, loss 0.3023112416267395
81 epoch, 36 iter, loss 0.25768595933914185
81 epoch, 37 iter, loss 0.29490843415260315
81 epoch, 38 iter, loss 0.20890212059020996
81 epoch, 39 iter, loss 0.2512926757335663
81 epoch, 40 iter, loss 0.229007750749588
81 epoch, 41 iter, loss 0.25298237800598145
81 epoch, 42 iter, loss 0.4634961783885956
81 epoch, 43 iter, loss 0.3673766851425171
81 epoch, 44 iter, loss 0.2890150547027588
81 epoch, 45 iter, loss 0.31049463152885437
81 epoch, 46 iter, loss 0.13136588037014008
81 epoch, 47 iter, loss 0.2586704194545746
81 epoch, 48 iter, loss 0.2801513671875
81 epoch, 49 iter, loss 0.28080517053604126
81 epoch, 50 iter, loss 0.24101127684116364
81 epoch, 51 iter, loss 0.2068399339914322
81 epoch, 52 iter, loss 0.26195695996284485
81 epoch, 53 iter, loss 0.192214235663414
81 epoch, 54 iter, loss 0.35496652126312256
81 epoch, 55 iter, loss 0.2709931433200836
81 epoch, 56 iter, loss 0.36544299125671387
81 epoch, 57 iter, loss 0.30009594559669495
81 epoch, Average loss 0.27500840289550915
./model/merge_model_Param_v83.pth
some of decrypted state:
tensor([[[[ 6.9417e-02, -4.9462e-02,  5.4836e-02],
          [ 1.3444e-01,  1.4946e-01,  8.9995e-02],
          [-9.5633e-02, -8.6566e-02, -1.0163e-02]],

         [[-2.2711e-02,  1.2653e-01,  1.4018e-01],
          [-9.1410e-04,  8.6934e-02, -1.1877e-01],
          [-1.3996e-01, -5.7036e-02,  6.7017e-02]],

         [[ 1.0439e-01, -9.8376e-02,  1.0954e-02],
          [ 1.2875e-04, -7.5343e-02,  7.8063e-02],
          [ 9.6235e-02,  1.0933e-01, -1.1729e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0825e-01, -1.4839e-01,  1.6451e-01],
          [ 4.0332e-01,  4.4837e-01,  2.6999e-01],
          [-2.8690e-01, -2.5970e-01, -3.0490e-02]],

         [[-6.8134e-02,  3.7958e-01,  4.2054e-01],
          [-2.7423e-03,  2.6080e-01, -3.5631e-01],
          [-4.1987e-01, -1.7111e-01,  2.0105e-01]],

         [[ 3.1317e-01, -2.9513e-01,  3.2862e-02],
          [ 3.8624e-04, -2.2603e-01,  2.3419e-01],
          [ 2.8871e-01,  3.2800e-01, -3.5188e-01]]]], device='cuda:0')
start training
82 epoch, 1 iter, loss 0.23725853860378265
82 epoch, 2 iter, loss 0.17437461018562317
82 epoch, 3 iter, loss 0.1617722064256668
82 epoch, 4 iter, loss 0.2851337194442749
82 epoch, 5 iter, loss 0.2998405396938324
82 epoch, 6 iter, loss 0.26000693440437317
82 epoch, 7 iter, loss 0.2823105454444885
82 epoch, 8 iter, loss 0.43654191493988037
82 epoch, 9 iter, loss 0.2511899173259735
82 epoch, 10 iter, loss 0.24067337810993195
82 epoch, 11 iter, loss 0.3018251061439514
82 epoch, 12 iter, loss 0.37366652488708496
82 epoch, 13 iter, loss 0.23761402070522308
82 epoch, 14 iter, loss 0.29672449827194214
82 epoch, 15 iter, loss 0.2158869355916977
82 epoch, 16 iter, loss 0.32371121644973755
82 epoch, 17 iter, loss 0.27375155687332153
82 epoch, 18 iter, loss 0.21789412200450897
82 epoch, 19 iter, loss 0.24673041701316833
82 epoch, 20 iter, loss 0.24687853455543518
82 epoch, 21 iter, loss 0.26106441020965576
82 epoch, 22 iter, loss 0.2565379738807678
82 epoch, 23 iter, loss 0.23249632120132446
82 epoch, 24 iter, loss 0.29058629274368286
82 epoch, 25 iter, loss 0.33355674147605896
82 epoch, 26 iter, loss 0.196344792842865
82 epoch, 27 iter, loss 0.3323085308074951
82 epoch, 28 iter, loss 0.3770427405834198
82 epoch, 29 iter, loss 0.22398976981639862
82 epoch, 30 iter, loss 0.267596572637558
82 epoch, 31 iter, loss 0.22993780672550201
82 epoch, 32 iter, loss 0.2921789884567261
82 epoch, 33 iter, loss 0.2784336507320404
82 epoch, 34 iter, loss 0.3502541482448578
82 epoch, 35 iter, loss 0.15541456639766693
82 epoch, 36 iter, loss 0.26412081718444824
82 epoch, 37 iter, loss 0.2920704185962677
82 epoch, 38 iter, loss 0.34748804569244385
82 epoch, 39 iter, loss 0.246782585978508
82 epoch, 40 iter, loss 0.21091826260089874
82 epoch, 41 iter, loss 0.2363746464252472
82 epoch, 42 iter, loss 0.356299489736557
82 epoch, 43 iter, loss 0.24765601754188538
82 epoch, 44 iter, loss 0.22643114626407623
82 epoch, 45 iter, loss 0.20334085822105408
82 epoch, 46 iter, loss 0.3166595995426178
82 epoch, 47 iter, loss 0.26261189579963684
82 epoch, 48 iter, loss 0.29299652576446533
82 epoch, 49 iter, loss 0.32375240325927734
82 epoch, 50 iter, loss 0.2301458865404129
82 epoch, 51 iter, loss 0.19594471156597137
82 epoch, 52 iter, loss 0.16315029561519623
82 epoch, 53 iter, loss 0.2448190301656723
82 epoch, 54 iter, loss 0.26308876276016235
82 epoch, 55 iter, loss 0.2870027422904968
82 epoch, 56 iter, loss 0.3069576621055603
82 epoch, 57 iter, loss 0.5575454235076904
82 epoch, Average loss 0.27224010124541165
./model/merge_model_Param_v84.pth
some of decrypted state:
tensor([[[[ 0.0694, -0.0495,  0.0548],
          [ 0.1345,  0.1495,  0.0900],
          [-0.0957, -0.0866, -0.0102]],

         [[-0.0227,  0.1265,  0.1401],
          [-0.0009,  0.0870, -0.1187],
          [-0.1400, -0.0571,  0.0670]],

         [[ 0.1044, -0.0984,  0.0109],
          [ 0.0002, -0.0753,  0.0781],
          [ 0.0962,  0.1093, -0.1173]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2083, -0.1485,  0.1643],
          [ 0.4034,  0.4485,  0.2701],
          [-0.2871, -0.2598, -0.0306]],

         [[-0.0681,  0.3794,  0.4202],
          [-0.0026,  0.2609, -0.3562],
          [-0.4200, -0.1712,  0.2009]],

         [[ 0.3132, -0.2952,  0.0326],
          [ 0.0006, -0.2258,  0.2344],
          [ 0.2887,  0.3280, -0.3518]]]], device='cuda:0')
start training
83 epoch, 1 iter, loss 0.21452979743480682
83 epoch, 2 iter, loss 0.17086553573608398
83 epoch, 3 iter, loss 0.37983882427215576
83 epoch, 4 iter, loss 0.31281813979148865
83 epoch, 5 iter, loss 0.290345162153244
83 epoch, 6 iter, loss 0.2778579890727997
83 epoch, 7 iter, loss 0.3065039813518524
83 epoch, 8 iter, loss 0.28450143337249756
83 epoch, 9 iter, loss 0.2629338800907135
83 epoch, 10 iter, loss 0.237737774848938
83 epoch, 11 iter, loss 0.27421942353248596
83 epoch, 12 iter, loss 0.27516695857048035
83 epoch, 13 iter, loss 0.21633774042129517
83 epoch, 14 iter, loss 0.17678996920585632
83 epoch, 15 iter, loss 0.449354350566864
83 epoch, 16 iter, loss 0.28011658787727356
83 epoch, 17 iter, loss 0.30575504899024963
83 epoch, 18 iter, loss 0.3586530089378357
83 epoch, 19 iter, loss 0.1927681416273117
83 epoch, 20 iter, loss 0.2830338180065155
83 epoch, 21 iter, loss 0.24642641842365265
83 epoch, 22 iter, loss 0.31291720271110535
83 epoch, 23 iter, loss 0.21194425225257874
83 epoch, 24 iter, loss 0.23444770276546478
83 epoch, 25 iter, loss 0.16585637629032135
83 epoch, 26 iter, loss 0.23412825167179108
83 epoch, 27 iter, loss 0.20922857522964478
83 epoch, 28 iter, loss 0.1953893005847931
83 epoch, 29 iter, loss 0.26439329981803894
83 epoch, 30 iter, loss 0.22170278429985046
83 epoch, 31 iter, loss 0.18193350732326508
83 epoch, 32 iter, loss 0.3395541310310364
83 epoch, 33 iter, loss 0.486591637134552
83 epoch, 34 iter, loss 0.27561137080192566
83 epoch, 35 iter, loss 0.18834492564201355
83 epoch, 36 iter, loss 0.21873287856578827
83 epoch, 37 iter, loss 0.20658066868782043
83 epoch, 38 iter, loss 0.21968728303909302
83 epoch, 39 iter, loss 0.21146923303604126
83 epoch, 40 iter, loss 0.11762291938066483
83 epoch, 41 iter, loss 0.3883425295352936
83 epoch, 42 iter, loss 0.1816614419221878
83 epoch, 43 iter, loss 0.32805335521698
83 epoch, 44 iter, loss 0.29710230231285095
83 epoch, 45 iter, loss 0.2743236720561981
83 epoch, 46 iter, loss 0.15757891535758972
83 epoch, 47 iter, loss 0.21595241129398346
83 epoch, 48 iter, loss 0.3214735984802246
83 epoch, 49 iter, loss 0.3768497407436371
83 epoch, 50 iter, loss 0.16344527900218964
83 epoch, 51 iter, loss 0.28804001212120056
83 epoch, 52 iter, loss 0.24592548608779907
83 epoch, 53 iter, loss 0.28641319274902344
83 epoch, 54 iter, loss 0.20700450241565704
83 epoch, 55 iter, loss 0.24989743530750275
83 epoch, 56 iter, loss 0.2287408411502838
83 epoch, 57 iter, loss 0.19798554480075836
83 epoch, Average loss 0.25792071131760613
./model/merge_model_Param_v85.pth
some of decrypted state:
tensor([[[[ 0.0695, -0.0494,  0.0548],
          [ 0.1345,  0.1496,  0.0902],
          [-0.0956, -0.0865, -0.0101]],

         [[-0.0227,  0.1265,  0.1401],
          [-0.0008,  0.0870, -0.1186],
          [-0.1399, -0.0570,  0.0670]],

         [[ 0.1044, -0.0984,  0.0109],
          [ 0.0002, -0.0753,  0.0781],
          [ 0.0962,  0.1094, -0.1172]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2084, -0.1483,  0.1645],
          [ 0.4035,  0.4487,  0.2705],
          [-0.2867, -0.2594, -0.0303]],

         [[-0.0680,  0.3795,  0.4203],
          [-0.0025,  0.2611, -0.3559],
          [-0.4198, -0.1710,  0.2011]],

         [[ 0.3132, -0.2952,  0.0327],
          [ 0.0005, -0.2258,  0.2344],
          [ 0.2887,  0.3281, -0.3517]]]], device='cuda:0')
start training
84 epoch, 1 iter, loss 0.2392961084842682
84 epoch, 2 iter, loss 0.28186190128326416
84 epoch, 3 iter, loss 0.26835083961486816
84 epoch, 4 iter, loss 0.34527692198753357
84 epoch, 5 iter, loss 0.29979708790779114
84 epoch, 6 iter, loss 0.28488031029701233
84 epoch, 7 iter, loss 0.21849393844604492
84 epoch, 8 iter, loss 0.2771526873111725
84 epoch, 9 iter, loss 0.20461317896842957
84 epoch, 10 iter, loss 0.3619951903820038
84 epoch, 11 iter, loss 0.30737197399139404
84 epoch, 12 iter, loss 0.28960132598876953
84 epoch, 13 iter, loss 0.3547716736793518
84 epoch, 14 iter, loss 0.39984220266342163
84 epoch, 15 iter, loss 0.3852001130580902
84 epoch, 16 iter, loss 0.2093488723039627
84 epoch, 17 iter, loss 0.3361635208129883
84 epoch, 18 iter, loss 0.2621966004371643
84 epoch, 19 iter, loss 0.261142373085022
84 epoch, 20 iter, loss 0.20388498902320862
84 epoch, 21 iter, loss 0.24931606650352478
84 epoch, 22 iter, loss 0.26625558733940125
84 epoch, 23 iter, loss 0.34841498732566833
84 epoch, 24 iter, loss 0.2046520859003067
84 epoch, 25 iter, loss 0.26426050066947937
84 epoch, 26 iter, loss 0.2699068486690521
84 epoch, 27 iter, loss 0.4031534492969513
84 epoch, 28 iter, loss 0.2509440779685974
84 epoch, 29 iter, loss 0.24061445891857147
84 epoch, 30 iter, loss 0.25541213154792786
84 epoch, 31 iter, loss 0.15359468758106232
84 epoch, 32 iter, loss 0.14702454209327698
84 epoch, 33 iter, loss 0.25296205282211304
84 epoch, 34 iter, loss 0.3888072669506073
84 epoch, 35 iter, loss 0.30129849910736084
84 epoch, 36 iter, loss 0.16144897043704987
84 epoch, 37 iter, loss 0.26213791966438293
84 epoch, 38 iter, loss 0.2722800374031067
84 epoch, 39 iter, loss 0.20647363364696503
84 epoch, 40 iter, loss 0.18450407683849335
84 epoch, 41 iter, loss 0.3474421799182892
84 epoch, 42 iter, loss 0.19415248930454254
84 epoch, 43 iter, loss 0.24440303444862366
84 epoch, 44 iter, loss 0.24895049631595612
84 epoch, 45 iter, loss 0.4101039171218872
84 epoch, 46 iter, loss 0.2727665603160858
84 epoch, 47 iter, loss 0.23707079887390137
84 epoch, 48 iter, loss 0.1943083107471466
84 epoch, 49 iter, loss 0.304263174533844
84 epoch, 50 iter, loss 0.3285784125328064
84 epoch, 51 iter, loss 0.22552409768104553
84 epoch, 52 iter, loss 0.37235814332962036
84 epoch, 53 iter, loss 0.367199569940567
84 epoch, 54 iter, loss 0.3948262631893158
84 epoch, 55 iter, loss 0.28189605474472046
84 epoch, 56 iter, loss 0.26492732763290405
84 epoch, 57 iter, loss 0.37893328070640564
84 epoch, Average loss 0.27969136494293545
./model/merge_model_Param_v86.pth
some of decrypted state:
tensor([[[[ 6.9489e-02, -4.9410e-02,  5.4867e-02],
          [ 1.3447e-01,  1.4958e-01,  9.0205e-02],
          [-9.5570e-02, -8.6405e-02, -9.9893e-03]],

         [[-2.2631e-02,  1.2653e-01,  1.4014e-01],
          [-8.4400e-04,  8.7036e-02, -1.1861e-01],
          [-1.3995e-01, -5.6973e-02,  6.7111e-02]],

         [[ 1.0444e-01, -9.8352e-02,  1.0935e-02],
          [ 1.3161e-04, -7.5312e-02,  7.8102e-02],
          [ 9.6202e-02,  1.0938e-01, -1.1717e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0847e-01, -1.4823e-01,  1.6460e-01],
          [ 4.0341e-01,  4.4873e-01,  2.7062e-01],
          [-2.8671e-01, -2.5922e-01, -2.9968e-02]],

         [[-6.7894e-02,  3.7960e-01,  4.2042e-01],
          [-2.5320e-03,  2.6111e-01, -3.5583e-01],
          [-4.1985e-01, -1.7092e-01,  2.0133e-01]],

         [[ 3.1331e-01, -2.9506e-01,  3.2804e-02],
          [ 3.9482e-04, -2.2594e-01,  2.3431e-01],
          [ 2.8861e-01,  3.2815e-01, -3.5152e-01]]]], device='cuda:0')
start training
85 epoch, 1 iter, loss 0.22075249254703522
85 epoch, 2 iter, loss 0.28009188175201416
85 epoch, 3 iter, loss 0.2728469669818878
85 epoch, 4 iter, loss 0.22179783880710602
85 epoch, 5 iter, loss 0.2853347063064575
85 epoch, 6 iter, loss 0.2451416701078415
85 epoch, 7 iter, loss 0.23723344504833221
85 epoch, 8 iter, loss 0.23109853267669678
85 epoch, 9 iter, loss 0.2304864078760147
85 epoch, 10 iter, loss 0.296366810798645
85 epoch, 11 iter, loss 0.3268738389015198
85 epoch, 12 iter, loss 0.19206702709197998
85 epoch, 13 iter, loss 0.23051726818084717
85 epoch, 14 iter, loss 0.20997853577136993
85 epoch, 15 iter, loss 0.25662946701049805
85 epoch, 16 iter, loss 0.2475334107875824
85 epoch, 17 iter, loss 0.1876143515110016
85 epoch, 18 iter, loss 0.29430001974105835
85 epoch, 19 iter, loss 0.19131872057914734
85 epoch, 20 iter, loss 0.18413785099983215
85 epoch, 21 iter, loss 0.25883325934410095
85 epoch, 22 iter, loss 0.27175262570381165
85 epoch, 23 iter, loss 0.16636739671230316
85 epoch, 24 iter, loss 0.24365901947021484
85 epoch, 25 iter, loss 0.24741733074188232
85 epoch, 26 iter, loss 0.19680820405483246
85 epoch, 27 iter, loss 0.19717328250408173
85 epoch, 28 iter, loss 0.32846108078956604
85 epoch, 29 iter, loss 0.21552208065986633
85 epoch, 30 iter, loss 0.23788844048976898
85 epoch, 31 iter, loss 0.27747270464897156
85 epoch, 32 iter, loss 0.28055986762046814
85 epoch, 33 iter, loss 0.2454172521829605
85 epoch, 34 iter, loss 0.2041282057762146
85 epoch, 35 iter, loss 0.25834921002388
85 epoch, 36 iter, loss 0.2691061198711395
85 epoch, 37 iter, loss 0.3226296007633209
85 epoch, 38 iter, loss 0.19630280137062073
85 epoch, 39 iter, loss 0.157565176486969
85 epoch, 40 iter, loss 0.24221502244472504
85 epoch, 41 iter, loss 0.26312389969825745
85 epoch, 42 iter, loss 0.37782415747642517
85 epoch, 43 iter, loss 0.27768680453300476
85 epoch, 44 iter, loss 0.19765391945838928
85 epoch, 45 iter, loss 0.21902154386043549
85 epoch, 46 iter, loss 0.1857440173625946
85 epoch, 47 iter, loss 0.1645718812942505
85 epoch, 48 iter, loss 0.28540387749671936
85 epoch, 49 iter, loss 0.19275043904781342
85 epoch, 50 iter, loss 0.27589988708496094
85 epoch, 51 iter, loss 0.34322428703308105
85 epoch, 52 iter, loss 0.28922316431999207
85 epoch, 53 iter, loss 0.2889938950538635
85 epoch, 54 iter, loss 0.378414124250412
85 epoch, 55 iter, loss 0.3168984353542328
85 epoch, 56 iter, loss 0.24715708196163177
85 epoch, 57 iter, loss 0.49736669659614563
85 epoch, Average loss 0.25369663222839955
./model/merge_model_Param_v87.pth
some of decrypted state:
tensor([[[[ 0.0695, -0.0494,  0.0548],
          [ 0.1345,  0.1496,  0.0902],
          [-0.0955, -0.0864, -0.0099]],

         [[-0.0226,  0.1266,  0.1401],
          [-0.0008,  0.0871, -0.1185],
          [-0.1399, -0.0569,  0.0672]],

         [[ 0.1045, -0.0983,  0.0109],
          [ 0.0002, -0.0753,  0.0782],
          [ 0.0963,  0.1095, -0.1171]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2085, -0.1483,  0.1645],
          [ 0.4035,  0.4488,  0.2707],
          [-0.2866, -0.2591, -0.0298]],

         [[-0.0678,  0.3797,  0.4204],
          [-0.0024,  0.2613, -0.3556],
          [-0.4197, -0.1707,  0.2016]],

         [[ 0.3134, -0.2950,  0.0328],
          [ 0.0005, -0.2258,  0.2345],
          [ 0.2888,  0.3284, -0.3512]]]], device='cuda:0')
start training
86 epoch, 1 iter, loss 0.2583918571472168
86 epoch, 2 iter, loss 0.23495936393737793
86 epoch, 3 iter, loss 0.22842161357402802
86 epoch, 4 iter, loss 0.20807892084121704
86 epoch, 5 iter, loss 0.3120749592781067
86 epoch, 6 iter, loss 0.27173513174057007
86 epoch, 7 iter, loss 0.25410202145576477
86 epoch, 8 iter, loss 0.3274415135383606
86 epoch, 9 iter, loss 0.23784035444259644
86 epoch, 10 iter, loss 0.31724125146865845
86 epoch, 11 iter, loss 0.21942538022994995
86 epoch, 12 iter, loss 0.2604498565196991
86 epoch, 13 iter, loss 0.14735275506973267
86 epoch, 14 iter, loss 0.2524034082889557
86 epoch, 15 iter, loss 0.28423482179641724
86 epoch, 16 iter, loss 0.3124919831752777
86 epoch, 17 iter, loss 0.1927327960729599
86 epoch, 18 iter, loss 0.23487243056297302
86 epoch, 19 iter, loss 0.1676291972398758
86 epoch, 20 iter, loss 0.2607753872871399
86 epoch, 21 iter, loss 0.21258214116096497
86 epoch, 22 iter, loss 0.283720999956131
86 epoch, 23 iter, loss 0.22842809557914734
86 epoch, 24 iter, loss 0.19267141819000244
86 epoch, 25 iter, loss 0.20438843965530396
86 epoch, 26 iter, loss 0.20385737717151642
86 epoch, 27 iter, loss 0.21470746397972107
86 epoch, 28 iter, loss 0.19512082636356354
86 epoch, 29 iter, loss 0.37749776244163513
86 epoch, 30 iter, loss 0.1549953818321228
86 epoch, 31 iter, loss 0.7110137939453125
86 epoch, 32 iter, loss 0.30919867753982544
86 epoch, 33 iter, loss 0.29287421703338623
86 epoch, 34 iter, loss 0.2069970965385437
86 epoch, 35 iter, loss 0.34002742171287537
86 epoch, 36 iter, loss 0.2170901894569397
86 epoch, 37 iter, loss 0.1598530411720276
86 epoch, 38 iter, loss 0.2166031450033188
86 epoch, 39 iter, loss 0.18895986676216125
86 epoch, 40 iter, loss 0.39113032817840576
86 epoch, 41 iter, loss 0.22447733581066132
86 epoch, 42 iter, loss 0.10244015604257584
86 epoch, 43 iter, loss 0.2466219663619995
86 epoch, 44 iter, loss 0.22637680172920227
86 epoch, 45 iter, loss 0.33816206455230713
86 epoch, 46 iter, loss 0.21057817339897156
86 epoch, 47 iter, loss 0.4690416753292084
86 epoch, 48 iter, loss 0.19237177073955536
86 epoch, 49 iter, loss 0.27318495512008667
86 epoch, 50 iter, loss 0.3216748833656311
86 epoch, 51 iter, loss 0.24790483713150024
86 epoch, 52 iter, loss 0.32621118426322937
86 epoch, 53 iter, loss 0.20942345261573792
86 epoch, 54 iter, loss 0.25552210211753845
86 epoch, 55 iter, loss 0.2534087300300598
86 epoch, 56 iter, loss 0.2735823690891266
86 epoch, 57 iter, loss 0.29551219940185547
86 epoch, Average loss 0.2587871463936672
./model/merge_model_Param_v88.pth
some of decrypted state:
tensor([[[[ 6.9561e-02, -4.9367e-02,  5.4867e-02],
          [ 1.3450e-01,  1.4961e-01,  9.0281e-02],
          [-9.5508e-02, -8.6338e-02, -9.8934e-03]],

         [[-2.2527e-02,  1.2659e-01,  1.4014e-01],
          [-8.0490e-04,  8.7075e-02, -1.1853e-01],
          [-1.3992e-01, -5.6931e-02,  6.7183e-02]],

         [[ 1.0452e-01, -9.8293e-02,  1.0944e-02],
          [ 1.2970e-04, -7.5303e-02,  7.8135e-02],
          [ 9.6205e-02,  1.0940e-01, -1.1711e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0868e-01, -1.4810e-01,  1.6460e-01],
          [ 4.0351e-01,  4.4884e-01,  2.7084e-01],
          [-2.8652e-01, -2.5901e-01, -2.9680e-02]],

         [[-6.7580e-02,  3.7976e-01,  4.2042e-01],
          [-2.4147e-03,  2.6123e-01, -3.5558e-01],
          [-4.1975e-01, -1.7079e-01,  2.0155e-01]],

         [[ 3.1357e-01, -2.9488e-01,  3.2833e-02],
          [ 3.8910e-04, -2.2591e-01,  2.3440e-01],
          [ 2.8861e-01,  3.2820e-01, -3.5133e-01]]]], device='cuda:0')
start training
87 epoch, 1 iter, loss 0.27029064297676086
87 epoch, 2 iter, loss 0.20211392641067505
87 epoch, 3 iter, loss 0.16914182901382446
87 epoch, 4 iter, loss 0.25553399324417114
87 epoch, 5 iter, loss 0.4014376997947693
87 epoch, 6 iter, loss 0.22823525965213776
87 epoch, 7 iter, loss 0.25814494490623474
87 epoch, 8 iter, loss 0.2528087794780731
87 epoch, 9 iter, loss 0.16128553450107574
87 epoch, 10 iter, loss 0.41260311007499695
87 epoch, 11 iter, loss 0.22918909788131714
87 epoch, 12 iter, loss 0.18949349224567413
87 epoch, 13 iter, loss 0.16148608922958374
87 epoch, 14 iter, loss 0.2520691454410553
87 epoch, 15 iter, loss 0.19935037195682526
87 epoch, 16 iter, loss 0.26497384905815125
87 epoch, 17 iter, loss 0.23197883367538452
87 epoch, 18 iter, loss 0.23968876898288727
87 epoch, 19 iter, loss 0.3722569942474365
87 epoch, 20 iter, loss 0.1750086098909378
87 epoch, 21 iter, loss 0.1597629338502884
87 epoch, 22 iter, loss 0.31180116534233093
87 epoch, 23 iter, loss 0.18523071706295013
87 epoch, 24 iter, loss 0.1971079707145691
87 epoch, 25 iter, loss 0.32138362526893616
87 epoch, 26 iter, loss 0.17350678145885468
87 epoch, 27 iter, loss 0.24477441608905792
87 epoch, 28 iter, loss 0.290179044008255
87 epoch, 29 iter, loss 0.19678238034248352
87 epoch, 30 iter, loss 0.4143798351287842
87 epoch, 31 iter, loss 0.4063713252544403
87 epoch, 32 iter, loss 0.19106237590312958
87 epoch, 33 iter, loss 0.3185662031173706
87 epoch, 34 iter, loss 0.2191828340291977
87 epoch, 35 iter, loss 0.24405895173549652
87 epoch, 36 iter, loss 0.2061784267425537
87 epoch, 37 iter, loss 0.1957421600818634
87 epoch, 38 iter, loss 0.27765926718711853
87 epoch, 39 iter, loss 0.3564924895763397
87 epoch, 40 iter, loss 0.3363622725009918
87 epoch, 41 iter, loss 0.26156550645828247
87 epoch, 42 iter, loss 0.2628580629825592
87 epoch, 43 iter, loss 0.23268045485019684
87 epoch, 44 iter, loss 0.19879522919654846
87 epoch, 45 iter, loss 0.16630984842777252
87 epoch, 46 iter, loss 0.1821468472480774
87 epoch, 47 iter, loss 0.2777654528617859
87 epoch, 48 iter, loss 0.28024089336395264
87 epoch, 49 iter, loss 0.2580609917640686
87 epoch, 50 iter, loss 0.2197645604610443
87 epoch, 51 iter, loss 0.13825494050979614
87 epoch, 52 iter, loss 0.352601557970047
87 epoch, 53 iter, loss 0.41828805208206177
87 epoch, 54 iter, loss 0.28870588541030884
87 epoch, 55 iter, loss 0.2858825922012329
87 epoch, 56 iter, loss 0.2393958568572998
87 epoch, 57 iter, loss 0.20186936855316162
87 epoch, Average loss 0.25331337279395055
./model/merge_model_Param_v89.pth
some of decrypted state:
tensor([[[[ 6.9590e-02, -4.9335e-02,  5.4904e-02],
          [ 1.3449e-01,  1.4962e-01,  9.0312e-02],
          [-9.5480e-02, -8.6298e-02, -9.8381e-03]],

         [[-2.2505e-02,  1.2660e-01,  1.4016e-01],
          [-8.2636e-04,  8.7064e-02, -1.1852e-01],
          [-1.3990e-01, -5.6902e-02,  6.7225e-02]],

         [[ 1.0454e-01, -9.8283e-02,  1.0956e-02],
          [ 1.0204e-04, -7.5321e-02,  7.8138e-02],
          [ 9.6210e-02,  1.0942e-01, -1.1707e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0877e-01, -1.4800e-01,  1.6471e-01],
          [ 4.0347e-01,  4.4885e-01,  2.7094e-01],
          [-2.8644e-01, -2.5890e-01, -2.9514e-02]],

         [[-6.7516e-02,  3.7981e-01,  4.2049e-01],
          [-2.4791e-03,  2.6119e-01, -3.5555e-01],
          [-4.1971e-01, -1.7071e-01,  2.0168e-01]],

         [[ 3.1361e-01, -2.9485e-01,  3.2867e-02],
          [ 3.0613e-04, -2.2596e-01,  2.3442e-01],
          [ 2.8863e-01,  3.2827e-01, -3.5121e-01]]]], device='cuda:0')
start training
88 epoch, 1 iter, loss 0.3172833323478699
88 epoch, 2 iter, loss 0.33382824063301086
88 epoch, 3 iter, loss 0.3230504095554352
88 epoch, 4 iter, loss 0.23810675740242004
88 epoch, 5 iter, loss 0.20527273416519165
88 epoch, 6 iter, loss 0.23324990272521973
88 epoch, 7 iter, loss 0.2660056948661804
88 epoch, 8 iter, loss 0.21685124933719635
88 epoch, 9 iter, loss 0.22646088898181915
88 epoch, 10 iter, loss 0.48128652572631836
88 epoch, 11 iter, loss 0.28851214051246643
88 epoch, 12 iter, loss 0.20868754386901855
88 epoch, 13 iter, loss 0.20995427668094635
88 epoch, 14 iter, loss 0.22158052027225494
88 epoch, 15 iter, loss 0.287682443857193
88 epoch, 16 iter, loss 0.33643755316734314
88 epoch, 17 iter, loss 0.2970034182071686
88 epoch, 18 iter, loss 0.300484836101532
88 epoch, 19 iter, loss 0.24304400384426117
88 epoch, 20 iter, loss 0.32529547810554504
88 epoch, 21 iter, loss 0.22494587302207947
88 epoch, 22 iter, loss 0.4731288552284241
88 epoch, 23 iter, loss 0.2956576943397522
88 epoch, 24 iter, loss 0.21784637868404388
88 epoch, 25 iter, loss 0.11796065419912338
88 epoch, 26 iter, loss 0.2340877503156662
88 epoch, 27 iter, loss 0.2769010066986084
88 epoch, 28 iter, loss 0.23651888966560364
88 epoch, 29 iter, loss 0.1987558752298355
88 epoch, 30 iter, loss 0.3259395956993103
88 epoch, 31 iter, loss 0.5525650978088379
88 epoch, 32 iter, loss 0.2658555209636688
88 epoch, 33 iter, loss 0.3038046658039093
88 epoch, 34 iter, loss 0.4083634912967682
88 epoch, 35 iter, loss 0.20914892852306366
88 epoch, 36 iter, loss 0.1440432369709015
88 epoch, 37 iter, loss 0.17068737745285034
88 epoch, 38 iter, loss 0.28629857301712036
88 epoch, 39 iter, loss 0.24917195737361908
88 epoch, 40 iter, loss 0.16904990375041962
88 epoch, 41 iter, loss 0.2554626166820526
88 epoch, 42 iter, loss 0.21422608196735382
88 epoch, 43 iter, loss 0.18008725345134735
88 epoch, 44 iter, loss 0.27837225794792175
88 epoch, 45 iter, loss 0.19711312651634216
88 epoch, 46 iter, loss 0.3148552477359772
88 epoch, 47 iter, loss 0.2563592493534088
88 epoch, 48 iter, loss 0.26418888568878174
88 epoch, 49 iter, loss 0.17711128294467926
88 epoch, 50 iter, loss 0.19506841897964478
88 epoch, 51 iter, loss 0.258890300989151
88 epoch, 52 iter, loss 0.34496480226516724
88 epoch, 53 iter, loss 0.28488096594810486
88 epoch, 54 iter, loss 0.3248787224292755
88 epoch, 55 iter, loss 0.27825960516929626
88 epoch, 56 iter, loss 0.18793414533138275
88 epoch, 57 iter, loss 0.3827623724937439
88 epoch, Average loss 0.26870569495255486
./model/merge_model_Param_v90.pth
some of decrypted state:
tensor([[[[ 6.9618e-02, -4.9307e-02,  5.4927e-02],
          [ 1.3449e-01,  1.4963e-01,  9.0324e-02],
          [-9.5448e-02, -8.6266e-02, -9.8114e-03]],

         [[-2.2475e-02,  1.2663e-01,  1.4018e-01],
          [-8.1301e-04,  8.7074e-02, -1.1851e-01],
          [-1.3986e-01, -5.6870e-02,  6.7245e-02]],

         [[ 1.0456e-01, -9.8256e-02,  1.0972e-02],
          [ 1.0681e-04, -7.5324e-02,  7.8125e-02],
          [ 9.6233e-02,  1.0944e-01, -1.1706e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0885e-01, -1.4792e-01,  1.6478e-01],
          [ 4.0347e-01,  4.4888e-01,  2.7097e-01],
          [-2.8634e-01, -2.5880e-01, -2.9434e-02]],

         [[-6.7424e-02,  3.7988e-01,  4.2053e-01],
          [-2.4390e-03,  2.6122e-01, -3.5554e-01],
          [-4.1959e-01, -1.7061e-01,  2.0173e-01]],

         [[ 3.1368e-01, -2.9477e-01,  3.2916e-02],
          [ 3.2043e-04, -2.2597e-01,  2.3438e-01],
          [ 2.8870e-01,  3.2832e-01, -3.5118e-01]]]], device='cuda:0')
start training
89 epoch, 1 iter, loss 0.23474878072738647
89 epoch, 2 iter, loss 0.19961921870708466
89 epoch, 3 iter, loss 0.3418111503124237
89 epoch, 4 iter, loss 0.2866142988204956
89 epoch, 5 iter, loss 0.30073216557502747
89 epoch, 6 iter, loss 0.3293512463569641
89 epoch, 7 iter, loss 0.3447412848472595
89 epoch, 8 iter, loss 0.16902697086334229
89 epoch, 9 iter, loss 0.1793469339609146
89 epoch, 10 iter, loss 0.2849636971950531
89 epoch, 11 iter, loss 0.30666497349739075
89 epoch, 12 iter, loss 0.3491562604904175
89 epoch, 13 iter, loss 0.2743203341960907
89 epoch, 14 iter, loss 0.3399812877178192
89 epoch, 15 iter, loss 0.2932863235473633
89 epoch, 16 iter, loss 0.16961483657360077
89 epoch, 17 iter, loss 0.1815444976091385
89 epoch, 18 iter, loss 0.207508847117424
89 epoch, 19 iter, loss 0.20556730031967163
89 epoch, 20 iter, loss 0.15195631980895996
89 epoch, 21 iter, loss 0.14318910241127014
89 epoch, 22 iter, loss 0.2840583324432373
89 epoch, 23 iter, loss 0.3171965479850769
89 epoch, 24 iter, loss 0.2573443651199341
89 epoch, 25 iter, loss 0.23836779594421387
89 epoch, 26 iter, loss 0.32639849185943604
89 epoch, 27 iter, loss 0.1778094619512558
89 epoch, 28 iter, loss 0.1449606567621231
89 epoch, 29 iter, loss 0.2063177078962326
89 epoch, 30 iter, loss 0.2690146863460541
89 epoch, 31 iter, loss 0.2678394317626953
89 epoch, 32 iter, loss 0.2716759443283081
89 epoch, 33 iter, loss 0.2738760709762573
89 epoch, 34 iter, loss 0.21949732303619385
89 epoch, 35 iter, loss 0.33880868554115295
89 epoch, 36 iter, loss 0.25762245059013367
89 epoch, 37 iter, loss 0.14809852838516235
89 epoch, 38 iter, loss 0.24823065102100372
89 epoch, 39 iter, loss 0.18904198706150055
89 epoch, 40 iter, loss 0.3078640401363373
89 epoch, 41 iter, loss 0.31584876775741577
89 epoch, 42 iter, loss 0.24197052419185638
89 epoch, 43 iter, loss 0.2595274746417999
89 epoch, 44 iter, loss 0.22448213398456573
89 epoch, 45 iter, loss 0.28812214732170105
89 epoch, 46 iter, loss 0.34663501381874084
89 epoch, 47 iter, loss 0.3195771872997284
89 epoch, 48 iter, loss 0.414046049118042
89 epoch, 49 iter, loss 0.20178134739398956
89 epoch, 50 iter, loss 0.15455099940299988
89 epoch, 51 iter, loss 0.20810271799564362
89 epoch, 52 iter, loss 0.33114129304885864
89 epoch, 53 iter, loss 0.4236481189727783
89 epoch, 54 iter, loss 0.2579251825809479
89 epoch, 55 iter, loss 0.21916793286800385
89 epoch, 56 iter, loss 0.3124697208404541
89 epoch, 57 iter, loss 0.22525613009929657
89 epoch, Average loss 0.25933371458137244
./model/merge_model_Param_v91.pth
some of decrypted state:
tensor([[[[ 6.9629e-02, -4.9295e-02,  5.4941e-02],
          [ 1.3452e-01,  1.4966e-01,  9.0362e-02],
          [-9.5379e-02, -8.6188e-02, -9.7313e-03]],

         [[-2.2452e-02,  1.2665e-01,  1.4020e-01],
          [-7.7486e-04,  8.7124e-02, -1.1846e-01],
          [-1.3979e-01, -5.6792e-02,  6.7322e-02]],

         [[ 1.0458e-01, -9.8242e-02,  1.0988e-02],
          [ 1.3924e-04, -7.5284e-02,  7.8162e-02],
          [ 9.6299e-02,  1.0951e-01, -1.1698e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0889e-01, -1.4789e-01,  1.6482e-01],
          [ 4.0355e-01,  4.4899e-01,  2.7108e-01],
          [-2.8614e-01, -2.5856e-01, -2.9194e-02]],

         [[-6.7357e-02,  3.7995e-01,  4.2060e-01],
          [-2.3246e-03,  2.6137e-01, -3.5539e-01],
          [-4.1938e-01, -1.7038e-01,  2.0197e-01]],

         [[ 3.1373e-01, -2.9473e-01,  3.2965e-02],
          [ 4.1771e-04, -2.2585e-01,  2.3449e-01],
          [ 2.8890e-01,  3.2854e-01, -3.5095e-01]]]], device='cuda:0')
start training
90 epoch, 1 iter, loss 0.35134080052375793
90 epoch, 2 iter, loss 0.23978151381015778
90 epoch, 3 iter, loss 0.6157873868942261
90 epoch, 4 iter, loss 0.24357153475284576
90 epoch, 5 iter, loss 0.25608888268470764
90 epoch, 6 iter, loss 0.17616786062717438
90 epoch, 7 iter, loss 0.2990935742855072
90 epoch, 8 iter, loss 0.23746293783187866
90 epoch, 9 iter, loss 0.2612403631210327
90 epoch, 10 iter, loss 0.23838414251804352
90 epoch, 11 iter, loss 0.4702213406562805
90 epoch, 12 iter, loss 0.19071008265018463
90 epoch, 13 iter, loss 0.2732037305831909
90 epoch, 14 iter, loss 0.19734421372413635
90 epoch, 15 iter, loss 0.23621733486652374
90 epoch, 16 iter, loss 0.24430176615715027
90 epoch, 17 iter, loss 0.23413468897342682
90 epoch, 18 iter, loss 0.22907748818397522
90 epoch, 19 iter, loss 0.35086432099342346
90 epoch, 20 iter, loss 0.2316747009754181
90 epoch, 21 iter, loss 0.24744467437267303
90 epoch, 22 iter, loss 0.21035373210906982
90 epoch, 23 iter, loss 0.2157827466726303
90 epoch, 24 iter, loss 0.13163219392299652
90 epoch, 25 iter, loss 0.19246625900268555
90 epoch, 26 iter, loss 0.24882103502750397
90 epoch, 27 iter, loss 0.24911527335643768
90 epoch, 28 iter, loss 0.2573174834251404
90 epoch, 29 iter, loss 0.2460380345582962
90 epoch, 30 iter, loss 0.21680967509746552
90 epoch, 31 iter, loss 0.15265126526355743
90 epoch, 32 iter, loss 0.2905847132205963
90 epoch, 33 iter, loss 0.2702729105949402
90 epoch, 34 iter, loss 0.31902891397476196
90 epoch, 35 iter, loss 0.2509879171848297
90 epoch, 36 iter, loss 0.18107648193836212
90 epoch, 37 iter, loss 0.2300492376089096
90 epoch, 38 iter, loss 0.2291131317615509
90 epoch, 39 iter, loss 0.1898970901966095
90 epoch, 40 iter, loss 0.31302371621131897
90 epoch, 41 iter, loss 0.21733801066875458
90 epoch, 42 iter, loss 0.3292728066444397
90 epoch, 43 iter, loss 0.20229235291481018
90 epoch, 44 iter, loss 0.3071720600128174
90 epoch, 45 iter, loss 0.3004385530948639
90 epoch, 46 iter, loss 0.13947159051895142
90 epoch, 47 iter, loss 0.19695338606834412
90 epoch, 48 iter, loss 0.22041510045528412
90 epoch, 49 iter, loss 0.2664712071418762
90 epoch, 50 iter, loss 0.43081265687942505
90 epoch, 51 iter, loss 0.2188459187746048
90 epoch, 52 iter, loss 0.24183402955532074
90 epoch, 53 iter, loss 0.19193674623966217
90 epoch, 54 iter, loss 0.366905152797699
90 epoch, 55 iter, loss 0.14089955389499664
90 epoch, 56 iter, loss 0.5107800960540771
90 epoch, 57 iter, loss 0.3115018606185913
90 epoch, Average loss 0.25986800408154204
./model/merge_model_Param_v92.pth
some of decrypted state:
tensor([[[[ 6.9643e-02, -4.9286e-02,  5.4947e-02],
          [ 1.3451e-01,  1.4968e-01,  9.0381e-02],
          [-9.5371e-02, -8.6173e-02, -9.7146e-03]],

         [[-2.2444e-02,  1.2665e-01,  1.4019e-01],
          [-7.8297e-04,  8.7125e-02, -1.1846e-01],
          [-1.3980e-01, -5.6793e-02,  6.7318e-02]],

         [[ 1.0458e-01, -9.8251e-02,  1.0972e-02],
          [ 1.1253e-04, -7.5305e-02,  7.8150e-02],
          [ 9.6285e-02,  1.0950e-01, -1.1700e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0893e-01, -1.4786e-01,  1.6484e-01],
          [ 4.0354e-01,  4.4903e-01,  2.7114e-01],
          [-2.8611e-01, -2.5852e-01, -2.9144e-02]],

         [[-6.7331e-02,  3.7996e-01,  4.2058e-01],
          [-2.3489e-03,  2.6137e-01, -3.5537e-01],
          [-4.1939e-01, -1.7038e-01,  2.0195e-01]],

         [[ 3.1373e-01, -2.9475e-01,  3.2916e-02],
          [ 3.3760e-04, -2.2591e-01,  2.3445e-01],
          [ 2.8885e-01,  3.2851e-01, -3.5099e-01]]]], device='cuda:0')
start training
91 epoch, 1 iter, loss 0.21256563067436218
91 epoch, 2 iter, loss 0.20206685364246368
91 epoch, 3 iter, loss 0.31516462564468384
91 epoch, 4 iter, loss 0.2248648852109909
91 epoch, 5 iter, loss 0.32278141379356384
91 epoch, 6 iter, loss 0.24196214973926544
91 epoch, 7 iter, loss 0.30768319964408875
91 epoch, 8 iter, loss 0.26620084047317505
91 epoch, 9 iter, loss 0.2085188925266266
91 epoch, 10 iter, loss 0.14245153963565826
91 epoch, 11 iter, loss 0.3599488139152527
91 epoch, 12 iter, loss 0.2787320613861084
91 epoch, 13 iter, loss 0.1960323601961136
91 epoch, 14 iter, loss 0.20819427073001862
91 epoch, 15 iter, loss 0.21825945377349854
91 epoch, 16 iter, loss 0.29152241349220276
91 epoch, 17 iter, loss 0.3108963370323181
91 epoch, 18 iter, loss 0.28867587447166443
91 epoch, 19 iter, loss 0.32044345140457153
91 epoch, 20 iter, loss 0.15030504763126373
91 epoch, 21 iter, loss 0.333801805973053
91 epoch, 22 iter, loss 0.2205667793750763
91 epoch, 23 iter, loss 0.2456483691930771
91 epoch, 24 iter, loss 0.24092234671115875
91 epoch, 25 iter, loss 0.2571829855442047
91 epoch, 26 iter, loss 0.24523895978927612
91 epoch, 27 iter, loss 0.2606101334095001
91 epoch, 28 iter, loss 0.19434046745300293
91 epoch, 29 iter, loss 0.2046685665845871
91 epoch, 30 iter, loss 0.2508557438850403
91 epoch, 31 iter, loss 0.20898550748825073
91 epoch, 32 iter, loss 0.36691778898239136
91 epoch, 33 iter, loss 0.23464787006378174
91 epoch, 34 iter, loss 0.22861184179782867
91 epoch, 35 iter, loss 0.15720362961292267
91 epoch, 36 iter, loss 0.24792228639125824
91 epoch, 37 iter, loss 0.2621906101703644
91 epoch, 38 iter, loss 0.3121708035469055
91 epoch, 39 iter, loss 0.1816249042749405
91 epoch, 40 iter, loss 0.18683169782161713
91 epoch, 41 iter, loss 0.24326001107692719
91 epoch, 42 iter, loss 0.21454203128814697
91 epoch, 43 iter, loss 0.17544950544834137
91 epoch, 44 iter, loss 0.21105176210403442
91 epoch, 45 iter, loss 0.26126474142074585
91 epoch, 46 iter, loss 0.15736010670661926
91 epoch, 47 iter, loss 0.17900024354457855
91 epoch, 48 iter, loss 0.28421011567115784
91 epoch, 49 iter, loss 0.2903979420661926
91 epoch, 50 iter, loss 0.15597058832645416
91 epoch, 51 iter, loss 0.27671870589256287
91 epoch, 52 iter, loss 0.1442050337791443
91 epoch, 53 iter, loss 0.34064003825187683
91 epoch, 54 iter, loss 0.2408990114927292
91 epoch, 55 iter, loss 0.2905147671699524
91 epoch, 56 iter, loss 0.23605793714523315
91 epoch, 57 iter, loss 0.15966203808784485
91 epoch, Average loss 0.2415687332027837
./model/merge_model_Param_v93.pth
some of decrypted state:
tensor([[[[ 6.9648e-02, -4.9279e-02,  5.4951e-02],
          [ 1.3452e-01,  1.4969e-01,  9.0392e-02],
          [-9.5356e-02, -8.6155e-02, -9.6974e-03]],

         [[-2.2440e-02,  1.2665e-01,  1.4019e-01],
          [-7.7152e-04,  8.7139e-02, -1.1844e-01],
          [-1.3978e-01, -5.6771e-02,  6.7335e-02]],

         [[ 1.0457e-01, -9.8255e-02,  1.0968e-02],
          [ 1.2016e-04, -7.5293e-02,  7.8158e-02],
          [ 9.6305e-02,  1.0953e-01, -1.1698e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0894e-01, -1.4784e-01,  1.6485e-01],
          [ 4.0356e-01,  4.4906e-01,  2.7118e-01],
          [-2.8607e-01, -2.5846e-01, -2.9092e-02]],

         [[-6.7321e-02,  3.7995e-01,  4.2058e-01],
          [-2.3146e-03,  2.6142e-01, -3.5533e-01],
          [-4.1933e-01, -1.7031e-01,  2.0201e-01]],

         [[ 3.1372e-01, -2.9477e-01,  3.2905e-02],
          [ 3.6049e-04, -2.2588e-01,  2.3448e-01],
          [ 2.8891e-01,  3.2858e-01, -3.5093e-01]]]], device='cuda:0')
start training
92 epoch, 1 iter, loss 0.21917536854743958
92 epoch, 2 iter, loss 0.19374462962150574
92 epoch, 3 iter, loss 0.3909352421760559
92 epoch, 4 iter, loss 0.31570085883140564
92 epoch, 5 iter, loss 0.19143342971801758
92 epoch, 6 iter, loss 0.2949473559856415
92 epoch, 7 iter, loss 0.2225690335035324
92 epoch, 8 iter, loss 0.42378225922584534
92 epoch, 9 iter, loss 0.2367706298828125
92 epoch, 10 iter, loss 0.23400194942951202
92 epoch, 11 iter, loss 0.26996293663978577
92 epoch, 12 iter, loss 0.27611055970191956
92 epoch, 13 iter, loss 0.1742287427186966
92 epoch, 14 iter, loss 0.13599331676959991
92 epoch, 15 iter, loss 0.18477116525173187
92 epoch, 16 iter, loss 0.3153436779975891
92 epoch, 17 iter, loss 0.22935886681079865
92 epoch, 18 iter, loss 0.350933700799942
92 epoch, 19 iter, loss 0.28676989674568176
92 epoch, 20 iter, loss 0.30644986033439636
92 epoch, 21 iter, loss 0.23968462646007538
92 epoch, 22 iter, loss 0.16206204891204834
92 epoch, 23 iter, loss 0.1463790237903595
92 epoch, 24 iter, loss 0.3646996319293976
92 epoch, 25 iter, loss 0.36019113659858704
92 epoch, 26 iter, loss 0.48597580194473267
92 epoch, 27 iter, loss 0.22768516838550568
92 epoch, 28 iter, loss 0.17683354020118713
92 epoch, 29 iter, loss 0.14131571352481842
92 epoch, 30 iter, loss 0.11655085533857346
92 epoch, 31 iter, loss 0.18182359635829926
92 epoch, 32 iter, loss 0.30097049474716187
92 epoch, 33 iter, loss 0.2380610555410385
92 epoch, 34 iter, loss 0.1757608950138092
92 epoch, 35 iter, loss 0.31801342964172363
92 epoch, 36 iter, loss 0.1812376230955124
92 epoch, 37 iter, loss 0.1735164374113083
92 epoch, 38 iter, loss 0.4125814735889435
92 epoch, 39 iter, loss 0.22105784714221954
92 epoch, 40 iter, loss 0.30997997522354126
92 epoch, 41 iter, loss 0.18392689526081085
92 epoch, 42 iter, loss 0.20799210667610168
92 epoch, 43 iter, loss 0.2840532064437866
92 epoch, 44 iter, loss 0.2916381359100342
92 epoch, 45 iter, loss 0.1723478138446808
92 epoch, 46 iter, loss 0.28071239590644836
92 epoch, 47 iter, loss 0.1836794912815094
92 epoch, 48 iter, loss 0.25782448053359985
92 epoch, 49 iter, loss 0.2709803581237793
92 epoch, 50 iter, loss 0.3246817886829376
92 epoch, 51 iter, loss 0.21557162702083588
92 epoch, 52 iter, loss 0.27083221077919006
92 epoch, 53 iter, loss 0.22264906764030457
92 epoch, 54 iter, loss 0.3620779812335968
92 epoch, 55 iter, loss 0.41372254490852356
92 epoch, 56 iter, loss 0.26286444067955017
92 epoch, 57 iter, loss 0.32635796070098877
92 epoch, Average loss 0.25823291861697245
./model/merge_model_Param_v94.pth
some of decrypted state:
tensor([[[[ 6.9641e-02, -4.9291e-02,  5.4935e-02],
          [ 1.3452e-01,  1.4968e-01,  9.0386e-02],
          [-9.5379e-02, -8.6175e-02, -9.7165e-03]],

         [[-2.2439e-02,  1.2665e-01,  1.4019e-01],
          [-7.6962e-04,  8.7138e-02, -1.1844e-01],
          [-1.3980e-01, -5.6789e-02,  6.7322e-02]],

         [[ 1.0458e-01, -9.8250e-02,  1.0970e-02],
          [ 1.2875e-04, -7.5285e-02,  7.8166e-02],
          [ 9.6290e-02,  1.0951e-01, -1.1698e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0892e-01, -1.4787e-01,  1.6480e-01],
          [ 4.0355e-01,  4.4904e-01,  2.7116e-01],
          [-2.8614e-01, -2.5852e-01, -2.9150e-02]],

         [[-6.7316e-02,  3.7994e-01,  4.2056e-01],
          [-2.3088e-03,  2.6141e-01, -3.5532e-01],
          [-4.1939e-01, -1.7037e-01,  2.0197e-01]],

         [[ 3.1374e-01, -2.9475e-01,  3.2910e-02],
          [ 3.8624e-04, -2.2586e-01,  2.3450e-01],
          [ 2.8887e-01,  3.2854e-01, -3.5094e-01]]]], device='cuda:0')
start training
93 epoch, 1 iter, loss 0.1875532567501068
93 epoch, 2 iter, loss 0.2638755440711975
93 epoch, 3 iter, loss 0.20003145933151245
93 epoch, 4 iter, loss 0.1994524747133255
93 epoch, 5 iter, loss 0.2338569462299347
93 epoch, 6 iter, loss 0.32950496673583984
93 epoch, 7 iter, loss 0.18732760846614838
93 epoch, 8 iter, loss 0.25257453322410583
93 epoch, 9 iter, loss 0.15252357721328735
93 epoch, 10 iter, loss 0.26619577407836914
93 epoch, 11 iter, loss 0.24161656200885773
93 epoch, 12 iter, loss 0.3354412615299225
93 epoch, 13 iter, loss 0.21000903844833374
93 epoch, 14 iter, loss 0.32949063181877136
93 epoch, 15 iter, loss 0.26398766040802
93 epoch, 16 iter, loss 0.18768101930618286
93 epoch, 17 iter, loss 0.2668297290802002
93 epoch, 18 iter, loss 0.416898250579834
93 epoch, 19 iter, loss 0.282280296087265
93 epoch, 20 iter, loss 0.21696092188358307
93 epoch, 21 iter, loss 0.4952557682991028
93 epoch, 22 iter, loss 0.23467843234539032
93 epoch, 23 iter, loss 0.2829996943473816
93 epoch, 24 iter, loss 0.2521994411945343
93 epoch, 25 iter, loss 0.2746458053588867
93 epoch, 26 iter, loss 0.2113851010799408
93 epoch, 27 iter, loss 0.2047056257724762
93 epoch, 28 iter, loss 0.2207489013671875
93 epoch, 29 iter, loss 0.21531876921653748
93 epoch, 30 iter, loss 0.17350620031356812
93 epoch, 31 iter, loss 0.36492323875427246
93 epoch, 32 iter, loss 0.23564913868904114
93 epoch, 33 iter, loss 0.20194968581199646
93 epoch, 34 iter, loss 0.45262596011161804
93 epoch, 35 iter, loss 0.40289920568466187
93 epoch, 36 iter, loss 0.26444050669670105
93 epoch, 37 iter, loss 0.297566294670105
93 epoch, 38 iter, loss 0.2764727771282196
93 epoch, 39 iter, loss 0.20791544020175934
93 epoch, 40 iter, loss 0.2387893795967102
93 epoch, 41 iter, loss 0.2819518446922302
93 epoch, 42 iter, loss 0.22117988765239716
93 epoch, 43 iter, loss 0.19732138514518738
93 epoch, 44 iter, loss 0.31970468163490295
93 epoch, 45 iter, loss 0.3116953670978546
93 epoch, 46 iter, loss 0.16464434564113617
93 epoch, 47 iter, loss 0.2350424826145172
93 epoch, 48 iter, loss 0.15522313117980957
93 epoch, 49 iter, loss 0.30262601375579834
93 epoch, 50 iter, loss 0.16657349467277527
93 epoch, 51 iter, loss 0.4061606824398041
93 epoch, 52 iter, loss 0.2605181932449341
93 epoch, 53 iter, loss 0.26781055331230164
93 epoch, 54 iter, loss 0.30488714575767517
93 epoch, 55 iter, loss 0.24901649355888367
93 epoch, 56 iter, loss 0.267086923122406
93 epoch, 57 iter, loss 0.14206044375896454
93 epoch, Average loss 0.2594082446997626
./model/merge_model_Param_v95.pth
some of decrypted state:
tensor([[[[ 6.9641e-02, -4.9292e-02,  5.4934e-02],
          [ 1.3452e-01,  1.4968e-01,  9.0384e-02],
          [-9.5376e-02, -8.6174e-02, -9.7198e-03]],

         [[-2.2439e-02,  1.2665e-01,  1.4019e-01],
          [-7.6580e-04,  8.7140e-02, -1.1844e-01],
          [-1.3979e-01, -5.6787e-02,  6.7320e-02]],

         [[ 1.0458e-01, -9.8252e-02,  1.0969e-02],
          [ 1.2970e-04, -7.5286e-02,  7.8163e-02],
          [ 9.6293e-02,  1.0952e-01, -1.1698e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0892e-01, -1.4788e-01,  1.6480e-01],
          [ 4.0356e-01,  4.4904e-01,  2.7115e-01],
          [-2.8613e-01, -2.5852e-01, -2.9160e-02]],

         [[-6.7316e-02,  3.7994e-01,  4.2056e-01],
          [-2.2974e-03,  2.6142e-01, -3.5532e-01],
          [-4.1938e-01, -1.7036e-01,  2.0196e-01]],

         [[ 3.1374e-01, -2.9476e-01,  3.2907e-02],
          [ 3.8910e-04, -2.2586e-01,  2.3449e-01],
          [ 2.8888e-01,  3.2855e-01, -3.5095e-01]]]], device='cuda:0')
start training
94 epoch, 1 iter, loss 0.21067461371421814
94 epoch, 2 iter, loss 0.3621923625469208
94 epoch, 3 iter, loss 0.2768777310848236
94 epoch, 4 iter, loss 0.24396643042564392
94 epoch, 5 iter, loss 0.2110569030046463
94 epoch, 6 iter, loss 0.2894562780857086
94 epoch, 7 iter, loss 0.2629735469818115
94 epoch, 8 iter, loss 0.22271466255187988
94 epoch, 9 iter, loss 0.3484031856060028
94 epoch, 10 iter, loss 0.22044281661510468
94 epoch, 11 iter, loss 0.22224830090999603
94 epoch, 12 iter, loss 0.20251117646694183
94 epoch, 13 iter, loss 0.16525475680828094
94 epoch, 14 iter, loss 0.37876254320144653
94 epoch, 15 iter, loss 0.2292270064353943
94 epoch, 16 iter, loss 0.28660720586776733
94 epoch, 17 iter, loss 0.14162516593933105
94 epoch, 18 iter, loss 0.18455973267555237
94 epoch, 19 iter, loss 0.21307630836963654
94 epoch, 20 iter, loss 0.24513007700443268
94 epoch, 21 iter, loss 0.2908894717693329
94 epoch, 22 iter, loss 0.24932605028152466
94 epoch, 23 iter, loss 0.27273011207580566
94 epoch, 24 iter, loss 0.18537920713424683
94 epoch, 25 iter, loss 0.18817371129989624
94 epoch, 26 iter, loss 0.23840248584747314
94 epoch, 27 iter, loss 0.40959420800209045
94 epoch, 28 iter, loss 0.24008753895759583
94 epoch, 29 iter, loss 0.4024590253829956
94 epoch, 30 iter, loss 0.27899226546287537
94 epoch, 31 iter, loss 0.29303857684135437
94 epoch, 32 iter, loss 0.2623996436595917
94 epoch, 33 iter, loss 0.27786189317703247
94 epoch, 34 iter, loss 0.19983930885791779
94 epoch, 35 iter, loss 0.2493170201778412
94 epoch, 36 iter, loss 0.24057602882385254
94 epoch, 37 iter, loss 0.3582637310028076
94 epoch, 38 iter, loss 0.15268898010253906
94 epoch, 39 iter, loss 0.2046792358160019
94 epoch, 40 iter, loss 0.4076956510543823
94 epoch, 41 iter, loss 0.35415923595428467
94 epoch, 42 iter, loss 0.20260082185268402
94 epoch, 43 iter, loss 0.18633824586868286
94 epoch, 44 iter, loss 0.24414010345935822
94 epoch, 45 iter, loss 0.1774258017539978
94 epoch, 46 iter, loss 0.3774169683456421
94 epoch, 47 iter, loss 0.23559772968292236
94 epoch, 48 iter, loss 0.23161187767982483
94 epoch, 49 iter, loss 0.30459198355674744
94 epoch, 50 iter, loss 0.21658259630203247
94 epoch, 51 iter, loss 0.1782885193824768
94 epoch, 52 iter, loss 0.39994528889656067
94 epoch, 53 iter, loss 0.3375370502471924
94 epoch, 54 iter, loss 0.14063915610313416
94 epoch, 55 iter, loss 0.27795735001564026
94 epoch, 56 iter, loss 0.22658471763134003
94 epoch, 57 iter, loss 0.20993098616600037
94 epoch, Average loss 0.2565176032091442
./model/merge_model_Param_v96.pth
some of decrypted state:
tensor([[[[ 6.9641e-02, -4.9292e-02,  5.4933e-02],
          [ 1.3452e-01,  1.4968e-01,  9.0385e-02],
          [-9.5371e-02, -8.6169e-02, -9.7160e-03]],

         [[-2.2437e-02,  1.2665e-01,  1.4019e-01],
          [-7.6103e-04,  8.7145e-02, -1.1844e-01],
          [-1.3979e-01, -5.6783e-02,  6.7325e-02]],

         [[ 1.0458e-01, -9.8252e-02,  1.0969e-02],
          [ 1.3351e-04, -7.5282e-02,  7.8166e-02],
          [ 9.6298e-02,  1.0952e-01, -1.1698e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0892e-01, -1.4788e-01,  1.6480e-01],
          [ 4.0357e-01,  4.4905e-01,  2.7116e-01],
          [-2.8611e-01, -2.5851e-01, -2.9148e-02]],

         [[-6.7311e-02,  3.7994e-01,  4.2056e-01],
          [-2.2831e-03,  2.6143e-01, -3.5531e-01],
          [-4.1936e-01, -1.7035e-01,  2.0197e-01]],

         [[ 3.1374e-01, -2.9476e-01,  3.2907e-02],
          [ 4.0054e-04, -2.2584e-01,  2.3450e-01],
          [ 2.8889e-01,  3.2857e-01, -3.5094e-01]]]], device='cuda:0')
start training
95 epoch, 1 iter, loss 0.24342307448387146
95 epoch, 2 iter, loss 0.3125080168247223
95 epoch, 3 iter, loss 0.272548645734787
95 epoch, 4 iter, loss 0.19068416953086853
95 epoch, 5 iter, loss 0.18824833631515503
95 epoch, 6 iter, loss 0.29203203320503235
95 epoch, 7 iter, loss 0.26160573959350586
95 epoch, 8 iter, loss 0.2351612001657486
95 epoch, 9 iter, loss 0.1830824315547943
95 epoch, 10 iter, loss 0.2073245346546173
95 epoch, 11 iter, loss 0.23656855523586273
95 epoch, 12 iter, loss 0.26325374841690063
95 epoch, 13 iter, loss 0.20887623727321625
95 epoch, 14 iter, loss 0.2963787615299225
95 epoch, 15 iter, loss 0.14454159140586853
95 epoch, 16 iter, loss 0.3174520432949066
95 epoch, 17 iter, loss 0.18358072638511658
95 epoch, 18 iter, loss 0.17070166766643524
95 epoch, 19 iter, loss 0.2696470320224762
95 epoch, 20 iter, loss 0.2752770185470581
95 epoch, 21 iter, loss 0.21422159671783447
95 epoch, 22 iter, loss 0.2441999316215515
95 epoch, 23 iter, loss 0.17770977318286896
95 epoch, 24 iter, loss 0.2253904789686203
95 epoch, 25 iter, loss 0.3089289367198944
95 epoch, 26 iter, loss 0.22066907584667206
95 epoch, 27 iter, loss 0.2539815604686737
95 epoch, 28 iter, loss 0.17275960743427277
95 epoch, 29 iter, loss 0.21402236819267273
95 epoch, 30 iter, loss 0.15063166618347168
95 epoch, 31 iter, loss 0.3188447952270508
95 epoch, 32 iter, loss 0.2648404538631439
95 epoch, 33 iter, loss 0.2777770459651947
95 epoch, 34 iter, loss 0.20059482753276825
95 epoch, 35 iter, loss 0.2305154949426651
95 epoch, 36 iter, loss 0.17329750955104828
95 epoch, 37 iter, loss 0.2734028995037079
95 epoch, 38 iter, loss 0.27971529960632324
95 epoch, 39 iter, loss 0.1817188560962677
95 epoch, 40 iter, loss 0.13183730840682983
95 epoch, 41 iter, loss 0.14309173822402954
95 epoch, 42 iter, loss 0.3625186085700989
95 epoch, 43 iter, loss 0.20301978290081024
95 epoch, 44 iter, loss 0.22051429748535156
95 epoch, 45 iter, loss 0.1763269305229187
95 epoch, 46 iter, loss 0.3102804124355316
95 epoch, 47 iter, loss 0.35212597250938416
95 epoch, 48 iter, loss 0.2274605929851532
95 epoch, 49 iter, loss 0.2801184356212616
95 epoch, 50 iter, loss 0.27420249581336975
95 epoch, 51 iter, loss 0.25538650155067444
95 epoch, 52 iter, loss 0.36558210849761963
95 epoch, 53 iter, loss 0.296760618686676
95 epoch, 54 iter, loss 0.22773709893226624
95 epoch, 55 iter, loss 0.2521311342716217
95 epoch, 56 iter, loss 0.3840390741825104
95 epoch, 57 iter, loss 0.22209009528160095
95 epoch, Average loss 0.24247966576040836
./model/merge_model_Param_v97.pth
some of decrypted state:
tensor([[[[ 6.9641e-02, -4.9292e-02,  5.4934e-02],
          [ 1.3452e-01,  1.4968e-01,  9.0385e-02],
          [-9.5371e-02, -8.6169e-02, -9.7160e-03]],

         [[-2.2437e-02,  1.2665e-01,  1.4019e-01],
          [-7.6008e-04,  8.7146e-02, -1.1844e-01],
          [-1.3979e-01, -5.6782e-02,  6.7325e-02]],

         [[ 1.0458e-01, -9.8251e-02,  1.0970e-02],
          [ 1.3447e-04, -7.5281e-02,  7.8167e-02],
          [ 9.6300e-02,  1.0952e-01, -1.1698e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0892e-01, -1.4788e-01,  1.6480e-01],
          [ 4.0357e-01,  4.4905e-01,  2.7116e-01],
          [-2.8611e-01, -2.5851e-01, -2.9148e-02]],

         [[-6.7311e-02,  3.7994e-01,  4.2056e-01],
          [-2.2802e-03,  2.6144e-01, -3.5531e-01],
          [-4.1936e-01, -1.7035e-01,  2.0197e-01]],

         [[ 3.1374e-01, -2.9475e-01,  3.2910e-02],
          [ 4.0340e-04, -2.2584e-01,  2.3450e-01],
          [ 2.8890e-01,  3.2857e-01, -3.5094e-01]]]], device='cuda:0')
start training
96 epoch, 1 iter, loss 0.2698507308959961
96 epoch, 2 iter, loss 0.29784297943115234
96 epoch, 3 iter, loss 0.24017971754074097
96 epoch, 4 iter, loss 0.27598336338996887
96 epoch, 5 iter, loss 0.16488853096961975
96 epoch, 6 iter, loss 0.24847090244293213
96 epoch, 7 iter, loss 0.2361956089735031
96 epoch, 8 iter, loss 0.4088866710662842
96 epoch, 9 iter, loss 0.1647544801235199
96 epoch, 10 iter, loss 0.3012326657772064
96 epoch, 11 iter, loss 0.292266309261322
96 epoch, 12 iter, loss 0.3517296016216278
96 epoch, 13 iter, loss 0.21643517911434174
96 epoch, 14 iter, loss 0.19584280252456665
96 epoch, 15 iter, loss 0.2549808621406555
96 epoch, 16 iter, loss 0.26210668683052063
96 epoch, 17 iter, loss 0.20540496706962585
96 epoch, 18 iter, loss 0.15692058205604553
96 epoch, 19 iter, loss 0.3516216576099396
96 epoch, 20 iter, loss 0.2162824124097824
96 epoch, 21 iter, loss 0.26333102583885193
96 epoch, 22 iter, loss 0.22808539867401123
96 epoch, 23 iter, loss 0.1507752686738968
96 epoch, 24 iter, loss 0.19617971777915955
96 epoch, 25 iter, loss 0.42436718940734863
96 epoch, 26 iter, loss 0.23624840378761292
96 epoch, 27 iter, loss 0.24965022504329681
96 epoch, 28 iter, loss 0.2590278685092926
96 epoch, 29 iter, loss 0.262388676404953
96 epoch, 30 iter, loss 0.2978467345237732
96 epoch, 31 iter, loss 0.18334954977035522
96 epoch, 32 iter, loss 0.27088430523872375
96 epoch, 33 iter, loss 0.2602822780609131
96 epoch, 34 iter, loss 0.31007227301597595
96 epoch, 35 iter, loss 0.2590659260749817
96 epoch, 36 iter, loss 0.23210741579532623
96 epoch, 37 iter, loss 0.3241825997829437
96 epoch, 38 iter, loss 0.23207367956638336
96 epoch, 39 iter, loss 0.15985798835754395
96 epoch, 40 iter, loss 0.2995337247848511
96 epoch, 41 iter, loss 0.2709689438343048
96 epoch, 42 iter, loss 0.26694270968437195
96 epoch, 43 iter, loss 0.3117409646511078
96 epoch, 44 iter, loss 0.28336742520332336
96 epoch, 45 iter, loss 0.22022198140621185
96 epoch, 46 iter, loss 0.3559006452560425
96 epoch, 47 iter, loss 0.21754597127437592
96 epoch, 48 iter, loss 0.24612952768802643
96 epoch, 49 iter, loss 0.24230320751667023
96 epoch, 50 iter, loss 0.39884650707244873
96 epoch, 51 iter, loss 0.2317439615726471
96 epoch, 52 iter, loss 0.2434842884540558
96 epoch, 53 iter, loss 0.35852867364883423
96 epoch, 54 iter, loss 0.34217900037765503
96 epoch, 55 iter, loss 0.17904692888259888
96 epoch, 56 iter, loss 0.12670643627643585
96 epoch, 57 iter, loss 0.1672825962305069
96 epoch, Average loss 0.2574408198134941
./model/merge_model_Param_v98.pth
some of decrypted state:
tensor([[[[ 6.9641e-02, -4.9292e-02,  5.4934e-02],
          [ 1.3452e-01,  1.4968e-01,  9.0385e-02],
          [-9.5371e-02, -8.6169e-02, -9.7160e-03]],

         [[-2.2437e-02,  1.2665e-01,  1.4019e-01],
          [-7.6008e-04,  8.7146e-02, -1.1844e-01],
          [-1.3979e-01, -5.6782e-02,  6.7325e-02]],

         [[ 1.0458e-01, -9.8251e-02,  1.0970e-02],
          [ 1.3542e-04, -7.5281e-02,  7.8167e-02],
          [ 9.6300e-02,  1.0952e-01, -1.1698e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0892e-01, -1.4788e-01,  1.6480e-01],
          [ 4.0357e-01,  4.4905e-01,  2.7116e-01],
          [-2.8611e-01, -2.5851e-01, -2.9148e-02]],

         [[-6.7310e-02,  3.7994e-01,  4.2056e-01],
          [-2.2802e-03,  2.6144e-01, -3.5531e-01],
          [-4.1936e-01, -1.7035e-01,  2.0197e-01]],

         [[ 3.1374e-01, -2.9475e-01,  3.2910e-02],
          [ 4.0627e-04, -2.2584e-01,  2.3450e-01],
          [ 2.8890e-01,  3.2857e-01, -3.5094e-01]]]], device='cuda:0')
start training
97 epoch, 1 iter, loss 0.1614389270544052
97 epoch, 2 iter, loss 0.22614890336990356
97 epoch, 3 iter, loss 0.16502219438552856
97 epoch, 4 iter, loss 0.3547419309616089
97 epoch, 5 iter, loss 0.2036285251379013
97 epoch, 6 iter, loss 0.2867390215396881
97 epoch, 7 iter, loss 0.1831589937210083
97 epoch, 8 iter, loss 0.24745601415634155
97 epoch, 9 iter, loss 0.22289803624153137
97 epoch, 10 iter, loss 0.278179407119751
97 epoch, 11 iter, loss 0.20596526563167572
97 epoch, 12 iter, loss 0.24874259531497955
97 epoch, 13 iter, loss 0.1426657885313034
97 epoch, 14 iter, loss 0.27250251173973083
97 epoch, 15 iter, loss 0.21565981209278107
97 epoch, 16 iter, loss 0.23898807168006897
97 epoch, 17 iter, loss 0.2529841959476471
97 epoch, 18 iter, loss 0.2731359601020813
97 epoch, 19 iter, loss 0.18008793890476227
97 epoch, 20 iter, loss 0.3105260133743286
97 epoch, 21 iter, loss 0.3081720769405365
97 epoch, 22 iter, loss 0.2707599699497223
97 epoch, 23 iter, loss 0.26775726675987244
97 epoch, 24 iter, loss 0.17059147357940674
97 epoch, 25 iter, loss 0.24319559335708618
97 epoch, 26 iter, loss 0.22850120067596436
97 epoch, 27 iter, loss 0.192827507853508
97 epoch, 28 iter, loss 0.5145711302757263
97 epoch, 29 iter, loss 0.12381135672330856
97 epoch, 30 iter, loss 0.26552730798721313
97 epoch, 31 iter, loss 0.1936611384153366
97 epoch, 32 iter, loss 0.17278705537319183
97 epoch, 33 iter, loss 0.21320369839668274
97 epoch, 34 iter, loss 0.28464484214782715
97 epoch, 35 iter, loss 0.2809145748615265
97 epoch, 36 iter, loss 0.3648567497730255
97 epoch, 37 iter, loss 0.2816528081893921
97 epoch, 38 iter, loss 0.32367053627967834
97 epoch, 39 iter, loss 0.15190578997135162
97 epoch, 40 iter, loss 0.316243976354599
97 epoch, 41 iter, loss 0.17309105396270752
97 epoch, 42 iter, loss 0.28489238023757935
97 epoch, 43 iter, loss 0.29743891954421997
97 epoch, 44 iter, loss 0.28380081057548523
97 epoch, 45 iter, loss 0.30770736932754517
97 epoch, 46 iter, loss 0.20062249898910522
97 epoch, 47 iter, loss 0.32901662588119507
97 epoch, 48 iter, loss 0.2312493622303009
97 epoch, 49 iter, loss 0.46250131726264954
97 epoch, 50 iter, loss 0.27944958209991455
97 epoch, 51 iter, loss 0.18560855090618134
97 epoch, 52 iter, loss 0.33799251914024353
97 epoch, 53 iter, loss 0.32710790634155273
97 epoch, 54 iter, loss 0.2893223464488983
97 epoch, 55 iter, loss 0.1611551195383072
97 epoch, 56 iter, loss 0.20281872153282166
97 epoch, 57 iter, loss 0.23426367342472076
97 epoch, Average loss 0.2531221915493932
./model/merge_model_Param_v99.pth
some of decrypted state:
tensor([[[[ 6.9642e-02, -4.9292e-02,  5.4935e-02],
          [ 1.3452e-01,  1.4968e-01,  9.0387e-02],
          [-9.5370e-02, -8.6167e-02, -9.7146e-03]],

         [[-2.2436e-02,  1.2665e-01,  1.4019e-01],
          [-7.5960e-04,  8.7147e-02, -1.1844e-01],
          [-1.3979e-01, -5.6781e-02,  6.7326e-02]],

         [[ 1.0458e-01, -9.8250e-02,  1.0970e-02],
          [ 1.3638e-04, -7.5281e-02,  7.8167e-02],
          [ 9.6301e-02,  1.0952e-01, -1.1698e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0893e-01, -1.4787e-01,  1.6480e-01],
          [ 4.0357e-01,  4.4905e-01,  2.7116e-01],
          [-2.8611e-01, -2.5850e-01, -2.9144e-02]],

         [[-6.7308e-02,  3.7994e-01,  4.2056e-01],
          [-2.2788e-03,  2.6144e-01, -3.5531e-01],
          [-4.1936e-01, -1.7034e-01,  2.0198e-01]],

         [[ 3.1374e-01, -2.9475e-01,  3.2910e-02],
          [ 4.0913e-04, -2.2584e-01,  2.3450e-01],
          [ 2.8890e-01,  3.2857e-01, -3.5094e-01]]]], device='cuda:0')
start training
98 epoch, 1 iter, loss 0.21393460035324097
98 epoch, 2 iter, loss 0.34431248903274536
98 epoch, 3 iter, loss 0.2090648114681244
98 epoch, 4 iter, loss 0.262562096118927
98 epoch, 5 iter, loss 0.1994030922651291
98 epoch, 6 iter, loss 0.2613968551158905
98 epoch, 7 iter, loss 0.14041569828987122
98 epoch, 8 iter, loss 0.26837942004203796
98 epoch, 9 iter, loss 0.3079586923122406
98 epoch, 10 iter, loss 0.1247064396739006
98 epoch, 11 iter, loss 0.29873496294021606
98 epoch, 12 iter, loss 0.21334245800971985
98 epoch, 13 iter, loss 0.4062478840351105
98 epoch, 14 iter, loss 0.18676505982875824
98 epoch, 15 iter, loss 0.2999952733516693
98 epoch, 16 iter, loss 0.19819317758083344
98 epoch, 17 iter, loss 0.2519560158252716
98 epoch, 18 iter, loss 0.27422213554382324
98 epoch, 19 iter, loss 0.38706207275390625
98 epoch, 20 iter, loss 0.15591949224472046
98 epoch, 21 iter, loss 0.2862169146537781
98 epoch, 22 iter, loss 0.15043070912361145
98 epoch, 23 iter, loss 0.26782435178756714
98 epoch, 24 iter, loss 0.2526319622993469
98 epoch, 25 iter, loss 0.2283075600862503
98 epoch, 26 iter, loss 0.22409123182296753
98 epoch, 27 iter, loss 0.207642063498497
98 epoch, 28 iter, loss 0.1436416655778885
98 epoch, 29 iter, loss 0.17895862460136414
98 epoch, 30 iter, loss 0.28553101420402527
98 epoch, 31 iter, loss 0.2614712417125702
98 epoch, 32 iter, loss 0.23357358574867249
98 epoch, 33 iter, loss 0.25937315821647644
98 epoch, 34 iter, loss 0.19482778012752533
98 epoch, 35 iter, loss 0.4249807894229889
98 epoch, 36 iter, loss 0.16241532564163208
98 epoch, 37 iter, loss 0.26187843084335327
98 epoch, 38 iter, loss 0.20359261333942413
98 epoch, 39 iter, loss 0.35260722041130066
98 epoch, 40 iter, loss 0.3668830096721649
98 epoch, 41 iter, loss 0.3437211811542511
98 epoch, 42 iter, loss 0.2103622406721115
98 epoch, 43 iter, loss 0.35039758682250977
98 epoch, 44 iter, loss 0.2216523438692093
98 epoch, 45 iter, loss 0.20125113427639008
98 epoch, 46 iter, loss 0.2645716667175293
98 epoch, 47 iter, loss 0.16581527888774872
98 epoch, 48 iter, loss 0.15397174656391144
98 epoch, 49 iter, loss 0.2251167595386505
98 epoch, 50 iter, loss 0.3096866011619568
98 epoch, 51 iter, loss 0.22119928896427155
98 epoch, 52 iter, loss 0.3465109169483185
98 epoch, 53 iter, loss 0.19127118587493896
98 epoch, 54 iter, loss 0.2488964945077896
98 epoch, 55 iter, loss 0.23386940360069275
98 epoch, 56 iter, loss 0.3568047285079956
98 epoch, 57 iter, loss 0.2390587329864502
98 epoch, Average loss 0.249747531063724
./model/merge_model_Param_v100.pth
some of decrypted state:
tensor([[[[ 6.9645e-02, -4.9290e-02,  5.4937e-02],
          [ 1.3453e-01,  1.4969e-01,  9.0389e-02],
          [-9.5364e-02, -8.6162e-02, -9.7108e-03]],

         [[-2.2435e-02,  1.2665e-01,  1.4019e-01],
          [-7.5722e-04,  8.7149e-02, -1.1843e-01],
          [-1.3978e-01, -5.6777e-02,  6.7328e-02]],

         [[ 1.0458e-01, -9.8251e-02,  1.0969e-02],
          [ 1.3733e-04, -7.5281e-02,  7.8167e-02],
          [ 9.6306e-02,  1.0953e-01, -1.1698e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0893e-01, -1.4787e-01,  1.6481e-01],
          [ 4.0358e-01,  4.4906e-01,  2.7117e-01],
          [-2.8609e-01, -2.5848e-01, -2.9132e-02]],

         [[-6.7304e-02,  3.7994e-01,  4.2056e-01],
          [-2.2717e-03,  2.6145e-01, -3.5530e-01],
          [-4.1934e-01, -1.7033e-01,  2.0199e-01]],

         [[ 3.1374e-01, -2.9475e-01,  3.2907e-02],
          [ 4.1199e-04, -2.2584e-01,  2.3450e-01],
          [ 2.8892e-01,  3.2858e-01, -3.5093e-01]]]], device='cuda:0')
start training
99 epoch, 1 iter, loss 0.38172921538352966
99 epoch, 2 iter, loss 0.2325882464647293
99 epoch, 3 iter, loss 0.22332964837551117
99 epoch, 4 iter, loss 0.1518639475107193
99 epoch, 5 iter, loss 0.25088679790496826
99 epoch, 6 iter, loss 0.1931852102279663
99 epoch, 7 iter, loss 0.28458309173583984
99 epoch, 8 iter, loss 0.14951065182685852
99 epoch, 9 iter, loss 0.2238812893629074
99 epoch, 10 iter, loss 0.28034964203834534
99 epoch, 11 iter, loss 0.37063249945640564
99 epoch, 12 iter, loss 0.2515939772129059
99 epoch, 13 iter, loss 0.2730129063129425
99 epoch, 14 iter, loss 0.2784833312034607
99 epoch, 15 iter, loss 0.28559255599975586
99 epoch, 16 iter, loss 0.3452281355857849
99 epoch, 17 iter, loss 0.13864541053771973
99 epoch, 18 iter, loss 0.22793243825435638
99 epoch, 19 iter, loss 0.34140923619270325
99 epoch, 20 iter, loss 0.2573849856853485
99 epoch, 21 iter, loss 0.2047414481639862
99 epoch, 22 iter, loss 0.18996796011924744
99 epoch, 23 iter, loss 0.4331854581832886
99 epoch, 24 iter, loss 0.18532061576843262
99 epoch, 25 iter, loss 0.19202151894569397
99 epoch, 26 iter, loss 0.2734116315841675
99 epoch, 27 iter, loss 0.2685471177101135
99 epoch, 28 iter, loss 0.17371812462806702
99 epoch, 29 iter, loss 0.14804784953594208
99 epoch, 30 iter, loss 0.14767849445343018
99 epoch, 31 iter, loss 0.22415503859519958
99 epoch, 32 iter, loss 0.2975793778896332
99 epoch, 33 iter, loss 0.26307573914527893
99 epoch, 34 iter, loss 0.3958379626274109
99 epoch, 35 iter, loss 0.24941255152225494
99 epoch, 36 iter, loss 0.26723572611808777
99 epoch, 37 iter, loss 0.15130995213985443
99 epoch, 38 iter, loss 0.25070327520370483
99 epoch, 39 iter, loss 0.18531203269958496
99 epoch, 40 iter, loss 0.2198987901210785
99 epoch, 41 iter, loss 0.20567327737808228
99 epoch, 42 iter, loss 0.24497415125370026
99 epoch, 43 iter, loss 0.4101235568523407
99 epoch, 44 iter, loss 0.16262377798557281
99 epoch, 45 iter, loss 0.22886383533477783
99 epoch, 46 iter, loss 0.23479750752449036
99 epoch, 47 iter, loss 0.25539612770080566
99 epoch, 48 iter, loss 0.29613474011421204
99 epoch, 49 iter, loss 0.2711055874824524
99 epoch, 50 iter, loss 0.23486213386058807
99 epoch, 51 iter, loss 0.17230406403541565
99 epoch, 52 iter, loss 0.1698034703731537
99 epoch, 53 iter, loss 0.201450914144516
99 epoch, 54 iter, loss 0.27099180221557617
99 epoch, 55 iter, loss 0.24841168522834778
99 epoch, 56 iter, loss 0.22367781400680542
99 epoch, 57 iter, loss 0.1828695833683014
99 epoch, Average loss 0.2434569808997606
./model/merge_model_Param_v101.pth
some of decrypted state:
tensor([[[[ 6.9647e-02, -4.9288e-02,  5.4938e-02],
          [ 1.3453e-01,  1.4969e-01,  9.0393e-02],
          [-9.5355e-02, -8.6153e-02, -9.7036e-03]],

         [[-2.2434e-02,  1.2665e-01,  1.4019e-01],
          [-7.5054e-04,  8.7153e-02, -1.1843e-01],
          [-1.3977e-01, -5.6768e-02,  6.7335e-02]],

         [[ 1.0458e-01, -9.8250e-02,  1.0970e-02],
          [ 1.4496e-04, -7.5275e-02,  7.8173e-02],
          [ 9.6316e-02,  1.0954e-01, -1.1697e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0894e-01, -1.4786e-01,  1.6481e-01],
          [ 4.0360e-01,  4.4908e-01,  2.7118e-01],
          [-2.8606e-01, -2.5846e-01, -2.9111e-02]],

         [[-6.7303e-02,  3.7994e-01,  4.2056e-01],
          [-2.2516e-03,  2.6146e-01, -3.5529e-01],
          [-4.1931e-01, -1.7031e-01,  2.0201e-01]],

         [[ 3.1375e-01, -2.9475e-01,  3.2910e-02],
          [ 4.3488e-04, -2.2583e-01,  2.3452e-01],
          [ 2.8895e-01,  3.2861e-01, -3.5090e-01]]]], device='cuda:0')
start training
100 epoch, 1 iter, loss 0.23120802640914917
100 epoch, 2 iter, loss 0.3085073232650757
100 epoch, 3 iter, loss 0.22492839395999908
100 epoch, 4 iter, loss 0.45816123485565186
100 epoch, 5 iter, loss 0.23220352828502655
100 epoch, 6 iter, loss 0.32844701409339905
100 epoch, 7 iter, loss 0.22955264151096344
100 epoch, 8 iter, loss 0.2591186761856079
100 epoch, 9 iter, loss 0.23141123354434967
100 epoch, 10 iter, loss 0.3205188810825348
100 epoch, 11 iter, loss 0.3401853144168854
100 epoch, 12 iter, loss 0.2526017427444458
100 epoch, 13 iter, loss 0.3001881241798401
100 epoch, 14 iter, loss 0.17060211300849915
100 epoch, 15 iter, loss 0.19322867691516876
100 epoch, 16 iter, loss 0.32893139123916626
100 epoch, 17 iter, loss 0.310574471950531
100 epoch, 18 iter, loss 0.29616230726242065
100 epoch, 19 iter, loss 0.29370230436325073
100 epoch, 20 iter, loss 0.25944024324417114
100 epoch, 21 iter, loss 0.2721222937107086
100 epoch, 22 iter, loss 0.29867464303970337
100 epoch, 23 iter, loss 0.28851935267448425
100 epoch, 24 iter, loss 0.27353471517562866
100 epoch, 25 iter, loss 0.1698044240474701
100 epoch, 26 iter, loss 0.30967602133750916
100 epoch, 27 iter, loss 0.18951913714408875
100 epoch, 28 iter, loss 0.3473505973815918
100 epoch, 29 iter, loss 0.31939899921417236
100 epoch, 30 iter, loss 0.24321426451206207
100 epoch, 31 iter, loss 0.29708629846572876
100 epoch, 32 iter, loss 0.2670668661594391
100 epoch, 33 iter, loss 0.2738252282142639
100 epoch, 34 iter, loss 0.266798198223114
100 epoch, 35 iter, loss 0.10484272986650467
100 epoch, 36 iter, loss 0.17832516133785248
100 epoch, 37 iter, loss 0.249504953622818
100 epoch, 38 iter, loss 0.19825536012649536
100 epoch, 39 iter, loss 0.259492963552475
100 epoch, 40 iter, loss 0.22104282677173615
100 epoch, 41 iter, loss 0.2557543218135834
100 epoch, 42 iter, loss 0.17749853432178497
100 epoch, 43 iter, loss 0.23438327014446259
100 epoch, 44 iter, loss 0.2457922250032425
100 epoch, 45 iter, loss 0.2347060590982437
100 epoch, 46 iter, loss 0.422338604927063
100 epoch, 47 iter, loss 0.3270842134952545
100 epoch, 48 iter, loss 0.16887204349040985
100 epoch, 49 iter, loss 0.222093403339386
100 epoch, 50 iter, loss 0.18034140765666962
100 epoch, 51 iter, loss 0.23143193125724792
100 epoch, 52 iter, loss 0.29174309968948364
100 epoch, 53 iter, loss 0.2237919420003891
100 epoch, 54 iter, loss 0.16401275992393494
100 epoch, 55 iter, loss 0.1930134892463684
100 epoch, 56 iter, loss 0.2718126177787781
100 epoch, 57 iter, loss 0.32109543681144714
100 epoch, Average loss 0.2590086673173988
./model/merge_model_Param_v102.pth
some of decrypted state:
tensor([[[[ 0.0696, -0.0493,  0.0549],
          [ 0.1345,  0.1497,  0.0904],
          [-0.0953, -0.0861, -0.0097]],

         [[-0.0224,  0.1267,  0.1402],
          [-0.0007,  0.0872, -0.1184],
          [-0.1398, -0.0567,  0.0674]],

         [[ 0.1046, -0.0982,  0.0110],
          [ 0.0002, -0.0753,  0.0782],
          [ 0.0963,  0.1096, -0.1169]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2089, -0.1478,  0.1648],
          [ 0.4036,  0.4491,  0.2712],
          [-0.2860, -0.2584, -0.0290]],

         [[-0.0673,  0.3800,  0.4206],
          [-0.0022,  0.2615, -0.3552],
          [-0.4193, -0.1702,  0.2021]],

         [[ 0.3137, -0.2947,  0.0329],
          [ 0.0005, -0.2258,  0.2346],
          [ 0.2890,  0.3287, -0.3508]]]], device='cuda:0')
start training
101 epoch, 1 iter, loss 0.308627188205719
101 epoch, 2 iter, loss 0.1679525226354599
101 epoch, 3 iter, loss 0.3691653311252594
101 epoch, 4 iter, loss 0.18757812678813934
101 epoch, 5 iter, loss 0.2233683317899704
101 epoch, 6 iter, loss 0.2408880591392517
101 epoch, 7 iter, loss 0.24283410608768463
101 epoch, 8 iter, loss 0.2616415023803711
101 epoch, 9 iter, loss 0.20927144587039948
101 epoch, 10 iter, loss 0.20520807802677155
101 epoch, 11 iter, loss 0.2400720864534378
101 epoch, 12 iter, loss 0.2032637596130371
101 epoch, 13 iter, loss 0.2186029702425003
101 epoch, 14 iter, loss 0.21878427267074585
101 epoch, 15 iter, loss 0.24689406156539917
101 epoch, 16 iter, loss 0.20177409052848816
101 epoch, 17 iter, loss 0.18361568450927734
101 epoch, 18 iter, loss 0.16406379640102386
101 epoch, 19 iter, loss 0.22519291937351227
101 epoch, 20 iter, loss 0.29292717576026917
101 epoch, 21 iter, loss 0.3237204849720001
101 epoch, 22 iter, loss 0.22687393426895142
101 epoch, 23 iter, loss 0.2898927927017212
101 epoch, 24 iter, loss 0.14778876304626465
101 epoch, 25 iter, loss 0.2905541658401489
101 epoch, 26 iter, loss 0.2687535583972931
101 epoch, 27 iter, loss 0.2658189535140991
101 epoch, 28 iter, loss 0.22365199029445648
101 epoch, 29 iter, loss 0.2015082836151123
101 epoch, 30 iter, loss 0.2764478623867035
101 epoch, 31 iter, loss 0.2522231340408325
101 epoch, 32 iter, loss 0.3154185712337494
101 epoch, 33 iter, loss 0.2869497239589691
101 epoch, 34 iter, loss 0.1934911608695984
101 epoch, 35 iter, loss 0.18682749569416046
101 epoch, 36 iter, loss 0.22812189161777496
101 epoch, 37 iter, loss 0.3747260570526123
101 epoch, 38 iter, loss 0.27403005957603455
101 epoch, 39 iter, loss 0.24677160382270813
101 epoch, 40 iter, loss 0.36080819368362427
101 epoch, 41 iter, loss 0.28023970127105713
101 epoch, 42 iter, loss 0.26689621806144714
101 epoch, 43 iter, loss 0.3000160753726959
101 epoch, 44 iter, loss 0.3676223158836365
101 epoch, 45 iter, loss 0.33250269293785095
101 epoch, 46 iter, loss 0.26957273483276367
101 epoch, 47 iter, loss 0.27623504400253296
101 epoch, 48 iter, loss 0.18156912922859192
101 epoch, 49 iter, loss 0.3075115978717804
101 epoch, 50 iter, loss 0.19318486750125885
101 epoch, 51 iter, loss 0.24242021143436432
101 epoch, 52 iter, loss 0.24746376276016235
101 epoch, 53 iter, loss 0.250588595867157
101 epoch, 54 iter, loss 0.10515141487121582
101 epoch, 55 iter, loss 0.26659244298934937
101 epoch, 56 iter, loss 0.1783653199672699
101 epoch, 57 iter, loss 0.17566633224487305
101 epoch, Average loss 0.2471526780149393
./model/merge_model_Param_v103.pth
some of decrypted state:
tensor([[[[ 0.0696, -0.0493,  0.0549],
          [ 0.1346,  0.1497,  0.0904],
          [-0.0953, -0.0861, -0.0097]],

         [[-0.0224,  0.1267,  0.1402],
          [-0.0007,  0.0872, -0.1184],
          [-0.1397, -0.0567,  0.0674]],

         [[ 0.1046, -0.0982,  0.0110],
          [ 0.0002, -0.0753,  0.0782],
          [ 0.0963,  0.1096, -0.1169]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2089, -0.1479,  0.1648],
          [ 0.4037,  0.4491,  0.2713],
          [-0.2860, -0.2583, -0.0290]],

         [[-0.0673,  0.3800,  0.4206],
          [-0.0022,  0.2615, -0.3552],
          [-0.4192, -0.1702,  0.2021]],

         [[ 0.3138, -0.2947,  0.0329],
          [ 0.0005, -0.2258,  0.2346],
          [ 0.2890,  0.3287, -0.3508]]]], device='cuda:0')
start training
102 epoch, 1 iter, loss 0.4191759526729584
102 epoch, 2 iter, loss 0.22295579314231873
102 epoch, 3 iter, loss 0.1975974291563034
102 epoch, 4 iter, loss 0.27727434039115906
102 epoch, 5 iter, loss 0.4213326573371887
102 epoch, 6 iter, loss 0.22268708050251007
102 epoch, 7 iter, loss 0.24969862401485443
102 epoch, 8 iter, loss 0.27450430393218994
102 epoch, 9 iter, loss 0.31345003843307495
102 epoch, 10 iter, loss 0.33472180366516113
102 epoch, 11 iter, loss 0.3834775388240814
102 epoch, 12 iter, loss 0.20890207588672638
102 epoch, 13 iter, loss 0.16012753546237946
102 epoch, 14 iter, loss 0.21831652522087097
102 epoch, 15 iter, loss 0.2518991231918335
102 epoch, 16 iter, loss 0.38873550295829773
102 epoch, 17 iter, loss 0.2196730375289917
102 epoch, 18 iter, loss 0.16075992584228516
102 epoch, 19 iter, loss 0.3624212443828583
102 epoch, 20 iter, loss 0.2735101878643036
102 epoch, 21 iter, loss 0.23972088098526
102 epoch, 22 iter, loss 0.32032307982444763
102 epoch, 23 iter, loss 0.24207817018032074
102 epoch, 24 iter, loss 0.1683347523212433
102 epoch, 25 iter, loss 0.1814526617527008
102 epoch, 26 iter, loss 0.1813422590494156
102 epoch, 27 iter, loss 0.3338223695755005
102 epoch, 28 iter, loss 0.12230119109153748
102 epoch, 29 iter, loss 0.1759694367647171
102 epoch, 30 iter, loss 0.20841678977012634
102 epoch, 31 iter, loss 0.2172045111656189
102 epoch, 32 iter, loss 0.16282187402248383
102 epoch, 33 iter, loss 0.2543136477470398
102 epoch, 34 iter, loss 0.27998679876327515
102 epoch, 35 iter, loss 0.1636856198310852
102 epoch, 36 iter, loss 0.17968225479125977
102 epoch, 37 iter, loss 0.2899637818336487
102 epoch, 38 iter, loss 0.2748604714870453
102 epoch, 39 iter, loss 0.25261977314949036
102 epoch, 40 iter, loss 0.3323882222175598
102 epoch, 41 iter, loss 0.2612681984901428
102 epoch, 42 iter, loss 0.2270185649394989
102 epoch, 43 iter, loss 0.17015787959098816
102 epoch, 44 iter, loss 0.1885901242494583
102 epoch, 45 iter, loss 0.3550647795200348
102 epoch, 46 iter, loss 0.21836277842521667
102 epoch, 47 iter, loss 0.1777506321668625
102 epoch, 48 iter, loss 0.22050125896930695
102 epoch, 49 iter, loss 0.2832520604133606
102 epoch, 50 iter, loss 0.22687703371047974
102 epoch, 51 iter, loss 0.2207600623369217
102 epoch, 52 iter, loss 0.1461818814277649
102 epoch, 53 iter, loss 0.23232322931289673
102 epoch, 54 iter, loss 0.27093347907066345
102 epoch, 55 iter, loss 0.18458621203899384
102 epoch, 56 iter, loss 0.2681243121623993
102 epoch, 57 iter, loss 0.2868930995464325
102 epoch, Average loss 0.24703780444044815
./model/merge_model_Param_v104.pth
some of decrypted state:
tensor([[[[ 0.0696, -0.0493,  0.0549],
          [ 0.1345,  0.1497,  0.0904],
          [-0.0954, -0.0862, -0.0097]],

         [[-0.0224,  0.1267,  0.1402],
          [-0.0007,  0.0872, -0.1184],
          [-0.1398, -0.0568,  0.0673]],

         [[ 0.1046, -0.0982,  0.0110],
          [ 0.0002, -0.0753,  0.0782],
          [ 0.0963,  0.1095, -0.1169]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2089, -0.1479,  0.1648],
          [ 0.4036,  0.4491,  0.2712],
          [-0.2861, -0.2585, -0.0291]],

         [[-0.0673,  0.3800,  0.4206],
          [-0.0022,  0.2615, -0.3553],
          [-0.4194, -0.1703,  0.2020]],

         [[ 0.3138, -0.2947,  0.0329],
          [ 0.0005, -0.2258,  0.2346],
          [ 0.2889,  0.3286, -0.3508]]]], device='cuda:0')
start training
103 epoch, 1 iter, loss 0.31069469451904297
103 epoch, 2 iter, loss 0.247847318649292
103 epoch, 3 iter, loss 0.30240508913993835
103 epoch, 4 iter, loss 0.2294636368751526
103 epoch, 5 iter, loss 0.37816691398620605
103 epoch, 6 iter, loss 0.18408572673797607
103 epoch, 7 iter, loss 0.1877291351556778
103 epoch, 8 iter, loss 0.21213550865650177
103 epoch, 9 iter, loss 0.16838940978050232
103 epoch, 10 iter, loss 0.2866581082344055
103 epoch, 11 iter, loss 0.46574175357818604
103 epoch, 12 iter, loss 0.23954202234745026
103 epoch, 13 iter, loss 0.27381327748298645
103 epoch, 14 iter, loss 0.2770769000053406
103 epoch, 15 iter, loss 0.2610405683517456
103 epoch, 16 iter, loss 0.1613725870847702
103 epoch, 17 iter, loss 0.18442007899284363
103 epoch, 18 iter, loss 0.3397577106952667
103 epoch, 19 iter, loss 0.34082114696502686
103 epoch, 20 iter, loss 0.3287334144115448
103 epoch, 21 iter, loss 0.2874756455421448
103 epoch, 22 iter, loss 0.41629862785339355
103 epoch, 23 iter, loss 0.16528895497322083
103 epoch, 24 iter, loss 0.19613076746463776
103 epoch, 25 iter, loss 0.15431222319602966
103 epoch, 26 iter, loss 0.16465266048908234
103 epoch, 27 iter, loss 0.2234797328710556
103 epoch, 28 iter, loss 0.27251455187797546
103 epoch, 29 iter, loss 0.2056228369474411
103 epoch, 30 iter, loss 0.16713400185108185
103 epoch, 31 iter, loss 0.13632793724536896
103 epoch, 32 iter, loss 0.21751686930656433
103 epoch, 33 iter, loss 0.23118512332439423
103 epoch, 34 iter, loss 0.22245489060878754
103 epoch, 35 iter, loss 0.2962699234485626
103 epoch, 36 iter, loss 0.22681498527526855
103 epoch, 37 iter, loss 0.2908627390861511
103 epoch, 38 iter, loss 0.1921990066766739
103 epoch, 39 iter, loss 0.2744201123714447
103 epoch, 40 iter, loss 0.28125983476638794
103 epoch, 41 iter, loss 0.2663024663925171
103 epoch, 42 iter, loss 0.3309869170188904
103 epoch, 43 iter, loss 0.25139808654785156
103 epoch, 44 iter, loss 0.13693809509277344
103 epoch, 45 iter, loss 0.3075123727321625
103 epoch, 46 iter, loss 0.2231493443250656
103 epoch, 47 iter, loss 0.18567070364952087
103 epoch, 48 iter, loss 0.32090145349502563
103 epoch, 49 iter, loss 0.2164289951324463
103 epoch, 50 iter, loss 0.26507535576820374
103 epoch, 51 iter, loss 0.2626282572746277
103 epoch, 52 iter, loss 0.22567978501319885
103 epoch, 53 iter, loss 0.23399730026721954
103 epoch, 54 iter, loss 0.36877360939979553
103 epoch, 55 iter, loss 0.16526156663894653
103 epoch, 56 iter, loss 0.28007712960243225
103 epoch, 57 iter, loss 0.39806607365608215
103 epoch, Average loss 0.25335024454091726
./model/merge_model_Param_v105.pth
some of decrypted state:
tensor([[[[ 0.0697, -0.0493,  0.0549],
          [ 0.1346,  0.1497,  0.0904],
          [-0.0953, -0.0861, -0.0096]],

         [[-0.0224,  0.1267,  0.1402],
          [-0.0007,  0.0872, -0.1184],
          [-0.1398, -0.0567,  0.0674]],

         [[ 0.1046, -0.0982,  0.0110],
          [ 0.0002, -0.0752,  0.0782],
          [ 0.0963,  0.1096, -0.1169]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2090, -0.1479,  0.1648],
          [ 0.4037,  0.4492,  0.2713],
          [-0.2860, -0.2583, -0.0289]],

         [[-0.0673,  0.3800,  0.4206],
          [-0.0021,  0.2616, -0.3551],
          [-0.4193, -0.1702,  0.2022]],

         [[ 0.3138, -0.2947,  0.0330],
          [ 0.0005, -0.2257,  0.2347],
          [ 0.2890,  0.3288, -0.3507]]]], device='cuda:0')
start training
104 epoch, 1 iter, loss 0.28604552149772644
104 epoch, 2 iter, loss 0.28551921248435974
104 epoch, 3 iter, loss 0.1781330108642578
104 epoch, 4 iter, loss 0.18444222211837769
104 epoch, 5 iter, loss 0.3335081934928894
104 epoch, 6 iter, loss 0.3000825345516205
104 epoch, 7 iter, loss 0.2634707987308502
104 epoch, 8 iter, loss 0.24278435111045837
104 epoch, 9 iter, loss 0.2718036472797394
104 epoch, 10 iter, loss 0.3759606182575226
104 epoch, 11 iter, loss 0.41271838545799255
104 epoch, 12 iter, loss 0.3171730041503906
104 epoch, 13 iter, loss 0.2819522023200989
104 epoch, 14 iter, loss 0.2852465808391571
104 epoch, 15 iter, loss 0.13153651356697083
104 epoch, 16 iter, loss 0.1766470968723297
104 epoch, 17 iter, loss 0.1788686066865921
104 epoch, 18 iter, loss 0.2544185519218445
104 epoch, 19 iter, loss 0.27635177969932556
104 epoch, 20 iter, loss 0.28451284766197205
104 epoch, 21 iter, loss 0.27094727754592896
104 epoch, 22 iter, loss 0.3293825685977936
104 epoch, 23 iter, loss 0.16411468386650085
104 epoch, 24 iter, loss 0.29079943895339966
104 epoch, 25 iter, loss 0.25391578674316406
104 epoch, 26 iter, loss 0.1938915103673935
104 epoch, 27 iter, loss 0.15588721632957458
104 epoch, 28 iter, loss 0.19187769293785095
104 epoch, 29 iter, loss 0.25687795877456665
104 epoch, 30 iter, loss 0.27413201332092285
104 epoch, 31 iter, loss 0.3828722834587097
104 epoch, 32 iter, loss 0.22157014906406403
104 epoch, 33 iter, loss 0.2862773835659027
104 epoch, 34 iter, loss 0.2436903566122055
104 epoch, 35 iter, loss 0.2837927043437958
104 epoch, 36 iter, loss 0.3056654632091522
104 epoch, 37 iter, loss 0.24923644959926605
104 epoch, 38 iter, loss 0.3409663736820221
104 epoch, 39 iter, loss 0.24473722279071808
104 epoch, 40 iter, loss 0.3341009020805359
104 epoch, 41 iter, loss 0.466752290725708
104 epoch, 42 iter, loss 0.19452717900276184
104 epoch, 43 iter, loss 0.20914268493652344
104 epoch, 44 iter, loss 0.23147116601467133
104 epoch, 45 iter, loss 0.3339313566684723
104 epoch, 46 iter, loss 0.19925884902477264
104 epoch, 47 iter, loss 0.15850849449634552
104 epoch, 48 iter, loss 0.2154887318611145
104 epoch, 49 iter, loss 0.20278067886829376
104 epoch, 50 iter, loss 0.26859140396118164
104 epoch, 51 iter, loss 0.25438013672828674
104 epoch, 52 iter, loss 0.2790827751159668
104 epoch, 53 iter, loss 0.23806586861610413
104 epoch, 54 iter, loss 0.27825310826301575
104 epoch, 55 iter, loss 0.3465240001678467
104 epoch, 56 iter, loss 0.2018623799085617
104 epoch, 57 iter, loss 0.1794700026512146
104 epoch, Average loss 0.26059653021787343
./model/merge_model_Param_v106.pth
some of decrypted state:
tensor([[[[ 6.9705e-02, -4.9244e-02,  5.4962e-02],
          [ 1.3456e-01,  1.4974e-01,  9.0469e-02],
          [-9.5287e-02, -8.6070e-02, -9.6211e-03]],

         [[-2.2387e-02,  1.2667e-01,  1.4019e-01],
          [-7.3242e-04,  8.7196e-02, -1.1837e-01],
          [-1.3973e-01, -5.6714e-02,  6.7389e-02]],

         [[ 1.0460e-01, -9.8233e-02,  1.0969e-02],
          [ 1.3733e-04, -7.5258e-02,  7.8206e-02],
          [ 9.6342e-02,  1.0959e-01, -1.1690e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0912e-01, -1.4773e-01,  1.6489e-01],
          [ 4.0367e-01,  4.4923e-01,  2.7141e-01],
          [-2.8586e-01, -2.5821e-01, -2.8863e-02]],

         [[-6.7160e-02,  3.8002e-01,  4.2057e-01],
          [-2.1973e-03,  2.6159e-01, -3.5511e-01],
          [-4.1918e-01, -1.7014e-01,  2.0217e-01]],

         [[ 3.1381e-01, -2.9470e-01,  3.2907e-02],
          [ 4.1199e-04, -2.2577e-01,  2.3462e-01],
          [ 2.8903e-01,  3.2877e-01, -3.5070e-01]]]], device='cuda:0')
start training
105 epoch, 1 iter, loss 0.2906724512577057
105 epoch, 2 iter, loss 0.2773633897304535
105 epoch, 3 iter, loss 0.17674079537391663
105 epoch, 4 iter, loss 0.22270822525024414
105 epoch, 5 iter, loss 0.1507524996995926
105 epoch, 6 iter, loss 0.21342788636684418
105 epoch, 7 iter, loss 0.3200007379055023
105 epoch, 8 iter, loss 0.5052908062934875
105 epoch, 9 iter, loss 0.3963436484336853
105 epoch, 10 iter, loss 0.27232879400253296
105 epoch, 11 iter, loss 0.21401147544384003
105 epoch, 12 iter, loss 0.3930763006210327
105 epoch, 13 iter, loss 0.2160605788230896
105 epoch, 14 iter, loss 0.17372070252895355
105 epoch, 15 iter, loss 0.15538716316223145
105 epoch, 16 iter, loss 0.30197522044181824
105 epoch, 17 iter, loss 0.16977517306804657
105 epoch, 18 iter, loss 0.1623467206954956
105 epoch, 19 iter, loss 0.2953496277332306
105 epoch, 20 iter, loss 0.21169930696487427
105 epoch, 21 iter, loss 0.2931376099586487
105 epoch, 22 iter, loss 0.19858866930007935
105 epoch, 23 iter, loss 0.30816566944122314
105 epoch, 24 iter, loss 0.15898317098617554
105 epoch, 25 iter, loss 0.29757508635520935
105 epoch, 26 iter, loss 0.2789319157600403
105 epoch, 27 iter, loss 0.22588802874088287
105 epoch, 28 iter, loss 0.2998051345348358
105 epoch, 29 iter, loss 0.23901180922985077
105 epoch, 30 iter, loss 0.17165081202983856
105 epoch, 31 iter, loss 0.22661064565181732
105 epoch, 32 iter, loss 0.19982583820819855
105 epoch, 33 iter, loss 0.22966647148132324
105 epoch, 34 iter, loss 0.30216896533966064
105 epoch, 35 iter, loss 0.258694589138031
105 epoch, 36 iter, loss 0.27190104126930237
105 epoch, 37 iter, loss 0.15995341539382935
105 epoch, 38 iter, loss 0.20275036990642548
105 epoch, 39 iter, loss 0.2937578558921814
105 epoch, 40 iter, loss 0.17798905074596405
105 epoch, 41 iter, loss 0.18741637468338013
105 epoch, 42 iter, loss 0.2618890702724457
105 epoch, 43 iter, loss 0.31556466221809387
105 epoch, 44 iter, loss 0.3144957721233368
105 epoch, 45 iter, loss 0.3284919857978821
105 epoch, 46 iter, loss 0.29794421792030334
105 epoch, 47 iter, loss 0.23131074011325836
105 epoch, 48 iter, loss 0.30482298135757446
105 epoch, 49 iter, loss 0.26847004890441895
105 epoch, 50 iter, loss 0.19434405863285065
105 epoch, 51 iter, loss 0.13638371229171753
105 epoch, 52 iter, loss 0.2103990912437439
105 epoch, 53 iter, loss 0.3029448986053467
105 epoch, 54 iter, loss 0.2752050757408142
105 epoch, 55 iter, loss 0.45430150628089905
105 epoch, 56 iter, loss 0.33586910367012024
105 epoch, 57 iter, loss 0.22729192674160004
105 epoch, Average loss 0.2554602259606646
./model/merge_model_Param_v107.pth
some of decrypted state:
tensor([[[[ 0.0697, -0.0492,  0.0550],
          [ 0.1346,  0.1498,  0.0905],
          [-0.0952, -0.0860, -0.0095]],

         [[-0.0223,  0.1267,  0.1402],
          [-0.0007,  0.0873, -0.1183],
          [-0.1396, -0.0566,  0.0675]],

         [[ 0.1046, -0.0982,  0.0110],
          [ 0.0002, -0.0752,  0.0783],
          [ 0.0965,  0.1097, -0.1168]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2092, -0.1477,  0.1649],
          [ 0.4038,  0.4494,  0.2716],
          [-0.2855, -0.2579, -0.0285]],

         [[-0.0670,  0.3801,  0.4206],
          [-0.0020,  0.2618, -0.3548],
          [-0.4188, -0.1698,  0.2025]],

         [[ 0.3139, -0.2946,  0.0329],
          [ 0.0006, -0.2255,  0.2349],
          [ 0.2894,  0.3292, -0.3503]]]], device='cuda:0')
start training
106 epoch, 1 iter, loss 0.34325531125068665
106 epoch, 2 iter, loss 0.2044835239648819
106 epoch, 3 iter, loss 0.20230361819267273
106 epoch, 4 iter, loss 0.16896678507328033
106 epoch, 5 iter, loss 0.16234959661960602
106 epoch, 6 iter, loss 0.20001040399074554
106 epoch, 7 iter, loss 0.28645169734954834
106 epoch, 8 iter, loss 0.3163570761680603
106 epoch, 9 iter, loss 0.26951831579208374
106 epoch, 10 iter, loss 0.10795241594314575
106 epoch, 11 iter, loss 0.21397115290164948
106 epoch, 12 iter, loss 0.27015140652656555
106 epoch, 13 iter, loss 0.14773774147033691
106 epoch, 14 iter, loss 0.2147471010684967
106 epoch, 15 iter, loss 0.246391162276268
106 epoch, 16 iter, loss 0.2639545202255249
106 epoch, 17 iter, loss 0.18952147662639618
106 epoch, 18 iter, loss 0.2992529571056366
106 epoch, 19 iter, loss 0.2534906566143036
106 epoch, 20 iter, loss 0.30059319734573364
106 epoch, 21 iter, loss 0.1779307723045349
106 epoch, 22 iter, loss 0.30971798300743103
106 epoch, 23 iter, loss 0.1765703558921814
106 epoch, 24 iter, loss 0.2713691294193268
106 epoch, 25 iter, loss 0.20352481305599213
106 epoch, 26 iter, loss 0.1428859382867813
106 epoch, 27 iter, loss 0.23863491415977478
106 epoch, 28 iter, loss 0.34985312819480896
106 epoch, 29 iter, loss 0.2546274960041046
106 epoch, 30 iter, loss 0.20598828792572021
106 epoch, 31 iter, loss 0.27045226097106934
106 epoch, 32 iter, loss 0.18129320442676544
106 epoch, 33 iter, loss 0.31352123618125916
106 epoch, 34 iter, loss 0.20792484283447266
106 epoch, 35 iter, loss 0.21490883827209473
106 epoch, 36 iter, loss 0.23580041527748108
106 epoch, 37 iter, loss 0.24447818100452423
106 epoch, 38 iter, loss 0.25449031591415405
106 epoch, 39 iter, loss 0.33003735542297363
106 epoch, 40 iter, loss 0.21551857888698578
106 epoch, 41 iter, loss 0.194968581199646
106 epoch, 42 iter, loss 0.220949187874794
106 epoch, 43 iter, loss 0.20616000890731812
106 epoch, 44 iter, loss 0.30661237239837646
106 epoch, 45 iter, loss 0.2670283317565918
106 epoch, 46 iter, loss 0.24713020026683807
106 epoch, 47 iter, loss 0.18801449239253998
106 epoch, 48 iter, loss 0.2972145080566406
106 epoch, 49 iter, loss 0.20233871042728424
106 epoch, 50 iter, loss 0.2527218759059906
106 epoch, 51 iter, loss 0.2849869132041931
106 epoch, 52 iter, loss 0.2669695317745209
106 epoch, 53 iter, loss 0.2300083041191101
106 epoch, 54 iter, loss 0.4143473505973816
106 epoch, 55 iter, loss 0.2754976451396942
106 epoch, 56 iter, loss 0.2751716077327728
106 epoch, 57 iter, loss 0.30043354630470276
106 epoch, Average loss 0.24371125143870973
./model/merge_model_Param_v108.pth
some of decrypted state:
tensor([[[[ 0.0697, -0.0492,  0.0550],
          [ 0.1346,  0.1498,  0.0906],
          [-0.0952, -0.0860, -0.0095]],

         [[-0.0223,  0.1267,  0.1402],
          [-0.0006,  0.0873, -0.1182],
          [-0.1396, -0.0566,  0.0676]],

         [[ 0.1047, -0.0982,  0.0110],
          [ 0.0002, -0.0751,  0.0784],
          [ 0.0965,  0.1098, -0.1167]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2091, -0.1477,  0.1649],
          [ 0.4037,  0.4494,  0.2717],
          [-0.2856, -0.2579, -0.0285]],

         [[-0.0670,  0.3802,  0.4207],
          [-0.0019,  0.2620, -0.3546],
          [-0.4187, -0.1697,  0.2027]],

         [[ 0.3140, -0.2945,  0.0331],
          [ 0.0007, -0.2253,  0.2351],
          [ 0.2895,  0.3293, -0.3501]]]], device='cuda:0')
start training
107 epoch, 1 iter, loss 0.19382162392139435
107 epoch, 2 iter, loss 0.14391523599624634
107 epoch, 3 iter, loss 0.1580779105424881
107 epoch, 4 iter, loss 0.29290100932121277
107 epoch, 5 iter, loss 0.27302786707878113
107 epoch, 6 iter, loss 0.2999723255634308
107 epoch, 7 iter, loss 0.3189154267311096
107 epoch, 8 iter, loss 0.2669592499732971
107 epoch, 9 iter, loss 0.2983936667442322
107 epoch, 10 iter, loss 0.2827017605304718
107 epoch, 11 iter, loss 0.2872494161128998
107 epoch, 12 iter, loss 0.19047319889068604
107 epoch, 13 iter, loss 0.2978549599647522
107 epoch, 14 iter, loss 0.20611783862113953
107 epoch, 15 iter, loss 0.2957117557525635
107 epoch, 16 iter, loss 0.172250434756279
107 epoch, 17 iter, loss 0.23194070160388947
107 epoch, 18 iter, loss 0.2706560492515564
107 epoch, 19 iter, loss 0.33515167236328125
107 epoch, 20 iter, loss 0.23111410439014435
107 epoch, 21 iter, loss 0.26452478766441345
107 epoch, 22 iter, loss 0.17087289690971375
107 epoch, 23 iter, loss 0.37289443612098694
107 epoch, 24 iter, loss 0.2068653255701065
107 epoch, 25 iter, loss 0.3572925329208374
107 epoch, 26 iter, loss 0.2511279284954071
107 epoch, 27 iter, loss 0.1709953248500824
107 epoch, 28 iter, loss 0.22485849261283875
107 epoch, 29 iter, loss 0.27893444895744324
107 epoch, 30 iter, loss 0.24094508588314056
107 epoch, 31 iter, loss 0.18572606146335602
107 epoch, 32 iter, loss 0.2844199240207672
107 epoch, 33 iter, loss 0.21082395315170288
107 epoch, 34 iter, loss 0.23634888231754303
107 epoch, 35 iter, loss 0.2043728530406952
107 epoch, 36 iter, loss 0.3164139986038208
107 epoch, 37 iter, loss 0.2509639859199524
107 epoch, 38 iter, loss 0.3439224660396576
107 epoch, 39 iter, loss 0.22927647829055786
107 epoch, 40 iter, loss 0.29447585344314575
107 epoch, 41 iter, loss 0.16823479533195496
107 epoch, 42 iter, loss 0.3665536046028137
107 epoch, 43 iter, loss 0.19084319472312927
107 epoch, 44 iter, loss 0.29436635971069336
107 epoch, 45 iter, loss 0.2548454701900482
107 epoch, 46 iter, loss 0.1799248903989792
107 epoch, 47 iter, loss 0.24074530601501465
107 epoch, 48 iter, loss 0.18129143118858337
107 epoch, 49 iter, loss 0.2379295974969864
107 epoch, 50 iter, loss 0.18782198429107666
107 epoch, 51 iter, loss 0.3865988850593567
107 epoch, 52 iter, loss 0.2864125072956085
107 epoch, 53 iter, loss 0.24958810210227966
107 epoch, 54 iter, loss 0.24695293605327606
107 epoch, 55 iter, loss 0.2790409028530121
107 epoch, 56 iter, loss 0.2864602208137512
107 epoch, 57 iter, loss 0.47049060463905334
107 epoch, Average loss 0.25704145117809896
./model/merge_model_Param_v109.pth
some of decrypted state:
tensor([[[[ 0.0697, -0.0492,  0.0549],
          [ 0.1346,  0.1498,  0.0906],
          [-0.0952, -0.0859, -0.0094]],

         [[-0.0223,  0.1267,  0.1402],
          [-0.0007,  0.0874, -0.1182],
          [-0.1396, -0.0566,  0.0676]],

         [[ 0.1047, -0.0981,  0.0110],
          [ 0.0002, -0.0751,  0.0784],
          [ 0.0965,  0.1097, -0.1167]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2091, -0.1477,  0.1648],
          [ 0.4037,  0.4495,  0.2719],
          [-0.2856, -0.2578, -0.0283]],

         [[-0.0669,  0.3802,  0.4207],
          [-0.0020,  0.2621, -0.3545],
          [-0.4188, -0.1697,  0.2028]],

         [[ 0.3141, -0.2944,  0.0331],
          [ 0.0006, -0.2254,  0.2351],
          [ 0.2894,  0.3292, -0.3500]]]], device='cuda:0')
start training
108 epoch, 1 iter, loss 0.19115056097507477
108 epoch, 2 iter, loss 0.17427697777748108
108 epoch, 3 iter, loss 0.3110036551952362
108 epoch, 4 iter, loss 0.17539195716381073
108 epoch, 5 iter, loss 0.2754192650318146
108 epoch, 6 iter, loss 0.1817738115787506
108 epoch, 7 iter, loss 0.22446191310882568
108 epoch, 8 iter, loss 0.2906379997730255
108 epoch, 9 iter, loss 0.22234463691711426
108 epoch, 10 iter, loss 0.20823732018470764
108 epoch, 11 iter, loss 0.27238109707832336
108 epoch, 12 iter, loss 0.2345334142446518
108 epoch, 13 iter, loss 0.18785294890403748
108 epoch, 14 iter, loss 0.21628527343273163
108 epoch, 15 iter, loss 0.20479443669319153
108 epoch, 16 iter, loss 0.27021685242652893
108 epoch, 17 iter, loss 0.19634823501110077
108 epoch, 18 iter, loss 0.15931078791618347
108 epoch, 19 iter, loss 0.48222795128822327
108 epoch, 20 iter, loss 0.2881326675415039
108 epoch, 21 iter, loss 0.3370463252067566
108 epoch, 22 iter, loss 0.2945961058139801
108 epoch, 23 iter, loss 0.3825637400150299
108 epoch, 24 iter, loss 0.38441982865333557
108 epoch, 25 iter, loss 0.16037221252918243
108 epoch, 26 iter, loss 0.18272344768047333
108 epoch, 27 iter, loss 0.14938485622406006
108 epoch, 28 iter, loss 0.36982864141464233
108 epoch, 29 iter, loss 0.27447938919067383
108 epoch, 30 iter, loss 0.2717507779598236
108 epoch, 31 iter, loss 0.25956329703330994
108 epoch, 32 iter, loss 0.20771408081054688
108 epoch, 33 iter, loss 0.3829028606414795
108 epoch, 34 iter, loss 0.21245428919792175
108 epoch, 35 iter, loss 0.27750855684280396
108 epoch, 36 iter, loss 0.25321587920188904
108 epoch, 37 iter, loss 0.295289546251297
108 epoch, 38 iter, loss 0.4730050563812256
108 epoch, 39 iter, loss 0.28666752576828003
108 epoch, 40 iter, loss 0.3159957528114319
108 epoch, 41 iter, loss 0.1903241127729416
108 epoch, 42 iter, loss 0.24635113775730133
108 epoch, 43 iter, loss 0.3313067555427551
108 epoch, 44 iter, loss 0.24032439291477203
108 epoch, 45 iter, loss 0.27091002464294434
108 epoch, 46 iter, loss 0.28474223613739014
108 epoch, 47 iter, loss 0.3045029640197754
108 epoch, 48 iter, loss 0.32028284668922424
108 epoch, 49 iter, loss 0.24674385786056519
108 epoch, 50 iter, loss 0.32546576857566833
108 epoch, 51 iter, loss 0.18904978036880493
108 epoch, 52 iter, loss 0.1511896252632141
108 epoch, 53 iter, loss 0.2177988737821579
108 epoch, 54 iter, loss 0.2600363492965698
108 epoch, 55 iter, loss 0.2997450828552246
108 epoch, 56 iter, loss 0.14267666637897491
108 epoch, 57 iter, loss 0.31443217396736145
108 epoch, Average loss 0.2609499400122124
./model/merge_model_Param_v110.pth
some of decrypted state:
tensor([[[[ 0.0697, -0.0493,  0.0549],
          [ 0.1346,  0.1498,  0.0907],
          [-0.0953, -0.0860, -0.0095]],

         [[-0.0223,  0.1267,  0.1402],
          [-0.0006,  0.0874, -0.1181],
          [-0.1397, -0.0566,  0.0675]],

         [[ 0.1047, -0.0981,  0.0110],
          [ 0.0002, -0.0751,  0.0784],
          [ 0.0964,  0.1097, -0.1167]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 0.2090, -0.1479,  0.1646],
          [ 0.4037,  0.4495,  0.2720],
          [-0.2858, -0.2580, -0.0285]],

         [[-0.0669,  0.3801,  0.4205],
          [-0.0019,  0.2621, -0.3543],
          [-0.4190, -0.1698,  0.2026]],

         [[ 0.3142, -0.2944,  0.0330],
          [ 0.0007, -0.2253,  0.2352],
          [ 0.2892,  0.3291, -0.3501]]]], device='cuda:0')
start training
109 epoch, 1 iter, loss 0.2551629841327667
109 epoch, 2 iter, loss 0.21073056757450104
109 epoch, 3 iter, loss 0.12470312416553497
109 epoch, 4 iter, loss 0.3274906277656555
109 epoch, 5 iter, loss 0.21561726927757263
109 epoch, 6 iter, loss 0.29467496275901794
109 epoch, 7 iter, loss 0.18673180043697357
109 epoch, 8 iter, loss 0.2679640054702759
109 epoch, 9 iter, loss 0.23490743339061737
109 epoch, 10 iter, loss 0.22492556273937225
109 epoch, 11 iter, loss 0.3445703387260437
109 epoch, 12 iter, loss 0.18981103599071503
109 epoch, 13 iter, loss 0.19931723177433014
109 epoch, 14 iter, loss 0.15848667919635773
109 epoch, 15 iter, loss 0.20517756044864655
109 epoch, 16 iter, loss 0.4047333002090454
109 epoch, 17 iter, loss 0.2035694718360901
109 epoch, 18 iter, loss 0.2504096031188965
109 epoch, 19 iter, loss 0.27841463685035706
109 epoch, 20 iter, loss 0.18449240922927856
109 epoch, 21 iter, loss 0.3132209777832031
109 epoch, 22 iter, loss 0.24388809502124786
109 epoch, 23 iter, loss 0.12806713581085205
109 epoch, 24 iter, loss 0.2537609040737152
109 epoch, 25 iter, loss 0.24522221088409424
109 epoch, 26 iter, loss 0.2310706526041031
109 epoch, 27 iter, loss 0.31061655282974243
109 epoch, 28 iter, loss 0.269257515668869
109 epoch, 29 iter, loss 0.3410648703575134
109 epoch, 30 iter, loss 0.18276333808898926
109 epoch, 31 iter, loss 0.17795385420322418
109 epoch, 32 iter, loss 0.21401813626289368
109 epoch, 33 iter, loss 0.2675338089466095
109 epoch, 34 iter, loss 0.2350272834300995
109 epoch, 35 iter, loss 0.185599222779274
109 epoch, 36 iter, loss 0.11871147155761719
109 epoch, 37 iter, loss 0.2157631367444992
109 epoch, 38 iter, loss 0.22260619699954987
109 epoch, 39 iter, loss 0.32779133319854736
109 epoch, 40 iter, loss 0.22163477540016174
109 epoch, 41 iter, loss 0.20842082798480988
109 epoch, 42 iter, loss 0.3599126636981964
109 epoch, 43 iter, loss 0.3587157130241394
109 epoch, 44 iter, loss 0.3359627425670624
109 epoch, 45 iter, loss 0.3025412857532501
109 epoch, 46 iter, loss 0.24707414209842682
109 epoch, 47 iter, loss 0.33619776368141174
109 epoch, 48 iter, loss 0.23509998619556427
109 epoch, 49 iter, loss 0.27578437328338623
109 epoch, 50 iter, loss 0.191573366522789
109 epoch, 51 iter, loss 0.28155386447906494
109 epoch, 52 iter, loss 0.4342537224292755
109 epoch, 53 iter, loss 0.29928678274154663
109 epoch, 54 iter, loss 0.30174529552459717
109 epoch, 55 iter, loss 0.4332900643348694
109 epoch, 56 iter, loss 0.2510087788105011
109 epoch, 57 iter, loss 0.2124703973531723
109 epoch, Average loss 0.2549535762845424
./model/merge_model_Param_v111.pth
some of decrypted state:
tensor([[[[ 6.9674e-02, -4.9325e-02,  5.4836e-02],
          [ 1.3451e-01,  1.4979e-01,  9.0639e-02],
          [-9.5391e-02, -8.6098e-02, -9.5696e-03]],

         [[-2.2266e-02,  1.2671e-01,  1.4015e-01],
          [-6.8378e-04,  8.7317e-02, -1.1815e-01],
          [-1.3980e-01, -5.6721e-02,  6.7451e-02]],

         [[ 1.0471e-01, -9.8172e-02,  1.0963e-02],
          [ 1.1539e-04, -7.5226e-02,  7.8317e-02],
          [ 9.6252e-02,  1.0958e-01, -1.1679e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0902e-01, -1.4797e-01,  1.6451e-01],
          [ 4.0352e-01,  4.4937e-01,  2.7192e-01],
          [-2.8617e-01, -2.5829e-01, -2.8709e-02]],

         [[-6.6799e-02,  3.8013e-01,  4.2045e-01],
          [-2.0514e-03,  2.6195e-01, -3.5444e-01],
          [-4.1939e-01, -1.7016e-01,  2.0235e-01]],

         [[ 3.1413e-01, -2.9452e-01,  3.2890e-02],
          [ 3.4618e-04, -2.2568e-01,  2.3495e-01],
          [ 2.8876e-01,  3.2875e-01, -3.5038e-01]]]], device='cuda:0')
start training
110 epoch, 1 iter, loss 0.14055871963500977
110 epoch, 2 iter, loss 0.16110461950302124
110 epoch, 3 iter, loss 0.3465094268321991
110 epoch, 4 iter, loss 0.2324061244726181
110 epoch, 5 iter, loss 0.335319846868515
110 epoch, 6 iter, loss 0.29844585061073303
110 epoch, 7 iter, loss 0.21537724137306213
110 epoch, 8 iter, loss 0.27715086936950684
110 epoch, 9 iter, loss 0.3276267647743225
110 epoch, 10 iter, loss 0.27598217129707336
110 epoch, 11 iter, loss 0.1790253072977066
110 epoch, 12 iter, loss 0.35292789340019226
110 epoch, 13 iter, loss 0.21033549308776855
110 epoch, 14 iter, loss 0.15355002880096436
110 epoch, 15 iter, loss 0.3386724591255188
110 epoch, 16 iter, loss 0.23848563432693481
110 epoch, 17 iter, loss 0.34164294600486755
110 epoch, 18 iter, loss 0.24990998208522797
110 epoch, 19 iter, loss 0.24740301072597504
110 epoch, 20 iter, loss 0.24919423460960388
110 epoch, 21 iter, loss 0.24644170701503754
110 epoch, 22 iter, loss 0.1549132615327835
110 epoch, 23 iter, loss 0.1938001811504364
110 epoch, 24 iter, loss 0.34791553020477295
110 epoch, 25 iter, loss 0.2488107681274414
110 epoch, 26 iter, loss 0.2777484059333801
110 epoch, 27 iter, loss 0.2091926485300064
110 epoch, 28 iter, loss 0.32228973507881165
110 epoch, 29 iter, loss 0.15927013754844666
110 epoch, 30 iter, loss 0.19594497978687286
110 epoch, 31 iter, loss 0.21716053783893585
110 epoch, 32 iter, loss 0.3208562731742859
110 epoch, 33 iter, loss 0.20397409796714783
110 epoch, 34 iter, loss 0.13637670874595642
110 epoch, 35 iter, loss 0.3260727524757385
110 epoch, 36 iter, loss 0.24174994230270386
110 epoch, 37 iter, loss 0.3335050940513611
110 epoch, 38 iter, loss 0.20001423358917236
110 epoch, 39 iter, loss 0.25440818071365356
110 epoch, 40 iter, loss 0.3279717266559601
110 epoch, 41 iter, loss 0.2781294584274292
110 epoch, 42 iter, loss 0.2532372772693634
110 epoch, 43 iter, loss 0.2274835854768753
110 epoch, 44 iter, loss 0.24980944395065308
110 epoch, 45 iter, loss 0.2615029811859131
110 epoch, 46 iter, loss 0.2526269555091858
110 epoch, 47 iter, loss 0.25878283381462097
110 epoch, 48 iter, loss 0.24391008913516998
110 epoch, 49 iter, loss 0.12598995864391327
110 epoch, 50 iter, loss 0.2186587154865265
110 epoch, 51 iter, loss 0.22206123173236847
110 epoch, 52 iter, loss 0.17773054540157318
110 epoch, 53 iter, loss 0.3164597749710083
110 epoch, 54 iter, loss 0.23474085330963135
110 epoch, 55 iter, loss 0.2200598269701004
110 epoch, 56 iter, loss 0.39265573024749756
110 epoch, 57 iter, loss 0.23172315955162048
110 epoch, Average loss 0.2500983850474943
./model/merge_model_Param_v112.pth
some of decrypted state:
tensor([[[[ 6.9707e-02, -4.9286e-02,  5.4891e-02],
          [ 1.3454e-01,  1.4987e-01,  9.0783e-02],
          [-9.5282e-02, -8.5943e-02, -9.3880e-03]],

         [[-2.2221e-02,  1.2676e-01,  1.4018e-01],
          [-6.5041e-04,  8.7383e-02, -1.1802e-01],
          [-1.3972e-01, -5.6578e-02,  6.7625e-02]],

         [[ 1.0476e-01, -9.8131e-02,  1.0989e-02],
          [ 1.2398e-04, -7.5203e-02,  7.8403e-02],
          [ 9.6298e-02,  1.0970e-01, -1.1663e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0912e-01, -1.4786e-01,  1.6467e-01],
          [ 4.0363e-01,  4.4960e-01,  2.7235e-01],
          [-2.8584e-01, -2.5783e-01, -2.8164e-02]],

         [[-6.6662e-02,  3.8028e-01,  4.2054e-01],
          [-1.9512e-03,  2.6215e-01, -3.5405e-01],
          [-4.1916e-01, -1.6973e-01,  2.0288e-01]],

         [[ 3.1427e-01, -2.9439e-01,  3.2968e-02],
          [ 3.7193e-04, -2.2561e-01,  2.3521e-01],
          [ 2.8889e-01,  3.2911e-01, -3.4988e-01]]]], device='cuda:0')
start training
111 epoch, 1 iter, loss 0.43642282485961914
111 epoch, 2 iter, loss 0.17891106009483337
111 epoch, 3 iter, loss 0.14358735084533691
111 epoch, 4 iter, loss 0.32811787724494934
111 epoch, 5 iter, loss 0.2814582586288452
111 epoch, 6 iter, loss 0.2788771092891693
111 epoch, 7 iter, loss 0.19120825827121735
111 epoch, 8 iter, loss 0.3796978294849396
111 epoch, 9 iter, loss 0.33168289065361023
111 epoch, 10 iter, loss 0.28546929359436035
111 epoch, 11 iter, loss 0.2980862855911255
111 epoch, 12 iter, loss 0.2914559841156006
111 epoch, 13 iter, loss 0.197854146361351
111 epoch, 14 iter, loss 0.18200169503688812
111 epoch, 15 iter, loss 0.3304550349712372
111 epoch, 16 iter, loss 0.2611111104488373
111 epoch, 17 iter, loss 0.2799015939235687
111 epoch, 18 iter, loss 0.4336968958377838
111 epoch, 19 iter, loss 0.23674632608890533
111 epoch, 20 iter, loss 0.23176495730876923
111 epoch, 21 iter, loss 0.2666749060153961
111 epoch, 22 iter, loss 0.3808973431587219
111 epoch, 23 iter, loss 0.26840460300445557
111 epoch, 24 iter, loss 0.428869366645813
111 epoch, 25 iter, loss 0.20358067750930786
111 epoch, 26 iter, loss 0.28822895884513855
111 epoch, 27 iter, loss 0.30093932151794434
111 epoch, 28 iter, loss 0.20287537574768066
111 epoch, 29 iter, loss 0.3193397521972656
111 epoch, 30 iter, loss 0.33160609006881714
111 epoch, 31 iter, loss 0.2902142405509949
111 epoch, 32 iter, loss 0.18018701672554016
111 epoch, 33 iter, loss 0.3017520308494568
111 epoch, 34 iter, loss 0.44164571166038513
111 epoch, 35 iter, loss 0.42036116123199463
111 epoch, 36 iter, loss 0.21799108386039734
111 epoch, 37 iter, loss 0.3087048828601837
111 epoch, 38 iter, loss 0.22566594183444977
111 epoch, 39 iter, loss 0.2761995792388916
111 epoch, 40 iter, loss 0.22909002006053925
111 epoch, 41 iter, loss 0.2950359582901001
111 epoch, 42 iter, loss 0.21386770904064178
111 epoch, 43 iter, loss 0.4023258686065674
111 epoch, 44 iter, loss 0.3746376037597656
111 epoch, 45 iter, loss 0.301909476518631
111 epoch, 46 iter, loss 0.3129878640174866
111 epoch, 47 iter, loss 0.26631754636764526
111 epoch, 48 iter, loss 0.29961133003234863
111 epoch, 49 iter, loss 0.24886202812194824
111 epoch, 50 iter, loss 0.2265082150697708
111 epoch, 51 iter, loss 0.2309749275445938
111 epoch, 52 iter, loss 0.38049018383026123
111 epoch, 53 iter, loss 0.21478880941867828
111 epoch, 54 iter, loss 0.1738894134759903
111 epoch, 55 iter, loss 0.42549461126327515
111 epoch, 56 iter, loss 0.13806365430355072
111 epoch, 57 iter, loss 0.28257519006729126
111 epoch, Average loss 0.28508903922741874
./model/merge_model_Param_v113.pth
some of decrypted state:
tensor([[[[ 6.9631e-02, -4.9307e-02,  5.4882e-02],
          [ 1.3445e-01,  1.4988e-01,  9.0823e-02],
          [-9.5390e-02, -8.5999e-02, -9.4109e-03]],

         [[-2.2274e-02,  1.2676e-01,  1.4016e-01],
          [-7.4100e-04,  8.7385e-02, -1.1800e-01],
          [-1.3986e-01, -5.6667e-02,  6.7573e-02]],

         [[ 1.0474e-01, -9.8114e-02,  1.0994e-02],
          [ 3.6240e-05, -7.5213e-02,  7.8394e-02],
          [ 9.6155e-02,  1.0962e-01, -1.1666e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0889e-01, -1.4792e-01,  1.6465e-01],
          [ 4.0336e-01,  4.4964e-01,  2.7247e-01],
          [-2.8617e-01, -2.5800e-01, -2.8233e-02]],

         [[-6.6822e-02,  3.8028e-01,  4.2049e-01],
          [-2.2230e-03,  2.6216e-01, -3.5400e-01],
          [-4.1959e-01, -1.7000e-01,  2.0272e-01]],

         [[ 3.1422e-01, -2.9434e-01,  3.2982e-02],
          [ 1.0872e-04, -2.2564e-01,  2.3518e-01],
          [ 2.8847e-01,  3.2886e-01, -3.4999e-01]]]], device='cuda:0')
start training
112 epoch, 1 iter, loss 0.24768690764904022
112 epoch, 2 iter, loss 0.3103142976760864
112 epoch, 3 iter, loss 0.3177747130393982
112 epoch, 4 iter, loss 0.4293581545352936
112 epoch, 5 iter, loss 0.31664055585861206
112 epoch, 6 iter, loss 0.30627310276031494
112 epoch, 7 iter, loss 0.267307847738266
112 epoch, 8 iter, loss 0.3340683579444885
112 epoch, 9 iter, loss 0.2851742208003998
112 epoch, 10 iter, loss 0.2406136691570282
112 epoch, 11 iter, loss 0.19587109982967377
112 epoch, 12 iter, loss 0.34648755192756653
112 epoch, 13 iter, loss 0.16672304272651672
112 epoch, 14 iter, loss 0.2413674145936966
112 epoch, 15 iter, loss 0.2767906188964844
112 epoch, 16 iter, loss 0.39290285110473633
112 epoch, 17 iter, loss 0.1654534637928009
112 epoch, 18 iter, loss 0.3198215663433075
112 epoch, 19 iter, loss 0.38898569345474243
112 epoch, 20 iter, loss 0.3052549362182617
112 epoch, 21 iter, loss 0.27391114830970764
112 epoch, 22 iter, loss 0.2865982949733734
112 epoch, 23 iter, loss 0.2167544662952423
112 epoch, 24 iter, loss 0.3682815134525299
112 epoch, 25 iter, loss 0.18385031819343567
112 epoch, 26 iter, loss 0.27876409888267517
112 epoch, 27 iter, loss 0.259490966796875
112 epoch, 28 iter, loss 0.267534464597702
112 epoch, 29 iter, loss 0.3476046621799469
112 epoch, 30 iter, loss 0.1932501345872879
112 epoch, 31 iter, loss 0.18511484563350677
112 epoch, 32 iter, loss 0.3687759041786194
112 epoch, 33 iter, loss 0.24748462438583374
112 epoch, 34 iter, loss 0.22076371312141418
112 epoch, 35 iter, loss 0.22560295462608337
112 epoch, 36 iter, loss 0.2665445804595947
112 epoch, 37 iter, loss 0.24028201401233673
112 epoch, 38 iter, loss 0.17330652475357056
112 epoch, 39 iter, loss 0.34039777517318726
112 epoch, 40 iter, loss 0.430188924074173
112 epoch, 41 iter, loss 0.42156895995140076
112 epoch, 42 iter, loss 0.24033905565738678
112 epoch, 43 iter, loss 0.17916835844516754
112 epoch, 44 iter, loss 0.17603804171085358
112 epoch, 45 iter, loss 0.27474236488342285
112 epoch, 46 iter, loss 0.3110465705394745
112 epoch, 47 iter, loss 0.19826315343379974
112 epoch, 48 iter, loss 0.20673587918281555
112 epoch, 49 iter, loss 0.14181861281394958
112 epoch, 50 iter, loss 0.37319251894950867
112 epoch, 51 iter, loss 0.27570879459381104
112 epoch, 52 iter, loss 0.13461394608020782
112 epoch, 53 iter, loss 0.23469774425029755
112 epoch, 54 iter, loss 0.3277486264705658
112 epoch, 55 iter, loss 0.18108394742012024
112 epoch, 56 iter, loss 0.269499808549881
112 epoch, 57 iter, loss 0.3262651562690735
112 epoch, Average loss 0.2719632198936061
./model/merge_model_Param_v114.pth
some of decrypted state:
tensor([[[[ 6.9594e-02, -4.9286e-02,  5.4893e-02],
          [ 1.3447e-01,  1.4995e-01,  9.0966e-02],
          [-9.5387e-02, -8.5970e-02, -9.3622e-03]],

         [[-2.2308e-02,  1.2676e-01,  1.4015e-01],
          [-7.0047e-04,  8.7455e-02, -1.1787e-01],
          [-1.3988e-01, -5.6674e-02,  6.7600e-02]],

         [[ 1.0474e-01, -9.8096e-02,  1.0982e-02],
          [ 7.6294e-05, -7.5154e-02,  7.8485e-02],
          [ 9.6081e-02,  1.0961e-01, -1.1663e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0878e-01, -1.4786e-01,  1.6468e-01],
          [ 4.0342e-01,  4.4986e-01,  2.7290e-01],
          [-2.8616e-01, -2.5791e-01, -2.8087e-02]],

         [[-6.6925e-02,  3.8027e-01,  4.2044e-01],
          [-2.1014e-03,  2.6236e-01, -3.5361e-01],
          [-4.1965e-01, -1.7002e-01,  2.0280e-01]],

         [[ 3.1421e-01, -2.9429e-01,  3.2945e-02],
          [ 2.2888e-04, -2.2546e-01,  2.3545e-01],
          [ 2.8824e-01,  3.2883e-01, -3.4990e-01]]]], device='cuda:0')
start training
113 epoch, 1 iter, loss 0.3001691401004791
113 epoch, 2 iter, loss 0.26649272441864014
113 epoch, 3 iter, loss 0.3150216042995453
113 epoch, 4 iter, loss 0.1712849885225296
113 epoch, 5 iter, loss 0.19948600232601166
113 epoch, 6 iter, loss 0.26216399669647217
113 epoch, 7 iter, loss 0.15785212814807892
113 epoch, 8 iter, loss 0.36432746052742004
113 epoch, 9 iter, loss 0.25246381759643555
113 epoch, 10 iter, loss 0.2602841258049011
113 epoch, 11 iter, loss 0.23966604471206665
113 epoch, 12 iter, loss 0.21183979511260986
113 epoch, 13 iter, loss 0.14878255128860474
113 epoch, 14 iter, loss 0.29092714190483093
113 epoch, 15 iter, loss 0.24404440820217133
113 epoch, 16 iter, loss 0.31323567032814026
113 epoch, 17 iter, loss 0.3148646652698517
113 epoch, 18 iter, loss 0.20627008378505707
113 epoch, 19 iter, loss 0.15817631781101227
113 epoch, 20 iter, loss 0.2897375822067261
113 epoch, 21 iter, loss 0.35133886337280273
113 epoch, 22 iter, loss 0.25564292073249817
113 epoch, 23 iter, loss 0.3573867976665497
113 epoch, 24 iter, loss 0.3136555552482605
113 epoch, 25 iter, loss 0.19053493440151215
113 epoch, 26 iter, loss 0.17614684998989105
113 epoch, 27 iter, loss 0.28519952297210693
113 epoch, 28 iter, loss 0.19481880962848663
113 epoch, 29 iter, loss 0.266880065202713
113 epoch, 30 iter, loss 0.275118350982666
113 epoch, 31 iter, loss 0.2573135197162628
113 epoch, 32 iter, loss 0.23992116749286652
113 epoch, 33 iter, loss 0.2762652337551117
113 epoch, 34 iter, loss 0.21519845724105835
113 epoch, 35 iter, loss 0.20887157320976257
113 epoch, 36 iter, loss 0.2598063051700592
113 epoch, 37 iter, loss 0.3423563838005066
113 epoch, 38 iter, loss 0.1937757134437561
113 epoch, 39 iter, loss 0.24726146459579468
113 epoch, 40 iter, loss 0.3244618773460388
113 epoch, 41 iter, loss 0.3150012493133545
113 epoch, 42 iter, loss 0.1864631175994873
113 epoch, 43 iter, loss 0.2951408326625824
113 epoch, 44 iter, loss 0.1372985690832138
113 epoch, 45 iter, loss 0.29576289653778076
113 epoch, 46 iter, loss 0.18196752667427063
113 epoch, 47 iter, loss 0.23757219314575195
113 epoch, 48 iter, loss 0.3297749161720276
113 epoch, 49 iter, loss 0.2780468761920929
113 epoch, 50 iter, loss 0.12473160028457642
113 epoch, 51 iter, loss 0.14102067053318024
113 epoch, 52 iter, loss 0.22730860114097595
113 epoch, 53 iter, loss 0.2673366665840149
113 epoch, 54 iter, loss 0.2632882595062256
113 epoch, 55 iter, loss 0.2455015778541565
113 epoch, 56 iter, loss 0.1872468739748001
113 epoch, 57 iter, loss 0.2596297860145569
113 epoch, Average loss 0.24863397944391818
./model/merge_model_Param_v115.pth
some of decrypted state:
tensor([[[[ 6.9610e-02, -4.9269e-02,  5.4873e-02],
          [ 1.3449e-01,  1.4998e-01,  9.0916e-02],
          [-9.5435e-02, -8.6119e-02, -9.6016e-03]],

         [[-2.2305e-02,  1.2671e-01,  1.4005e-01],
          [-7.5531e-04,  8.7410e-02, -1.1796e-01],
          [-1.4004e-01, -5.6910e-02,  6.7286e-02]],

         [[ 1.0476e-01, -9.8104e-02,  1.0902e-02],
          [-4.0531e-05, -7.5268e-02,  7.8321e-02],
          [ 9.5852e-02,  1.0935e-01, -1.1694e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0883e-01, -1.4781e-01,  1.6462e-01],
          [ 4.0346e-01,  4.4993e-01,  2.7275e-01],
          [-2.8631e-01, -2.5836e-01, -2.8805e-02]],

         [[-6.6916e-02,  3.8014e-01,  4.2015e-01],
          [-2.2659e-03,  2.6223e-01, -3.5389e-01],
          [-4.2011e-01, -1.7073e-01,  2.0186e-01]],

         [[ 3.1428e-01, -2.9431e-01,  3.2707e-02],
          [-1.2159e-04, -2.2580e-01,  2.3496e-01],
          [ 2.8756e-01,  3.2805e-01, -3.5082e-01]]]], device='cuda:0')
start training
114 epoch, 1 iter, loss 0.2763679325580597
114 epoch, 2 iter, loss 0.18198998272418976
114 epoch, 3 iter, loss 0.3784313201904297
114 epoch, 4 iter, loss 0.24160081148147583
114 epoch, 5 iter, loss 0.2267555594444275
114 epoch, 6 iter, loss 0.3236575722694397
114 epoch, 7 iter, loss 0.22548191249370575
114 epoch, 8 iter, loss 0.25873732566833496
114 epoch, 9 iter, loss 0.28069397807121277
114 epoch, 10 iter, loss 0.1934146136045456
114 epoch, 11 iter, loss 0.19334851205348969
114 epoch, 12 iter, loss 0.23693357408046722
114 epoch, 13 iter, loss 0.1572587788105011
114 epoch, 14 iter, loss 0.3074771463871002
114 epoch, 15 iter, loss 0.3840833306312561
114 epoch, 16 iter, loss 0.15508723258972168
114 epoch, 17 iter, loss 0.21375294029712677
114 epoch, 18 iter, loss 0.1842799335718155
114 epoch, 19 iter, loss 0.18503108620643616
114 epoch, 20 iter, loss 0.3211436867713928
114 epoch, 21 iter, loss 0.4086311459541321
114 epoch, 22 iter, loss 0.2509647607803345
114 epoch, 23 iter, loss 0.20250777900218964
114 epoch, 24 iter, loss 0.2362130731344223
114 epoch, 25 iter, loss 0.30336499214172363
114 epoch, 26 iter, loss 0.2782723605632782
114 epoch, 27 iter, loss 0.2333604395389557
114 epoch, 28 iter, loss 0.23711927235126495
114 epoch, 29 iter, loss 0.2816259562969208
114 epoch, 30 iter, loss 0.30350756645202637
114 epoch, 31 iter, loss 0.3054753541946411
114 epoch, 32 iter, loss 0.18870556354522705
114 epoch, 33 iter, loss 0.18369048833847046
114 epoch, 34 iter, loss 0.3473239243030548
114 epoch, 35 iter, loss 0.1838744580745697
114 epoch, 36 iter, loss 0.18910489976406097
114 epoch, 37 iter, loss 0.49111664295196533
114 epoch, 38 iter, loss 0.2784215211868286
114 epoch, 39 iter, loss 0.2980717420578003
114 epoch, 40 iter, loss 0.21620596945285797
114 epoch, 41 iter, loss 0.3850975036621094
114 epoch, 42 iter, loss 0.19621647894382477
114 epoch, 43 iter, loss 0.3379572033882141
114 epoch, 44 iter, loss 0.3877881169319153
114 epoch, 45 iter, loss 0.1444951742887497
114 epoch, 46 iter, loss 0.2785428464412689
114 epoch, 47 iter, loss 0.26573076844215393
114 epoch, 48 iter, loss 0.19006136059761047
114 epoch, 49 iter, loss 0.22067111730575562
114 epoch, 50 iter, loss 0.20937837660312653
114 epoch, 51 iter, loss 0.2671336829662323
114 epoch, 52 iter, loss 0.22922420501708984
114 epoch, 53 iter, loss 0.2808944582939148
114 epoch, 54 iter, loss 0.21036508679389954
114 epoch, 55 iter, loss 0.39707592129707336
114 epoch, 56 iter, loss 0.28171876072883606
114 epoch, 57 iter, loss 0.12105699628591537
114 epoch, Average loss 0.25871040698206216
./model/merge_model_Param_v116.pth
some of decrypted state:
tensor([[[[ 6.9527e-02, -4.9349e-02,  5.4783e-02],
          [ 1.3454e-01,  1.5010e-01,  9.1095e-02],
          [-9.5399e-02, -8.6033e-02, -9.4833e-03]],

         [[-2.2266e-02,  1.2673e-01,  1.4001e-01],
          [-6.0511e-04,  8.7579e-02, -1.1774e-01],
          [-1.3997e-01, -5.6808e-02,  6.7400e-02]],

         [[ 1.0481e-01, -9.8069e-02,  1.0880e-02],
          [ 8.7738e-05, -7.5121e-02,  7.8457e-02],
          [ 9.5922e-02,  1.0943e-01, -1.1681e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0858e-01, -1.4805e-01,  1.6435e-01],
          [ 4.0363e-01,  4.5031e-01,  2.7328e-01],
          [-2.8620e-01, -2.5810e-01, -2.8450e-02]],

         [[-6.6799e-02,  3.8018e-01,  4.2004e-01],
          [-1.8153e-03,  2.6274e-01, -3.5323e-01],
          [-4.1990e-01, -1.7043e-01,  2.0220e-01]],

         [[ 3.1442e-01, -2.9421e-01,  3.2639e-02],
          [ 2.6321e-04, -2.2536e-01,  2.3537e-01],
          [ 2.8777e-01,  3.2830e-01, -3.5044e-01]]]], device='cuda:0')
start training
115 epoch, 1 iter, loss 0.2472810298204422
115 epoch, 2 iter, loss 0.23073865473270416
115 epoch, 3 iter, loss 0.18452410399913788
115 epoch, 4 iter, loss 0.3045876920223236
115 epoch, 5 iter, loss 0.4022160470485687
115 epoch, 6 iter, loss 0.24001598358154297
115 epoch, 7 iter, loss 0.24339884519577026
115 epoch, 8 iter, loss 0.3510151505470276
115 epoch, 9 iter, loss 0.22179748117923737
115 epoch, 10 iter, loss 0.3549990653991699
115 epoch, 11 iter, loss 0.4107533097267151
115 epoch, 12 iter, loss 0.3161596655845642
115 epoch, 13 iter, loss 0.3601020872592926
115 epoch, 14 iter, loss 0.2948063611984253
115 epoch, 15 iter, loss 0.2973603308200836
115 epoch, 16 iter, loss 0.2811832129955292
115 epoch, 17 iter, loss 0.25093716382980347
115 epoch, 18 iter, loss 0.18267640471458435
115 epoch, 19 iter, loss 0.2685730755329132
115 epoch, 20 iter, loss 0.24625669419765472
115 epoch, 21 iter, loss 0.14229154586791992
115 epoch, 22 iter, loss 0.22044843435287476
115 epoch, 23 iter, loss 0.21259094774723053
115 epoch, 24 iter, loss 0.237069770693779
115 epoch, 25 iter, loss 0.23821833729743958
115 epoch, 26 iter, loss 0.20996814966201782
115 epoch, 27 iter, loss 0.1652871072292328
115 epoch, 28 iter, loss 0.43773216009140015
115 epoch, 29 iter, loss 0.3529195189476013
115 epoch, 30 iter, loss 0.24644213914871216
115 epoch, 31 iter, loss 0.24057717621326447
115 epoch, 32 iter, loss 0.2963678538799286
115 epoch, 33 iter, loss 0.16734710335731506
115 epoch, 34 iter, loss 0.2139541655778885
115 epoch, 35 iter, loss 0.33495259284973145
115 epoch, 36 iter, loss 0.38807618618011475
115 epoch, 37 iter, loss 0.23357802629470825
115 epoch, 38 iter, loss 0.2718721628189087
115 epoch, 39 iter, loss 0.3444206118583679
115 epoch, 40 iter, loss 0.2229665219783783
115 epoch, 41 iter, loss 0.23781895637512207
115 epoch, 42 iter, loss 0.20021837949752808
115 epoch, 43 iter, loss 0.1786237508058548
115 epoch, 44 iter, loss 0.2184554785490036
115 epoch, 45 iter, loss 0.25542014837265015
115 epoch, 46 iter, loss 0.4596652090549469
115 epoch, 47 iter, loss 0.15587230026721954
115 epoch, 48 iter, loss 0.3029160499572754
115 epoch, 49 iter, loss 0.24693557620048523
115 epoch, 50 iter, loss 0.2951662242412567
115 epoch, 51 iter, loss 0.3287293314933777
115 epoch, 52 iter, loss 0.2133992314338684
115 epoch, 53 iter, loss 0.24158722162246704
115 epoch, 54 iter, loss 0.09569677710533142
115 epoch, 55 iter, loss 0.20105619728565216
115 epoch, 56 iter, loss 0.27849170565605164
115 epoch, 57 iter, loss 0.2906670868396759
115 epoch, Average loss 0.26433653502087845
./model/merge_model_Param_v117.pth
some of decrypted state:
tensor([[[[ 6.9575e-02, -4.9230e-02,  5.4880e-02],
          [ 1.3447e-01,  1.5003e-01,  9.1090e-02],
          [-9.5465e-02, -8.6048e-02, -9.4800e-03]],

         [[-2.2192e-02,  1.2683e-01,  1.4005e-01],
          [-7.4768e-04,  8.7417e-02, -1.1786e-01],
          [-1.4016e-01, -5.6952e-02,  6.7271e-02]],

         [[ 1.0490e-01, -9.7951e-02,  1.0920e-02],
          [-6.1512e-05, -7.5257e-02,  7.8302e-02],
          [ 9.5726e-02,  1.0930e-01, -1.1689e-01]]]], device='cuda:0')
Bob weight is 57
weight sum is 110	 client num is 3
After Decryption
 tensor([[[[ 2.0873e-01, -1.4769e-01,  1.6464e-01],
          [ 4.0341e-01,  4.5008e-01,  2.7327e-01],
          [-2.8640e-01, -2.5814e-01, -2.8440e-02]],

         [[-6.6576e-02,  3.8048e-01,  4.2015e-01],
          [-2.2430e-03,  2.6225e-01, -3.5357e-01],
          [-4.2049e-01, -1.7086e-01,  2.0181e-01]],

         [[ 3.1470e-01, -2.9385e-01,  3.2759e-02],
          [-1.8454e-04, -2.2577e-01,  2.3491e-01],
          [ 2.8718e-01,  3.2790e-01, -3.5068e-01]]]], device='cuda:0')
start training
116 epoch, 1 iter, loss 0.2337183952331543
116 epoch, 2 iter, loss 0.24691933393478394
116 epoch, 3 iter, loss 0.23331832885742188
116 epoch, 4 iter, loss 0.24023820459842682
116 epoch, 5 iter, loss 0.1689048558473587
116 epoch, 6 iter, loss 0.34772637486457825
116 epoch, 7 iter, loss 0.4476040005683899
116 epoch, 8 iter, loss 0.3675353527069092
116 epoch, 9 iter, loss 0.316802978515625
116 epoch, 10 iter, loss 0.32400500774383545
116 epoch, 11 iter, loss 0.24017681181430817
116 epoch, 12 iter, loss 0.2459491640329361
116 epoch, 13 iter, loss 0.2619297504425049
116 epoch, 14 iter, loss 0.21313077211380005
116 epoch, 15 iter, loss 0.207186758518219
116 epoch, 16 iter, loss 0.2340102195739746
116 epoch, 17 iter, loss 0.19557152688503265
116 epoch, 18 iter, loss 0.5216236710548401
116 epoch, 19 iter, loss 0.2310277670621872
116 epoch, 20 iter, loss 0.26443323493003845
116 epoch, 21 iter, loss 0.2675948739051819
116 epoch, 22 iter, loss 0.37738677859306335
116 epoch, 23 iter, loss 0.3274247944355011
116 epoch, 24 iter, loss 0.2972167432308197
116 epoch, 25 iter, loss 0.2709326446056366
116 epoch, 26 iter, loss 0.162847638130188
116 epoch, 27 iter, loss 0.30255112051963806
116 epoch, 28 iter, loss 0.29479309916496277
116 epoch, 29 iter, loss 0.17410555481910706
116 epoch, 30 iter, loss 0.570232629776001
116 epoch, 31 iter, loss 0.20945218205451965
116 epoch, 32 iter, loss 0.26592814922332764
116 epoch, 33 iter, loss 0.3494710922241211
116 epoch, 34 iter, loss 0.2558723986148834
116 epoch, 35 iter, loss 0.30273985862731934
116 epoch, 36 iter, loss 0.22991517186164856
116 epoch, 37 iter, loss 0.29120033979415894
116 epoch, 38 iter, loss 0.22917398810386658
116 epoch, 39 iter, loss 0.27680468559265137
116 epoch, 40 iter, loss 0.19762557744979858
116 epoch, 41 iter, loss 0.32457664608955383
116 epoch, 42 iter, loss 0.3112313747406006
116 epoch, 43 iter, loss 0.17279556393623352
116 epoch, 44 iter, loss 0.3635146915912628